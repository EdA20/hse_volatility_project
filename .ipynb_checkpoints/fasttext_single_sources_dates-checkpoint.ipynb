{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8495324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0da7883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f6ee630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm>=4.9.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.63.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install \"tqdm>=4.9.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "386b2622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fasttext==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fcbc498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/facebookresearch/fastText.git\n",
    "# !cd fastText\n",
    "# !pip install fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42d28100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ccf1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e0f7322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function download_model in module fasttext.util.util:\n",
      "\n",
      "download_model(lang_id, if_exists='strict', dimension=None)\n",
      "    Download pre-trained common-crawl vectors from fastText's website\n",
      "    https://fasttext.cc/docs/en/crawl-vectors.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(fasttext.util.download_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34cdbfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# fasttext.util.download_model('ru', if_exists='ignore')\n",
    "ft = fasttext.load_model('cc.ru.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5b2382c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06434693, -0.01527086, -0.06963537, -0.03582602,  0.01471584,\n",
       "       -0.03503159,  0.02701715,  0.04161827, -0.00033126,  0.00355259,\n",
       "        0.06979205,  0.06205348,  0.05154078,  0.03831509, -0.02394784,\n",
       "       -0.03954181, -0.00189653, -0.11174394, -0.0407712 ,  0.09289949,\n",
       "       -0.07412342, -0.05209147,  0.02017231,  0.04837443,  0.02212641,\n",
       "        0.00856511, -0.03055364,  0.04733564,  0.04380886,  0.03856769,\n",
       "        0.03442968,  0.05576854,  0.01513439,  0.14055566,  0.03365337,\n",
       "       -0.02920472, -0.10305687, -0.09332671,  0.03085899, -0.11067575,\n",
       "       -0.08992791,  0.05850704, -0.017424  ,  0.00120653, -0.07153153,\n",
       "        0.10312843, -0.08066262, -0.00642456,  0.04408539, -0.05728461,\n",
       "       -0.0179531 ,  0.03936698,  0.04778077, -0.04907751, -0.00909553,\n",
       "        0.05588715, -0.00236535,  0.04878682, -0.01769035,  0.03295048,\n",
       "        0.00906604,  0.08772802,  0.02970458, -0.04903899, -0.03025401,\n",
       "       -0.04151824,  0.04931813, -0.02804473,  0.05716789,  0.03559401,\n",
       "       -0.12191223,  0.02087349, -0.05121018, -0.0584691 , -0.04781278,\n",
       "       -0.06298476, -0.00432743, -0.03785646, -0.08833752, -0.0375172 ,\n",
       "        0.04602968,  0.02096615,  0.00321184, -0.00927999, -0.00288017,\n",
       "        0.04345381, -0.0330169 ,  0.00840916, -0.05537616, -0.02134524,\n",
       "       -0.03705332,  0.06453154, -0.01733523, -0.01977487, -0.02836509,\n",
       "        0.01901042,  0.04043126, -0.07048826, -0.09381784, -0.02532577,\n",
       "       -0.02679786,  0.01097633, -0.01681483, -0.08134623,  0.00429079,\n",
       "       -0.07213577, -0.03950587,  0.07274695, -0.00337509,  0.05469057,\n",
       "       -0.01510826, -0.05297935,  0.04232059, -0.04494021, -0.01873806,\n",
       "        0.02970697, -0.02128338, -0.07461107,  0.04457341,  0.02913763,\n",
       "       -0.05406609,  0.06825955, -0.0423348 , -0.01933457,  0.00638132,\n",
       "        0.00075826,  0.10154837, -0.06699109, -0.01374834,  0.10683898,\n",
       "        0.06719182,  0.00299954,  0.03092229, -0.01919586,  0.02315286,\n",
       "        0.02552165,  0.0297376 ,  0.0476847 , -0.06794806,  0.01934321,\n",
       "        0.07793375,  0.04631811,  0.07487484, -0.06923444, -0.09797966,\n",
       "       -0.02230856,  0.04383751,  0.05814477,  0.09182699,  0.0407513 ,\n",
       "        0.06562199,  0.06420117, -0.12618978, -0.00895569, -0.03637737,\n",
       "        0.0323772 ,  0.05442533,  0.02233687,  0.0607053 , -0.03511162,\n",
       "       -0.02011008, -0.04657565, -0.1363746 , -0.09366813, -0.01257268,\n",
       "       -0.0822741 ,  0.04026463,  0.08941573,  0.05416025, -0.00148568,\n",
       "        0.02470817, -0.01521165,  0.06688396,  0.01970377, -0.067048  ,\n",
       "        0.05173868, -0.06437217,  0.02638604,  0.02355881, -0.03286408,\n",
       "       -0.01542088,  0.0226214 ,  0.01009578, -0.06503511,  0.05164307,\n",
       "        0.08621447, -0.00291589,  0.0201317 ,  0.05789564,  0.04330945,\n",
       "       -0.01468945,  0.00915974,  0.02692279,  0.07124459, -0.05370982,\n",
       "        0.04218086,  0.00314814,  0.00356758, -0.02068229,  0.0604349 ,\n",
       "       -0.08158811,  0.04939371,  0.0430281 , -0.03372736, -0.0558867 ,\n",
       "        0.00376545, -0.037087  ,  0.05940549,  0.02495521, -0.00334628,\n",
       "        0.01005986, -0.02053031,  0.01179219,  0.07010209, -0.10397089,\n",
       "        0.07733957,  0.06056703,  0.01003617, -0.15787463, -0.01765688,\n",
       "        0.00765593, -0.01905038,  0.01327723,  0.01084452, -0.05930451,\n",
       "       -0.07062402, -0.08540855,  0.01374613, -0.03077546, -0.04025275,\n",
       "        0.00268231, -0.06844234,  0.05945092,  0.02234607,  0.14669767,\n",
       "        0.03161074, -0.03626112,  0.13065669, -0.02795461,  0.00260858,\n",
       "        0.02103085, -0.01555263,  0.02790887, -0.02395738, -0.10259839,\n",
       "       -0.01162906,  0.07939966,  0.01229805,  0.0472665 ,  0.00792722,\n",
       "        0.07495239, -0.04777352,  0.02290227, -0.02349729, -0.01035224,\n",
       "       -0.04128299, -0.05037197, -0.02936148, -0.03995599, -0.09582971,\n",
       "        0.00652219, -0.00309965,  0.09921778, -0.07993053, -0.07525942,\n",
       "       -0.03148453, -0.03216294,  0.00986726, -0.03059178, -0.01402058,\n",
       "        0.02519003, -0.04734642,  0.12286284, -0.09953459,  0.01202545,\n",
       "        0.03934894,  0.07455902,  0.02744922,  0.03999532, -0.05147249,\n",
       "       -0.0055727 ,  0.07064351,  0.07526451,  0.00223117,  0.01765039,\n",
       "       -0.02785274,  0.0251571 ,  0.05081079,  0.06183068, -0.03087618,\n",
       "       -0.00268458, -0.02822061, -0.05344585, -0.05139395,  0.00151552,\n",
       "       -0.01931686,  0.00034288, -0.01423903,  0.00377267, -0.0598783 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft['привет']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2fecc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "def get_tweet_embedding(lemmas, model, embedding_size=300):\n",
    "    \n",
    "    res = np.zeros(embedding_size)\n",
    "    cnt = 0\n",
    "    for word in lemmas.split():\n",
    "        if word in model:\n",
    "            res += np.array(model[word])\n",
    "            cnt += 1\n",
    "    if cnt:\n",
    "        res = res / cnt\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17ef304c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.84749218e-02,  1.14055865e-02, -1.54750008e-02,  6.10717852e-03,\n",
       "       -5.42343501e-03,  2.83443742e-03,  2.40256451e-03,  1.29073053e-02,\n",
       "        3.05031866e-02, -1.99234379e-02,  6.13203850e-02,  4.42768331e-02,\n",
       "        2.71531800e-02, -1.02064133e-02,  9.22483567e-04,  2.50384058e-02,\n",
       "       -1.25383004e-02, -4.89095808e-02, -3.07890818e-02,  1.01918663e-01,\n",
       "       -2.85800546e-02, -1.05811988e-01, -1.28629373e-02,  2.95597422e-02,\n",
       "        2.13206490e-03,  1.26906892e-02, -2.97227059e-02,  2.77029723e-02,\n",
       "       -1.21254625e-02, -4.76178443e-02, -6.68591424e-03,  3.05985650e-02,\n",
       "        3.59081652e-02,  1.02970391e-01,  3.62780495e-02, -5.56655712e-02,\n",
       "       -1.11200343e-01, -1.16946280e-01,  4.69890856e-02, -5.79430675e-02,\n",
       "       -4.56299540e-03, -2.32621958e-03, -2.30524363e-03,  1.96370891e-02,\n",
       "       -1.68996924e-02,  4.77626729e-02, -7.71877861e-02,  2.95996453e-02,\n",
       "        3.40769021e-02, -3.43663241e-02,  5.55797149e-02,  1.05126291e-02,\n",
       "        9.77615127e-03,  3.99762448e-02, -2.15159254e-02,  1.93620831e-02,\n",
       "       -1.34500194e-02,  2.17238814e-03,  1.39238648e-02, -1.24853794e-02,\n",
       "       -5.08000248e-02,  6.46954067e-02,  3.07824350e-02, -4.07074159e-02,\n",
       "       -1.99913508e-02,  1.96010725e-02, -1.52623175e-02, -1.58499312e-02,\n",
       "       -4.72955415e-02,  4.77682170e-03, -5.21384678e-02,  3.73177927e-02,\n",
       "       -3.41336881e-02,  5.90577209e-03,  6.41630217e-03, -2.70765051e-02,\n",
       "       -5.57585534e-02, -9.87857254e-03, -1.75393135e-02, -3.92743144e-02,\n",
       "        2.59191706e-02,  3.97690022e-02,  5.75262937e-03, -4.60929359e-02,\n",
       "        3.89499759e-03,  3.79725420e-02, -6.47511277e-02,  5.06016524e-02,\n",
       "        1.29573480e-02,  9.16208606e-04, -1.10791333e-01, -1.59734851e-02,\n",
       "        4.38956684e-03, -5.00591882e-02, -1.91273557e-02, -1.31234950e-02,\n",
       "        4.23284452e-02, -1.32317897e-02, -9.03501306e-02,  4.14077961e-02,\n",
       "       -9.01901850e-03,  7.61899361e-02, -1.04387742e-02, -1.22785277e-02,\n",
       "       -1.63511078e-02, -3.89259742e-02,  4.25888405e-02,  2.55549918e-02,\n",
       "        7.98778998e-03,  9.49782273e-03, -3.10476529e-02, -1.09063331e-02,\n",
       "        8.43151626e-02, -3.58087434e-02, -1.24211812e-02, -1.87083688e-02,\n",
       "       -5.45124998e-02, -8.86561619e-02,  3.79863534e-02, -3.31068560e-02,\n",
       "       -4.89519509e-02,  7.88756466e-02, -5.50974393e-02,  1.60968699e-02,\n",
       "        1.01266545e-03,  2.75706507e-02,  5.04551297e-02, -1.64009025e-02,\n",
       "        1.19224258e-02,  6.78465860e-02,  2.69761501e-02,  1.12457192e-02,\n",
       "        1.86175751e-02, -1.40191410e-02, -1.72757215e-02,  5.70655339e-02,\n",
       "        5.77574829e-04,  5.24380505e-02, -5.08161918e-03,  3.53807122e-02,\n",
       "       -1.40902330e-02,  2.29508245e-02,  6.68836981e-02, -2.08306434e-02,\n",
       "       -5.37150722e-02, -9.75077925e-03, -4.46044868e-02,  3.50373158e-02,\n",
       "        5.37473205e-02,  2.23793560e-02,  3.78368636e-02,  1.91988172e-02,\n",
       "       -9.24861385e-02,  1.07819675e-02, -1.21989548e-02,  3.31418150e-02,\n",
       "        2.23143799e-02,  1.49282608e-02,  1.40205264e-02, -2.72367133e-02,\n",
       "       -2.69449629e-02,  2.49509839e-03, -5.19380664e-02, -6.78124642e-02,\n",
       "       -6.38052975e-02,  1.68222875e-02, -7.74696337e-02,  8.44685482e-02,\n",
       "        4.74610087e-02, -2.62326931e-03, -9.03137206e-03, -6.54254213e-02,\n",
       "        4.35586069e-02,  3.72354283e-02, -3.41950073e-02, -1.16772181e-02,\n",
       "       -3.14856721e-02,  6.10582798e-02,  4.79020393e-02, -4.82062241e-02,\n",
       "       -1.99088580e-02,  3.10592290e-02, -4.53291640e-02, -6.53951182e-02,\n",
       "        6.01363019e-04,  3.27027021e-02,  1.47671076e-02, -3.70643544e-02,\n",
       "       -2.04997172e-02,  5.32348915e-02, -4.50411410e-02,  1.28656339e-02,\n",
       "        3.19320844e-02,  1.45057300e-02, -1.72404865e-02,  3.71150244e-02,\n",
       "       -2.15479551e-02, -1.15545052e-02, -1.25362631e-02,  2.60218652e-02,\n",
       "       -4.58280314e-02,  7.53374584e-03,  7.35389721e-03, -1.82377142e-02,\n",
       "       -9.48007656e-02, -2.56354164e-02,  5.40375593e-04,  4.41152531e-02,\n",
       "       -7.10717402e-04,  4.32135077e-03,  2.78144046e-02, -4.11721691e-03,\n",
       "       -8.98516446e-04,  5.58417288e-02, -3.63211357e-02, -6.08586776e-03,\n",
       "        3.32013650e-02,  3.86003682e-02, -4.08708490e-02,  1.05813891e-02,\n",
       "        1.79253643e-02,  3.97888436e-02,  3.22979216e-02,  1.34046650e-02,\n",
       "       -3.69763831e-02,  3.80074000e-02, -3.84184653e-02, -1.46874161e-02,\n",
       "        1.31309093e-02, -1.08475601e-02,  1.34081137e-02, -1.17426082e-02,\n",
       "        1.28444180e-01, -2.20539912e-02,  1.15903737e-01,  5.90186799e-03,\n",
       "        1.24620628e-02,  7.31505433e-02, -7.99386785e-03,  3.64330948e-02,\n",
       "        3.45786135e-02,  3.46622248e-02,  2.36364873e-03, -7.05305371e-02,\n",
       "       -5.42092409e-02, -8.53608083e-03, -5.25069842e-03, -6.02257324e-02,\n",
       "        2.03989604e-02, -1.16195149e-02,  9.21856882e-02, -6.69648121e-02,\n",
       "        7.29324436e-03,  2.93620190e-02,  6.43402617e-02,  1.59824028e-02,\n",
       "        2.18187862e-02, -1.51119323e-03, -8.90493509e-03, -1.16167957e-01,\n",
       "        3.43116624e-02, -2.22888631e-02,  6.75987527e-02,  2.60055298e-02,\n",
       "       -2.21864720e-02, -2.88950545e-02,  5.87026319e-02,  5.31624537e-05,\n",
       "        4.37127347e-02, -3.44873604e-02,  1.45444367e-02,  4.66503901e-04,\n",
       "        1.16275493e-01, -7.23772724e-02,  3.08836906e-02,  3.09007196e-03,\n",
       "        1.63774043e-02,  1.35315594e-02,  3.91931003e-02, -3.61349685e-02,\n",
       "        8.19852925e-04,  2.57454347e-04,  6.94709985e-03,  1.86907215e-02,\n",
       "       -3.81673360e-03,  1.24494154e-02, -2.23289109e-02, -3.35482652e-02,\n",
       "       -4.22900976e-02,  2.49405606e-02,  4.42143134e-03,  5.85364044e-03,\n",
       "        3.19063303e-03, -4.88638142e-02, -1.23414861e-02, -1.29953995e-02,\n",
       "        1.96110924e-02,  1.76430468e-02,  9.77955939e-03, -1.76622996e-02])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 'привет всем слушателям курса'\n",
    "get_tweet_embedding(x, model=ft, embedding_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d77a274",
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKTEST_CCY = 'EURUSD'\n",
    "BACKTEST_DAYS = 5\n",
    "YEAR = 2022\n",
    "\n",
    "PATH_TEXTS = 'data/telegram'\n",
    "PATH_OPT_PNL = 'data/pnl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9b3272b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cbonds.csv',\n",
       " 'themovchans.csv',\n",
       " 'headlines_QUANTS.csv',\n",
       " 'War_Wealth_Wisdom.csv',\n",
       " 'mmi.csv',\n",
       " 'vts.csv',\n",
       " 'signal.csv',\n",
       " '.gitignore',\n",
       " 'rshb_invest.csv',\n",
       " 'Alfa_Wealth.csv',\n",
       " 'sky_bond.csv',\n",
       " 'bitkogan.csv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all available data_sources\n",
    "sources = os.listdir(PATH_TEXTS)\n",
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c00cad9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_start</th>\n",
       "      <th>pnl</th>\n",
       "      <th>pnl_sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>291264.097914</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>-411993.830320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>521491.686795</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>62842.634116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-11</td>\n",
       "      <td>-537598.706217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2021-12-20</td>\n",
       "      <td>-407527.554561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2021-12-21</td>\n",
       "      <td>-176881.417077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>-206943.414418</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>23073.596468</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>283960.438531</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_start            pnl  pnl_sign\n",
       "0    2021-01-04  291264.097914         1\n",
       "1    2021-01-05 -411993.830320         0\n",
       "2    2021-01-06  521491.686795         1\n",
       "3    2021-01-08   62842.634116         1\n",
       "4    2021-01-11 -537598.706217         0\n",
       "..          ...            ...       ...\n",
       "245  2021-12-20 -407527.554561         0\n",
       "246  2021-12-21 -176881.417077         0\n",
       "247  2021-12-22 -206943.414418         0\n",
       "248  2021-12-23   23073.596468         1\n",
       "249  2021-12-24  283960.438531         1\n",
       "\n",
       "[250 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create target variable dataframe\n",
    "pnl = pd.read_csv(f'{PATH_OPT_PNL}/Backtest_{BACKTEST_CCY}_{BACKTEST_DAYS}_days_{YEAR}.txt')\n",
    "pnl['date_start'] = pd.to_datetime(pnl['date_start']).dt.strftime('%Y-%m-%d')\n",
    "pnl['pnl_sign'] = pnl['pnl'].apply(lambda x: 1 if x >= 0 else 0)\n",
    "pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c052489b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.536"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get balance of the sample\n",
    "balance = pnl['pnl_sign'].sum() / pnl.shape[0]\n",
    "balance = max(balance, 1 - balance)\n",
    "balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f953b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "\n",
    "def _binary_search_by_date(array: List[Tuple[dt.datetime, float]], date_x: dt.datetime) -> Union[int, None]:\n",
    "    \"\"\"\n",
    "    Searches for the index of date_x in the array via binary search.\n",
    "\n",
    "        Parameters:\n",
    "            array (list) : A sorted array of (date, float_value) tuples\n",
    "            date_x (datetime.datetime) : Date to search for\n",
    "\n",
    "        Returns:\n",
    "            index_x (int): Index of the searched date in the array.\n",
    "    \"\"\"\n",
    "    left = 0\n",
    "    right = len(array) - 1\n",
    "\n",
    "    while left <= right:\n",
    "        mid = left + (right - left) // 2\n",
    "\n",
    "        if array[mid - 1][0] <= date_x <= array[mid][0]:\n",
    "            return mid\n",
    "        elif date_x > array[mid - 1][0] and date_x > array[mid][0]:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def binary_search_time_series(time_series: List[Tuple[dt.datetime, float]], date_start: dt.datetime,\n",
    "                              date_end: dt.datetime) -> Union[List[Tuple[dt.datetime, float]], None]:\n",
    "    \"\"\"\n",
    "    Searches for the part of the time series that is contained inside [date_start; date_end] period via binary search.\n",
    "\n",
    "        Parameters:\n",
    "            time_series (list) : A sorted array of (date, float_value) tuples\n",
    "            date_start (datetime.datetime) : Starting date of the searched period\n",
    "            date_end (datetime.datetime) : Ending date of the searched period\n",
    "\n",
    "        Returns:\n",
    "            time_series_data (list): Part of the time series that is contained inside [date_start; date_end] period.\n",
    "    \"\"\"\n",
    "\n",
    "    if date_start <= date_end:\n",
    "        left_index = _binary_search_by_date(time_series, date_start)\n",
    "        \n",
    "        if left_index is None:\n",
    "            return None\n",
    "        \n",
    "        right_index = _binary_search_by_date(time_series[left_index:], date_end)\n",
    "        \n",
    "        if right_index is None:\n",
    "            return None\n",
    "        \n",
    "        right_index += left_index\n",
    "    else:\n",
    "        left_index = _binary_search_by_date(time_series, date_end)\n",
    "        \n",
    "        if left_index is None:\n",
    "            return None\n",
    "        \n",
    "        right_index = _binary_search_by_date(time_series[left_index:], date_start)\n",
    "        \n",
    "        if right_index is None:\n",
    "            return None\n",
    "        \n",
    "        right_index += left_index\n",
    "    \n",
    "    return time_series[left_index:right_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19fac87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.datetime(2021, 1, 4, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 5, 0, 0), 0),\n",
       " (datetime.datetime(2021, 1, 6, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 8, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 11, 0, 0), 0),\n",
       " (datetime.datetime(2021, 1, 12, 0, 0), 0),\n",
       " (datetime.datetime(2021, 1, 13, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 14, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 15, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 18, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 19, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 20, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 21, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 22, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 25, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 26, 0, 0), 0),\n",
       " (datetime.datetime(2021, 1, 27, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 28, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 29, 0, 0), 1),\n",
       " (datetime.datetime(2021, 2, 1, 0, 0), 0),\n",
       " (datetime.datetime(2021, 2, 2, 0, 0), 0),\n",
       " (datetime.datetime(2021, 2, 3, 0, 0), 0),\n",
       " (datetime.datetime(2021, 2, 4, 0, 0), 0),\n",
       " (datetime.datetime(2021, 2, 5, 0, 0), 0),\n",
       " (datetime.datetime(2021, 2, 8, 0, 0), 0),\n",
       " (datetime.datetime(2021, 2, 9, 0, 0), 0),\n",
       " (datetime.datetime(2021, 2, 10, 0, 0), 1),\n",
       " (datetime.datetime(2021, 2, 11, 0, 0), 0),\n",
       " (datetime.datetime(2021, 2, 12, 0, 0), 0),\n",
       " (datetime.datetime(2021, 2, 15, 0, 0), 1),\n",
       " (datetime.datetime(2021, 2, 16, 0, 0), 1),\n",
       " (datetime.datetime(2021, 2, 17, 0, 0), 1),\n",
       " (datetime.datetime(2021, 2, 18, 0, 0), 1),\n",
       " (datetime.datetime(2021, 2, 19, 0, 0), 1),\n",
       " (datetime.datetime(2021, 2, 22, 0, 0), 1),\n",
       " (datetime.datetime(2021, 2, 24, 0, 0), 1),\n",
       " (datetime.datetime(2021, 2, 25, 0, 0), 1),\n",
       " (datetime.datetime(2021, 2, 26, 0, 0), 0),\n",
       " (datetime.datetime(2021, 3, 1, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 2, 0, 0), 0),\n",
       " (datetime.datetime(2021, 3, 3, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 4, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 5, 0, 0), 0),\n",
       " (datetime.datetime(2021, 3, 9, 0, 0), 0),\n",
       " (datetime.datetime(2021, 3, 10, 0, 0), 0),\n",
       " (datetime.datetime(2021, 3, 11, 0, 0), 0),\n",
       " (datetime.datetime(2021, 3, 12, 0, 0), 0),\n",
       " (datetime.datetime(2021, 3, 15, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 16, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 17, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 18, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 19, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 22, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 23, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 24, 0, 0), 0),\n",
       " (datetime.datetime(2021, 3, 25, 0, 0), 0),\n",
       " (datetime.datetime(2021, 3, 26, 0, 0), 0),\n",
       " (datetime.datetime(2021, 3, 29, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 30, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 31, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 1, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 2, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 5, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 6, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 7, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 8, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 9, 0, 0), 0),\n",
       " (datetime.datetime(2021, 4, 12, 0, 0), 0),\n",
       " (datetime.datetime(2021, 4, 13, 0, 0), 0),\n",
       " (datetime.datetime(2021, 4, 14, 0, 0), 0),\n",
       " (datetime.datetime(2021, 4, 15, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 16, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 19, 0, 0), 0),\n",
       " (datetime.datetime(2021, 4, 20, 0, 0), 0),\n",
       " (datetime.datetime(2021, 4, 21, 0, 0), 0),\n",
       " (datetime.datetime(2021, 4, 22, 0, 0), 0),\n",
       " (datetime.datetime(2021, 4, 23, 0, 0), 0),\n",
       " (datetime.datetime(2021, 4, 26, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 27, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 28, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 29, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 30, 0, 0), 1),\n",
       " (datetime.datetime(2021, 5, 4, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 5, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 6, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 7, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 10, 0, 0), 1),\n",
       " (datetime.datetime(2021, 5, 11, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 12, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 13, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 14, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 17, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 18, 0, 0), 1),\n",
       " (datetime.datetime(2021, 5, 19, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 20, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 21, 0, 0), 1),\n",
       " (datetime.datetime(2021, 5, 24, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 25, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 26, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 27, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 28, 0, 0), 1),\n",
       " (datetime.datetime(2021, 5, 31, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 1, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 2, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 3, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 4, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 7, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 8, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 9, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 10, 0, 0), 1),\n",
       " (datetime.datetime(2021, 6, 11, 0, 0), 1),\n",
       " (datetime.datetime(2021, 6, 14, 0, 0), 1),\n",
       " (datetime.datetime(2021, 6, 15, 0, 0), 1),\n",
       " (datetime.datetime(2021, 6, 16, 0, 0), 1),\n",
       " (datetime.datetime(2021, 6, 17, 0, 0), 1),\n",
       " (datetime.datetime(2021, 6, 18, 0, 0), 1),\n",
       " (datetime.datetime(2021, 6, 21, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 22, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 23, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 24, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 25, 0, 0), 1),\n",
       " (datetime.datetime(2021, 6, 28, 0, 0), 1),\n",
       " (datetime.datetime(2021, 6, 29, 0, 0), 1),\n",
       " (datetime.datetime(2021, 6, 30, 0, 0), 1),\n",
       " (datetime.datetime(2021, 7, 1, 0, 0), 1),\n",
       " (datetime.datetime(2021, 7, 2, 0, 0), 1),\n",
       " (datetime.datetime(2021, 7, 5, 0, 0), 1),\n",
       " (datetime.datetime(2021, 7, 6, 0, 0), 1),\n",
       " (datetime.datetime(2021, 7, 7, 0, 0), 0),\n",
       " (datetime.datetime(2021, 7, 8, 0, 0), 0),\n",
       " (datetime.datetime(2021, 7, 9, 0, 0), 1),\n",
       " (datetime.datetime(2021, 7, 12, 0, 0), 0),\n",
       " (datetime.datetime(2021, 7, 13, 0, 0), 1),\n",
       " (datetime.datetime(2021, 7, 14, 0, 0), 1),\n",
       " (datetime.datetime(2021, 7, 15, 0, 0), 1),\n",
       " (datetime.datetime(2021, 7, 16, 0, 0), 0),\n",
       " (datetime.datetime(2021, 7, 19, 0, 0), 0),\n",
       " (datetime.datetime(2021, 7, 20, 0, 0), 0),\n",
       " (datetime.datetime(2021, 7, 21, 0, 0), 0),\n",
       " (datetime.datetime(2021, 7, 22, 0, 0), 1),\n",
       " (datetime.datetime(2021, 7, 23, 0, 0), 1),\n",
       " (datetime.datetime(2021, 7, 26, 0, 0), 0),\n",
       " (datetime.datetime(2021, 7, 27, 0, 0), 0),\n",
       " (datetime.datetime(2021, 7, 28, 0, 0), 0),\n",
       " (datetime.datetime(2021, 7, 29, 0, 0), 0),\n",
       " (datetime.datetime(2021, 7, 30, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 2, 0, 0), 1),\n",
       " (datetime.datetime(2021, 8, 3, 0, 0), 1),\n",
       " (datetime.datetime(2021, 8, 4, 0, 0), 1),\n",
       " (datetime.datetime(2021, 8, 5, 0, 0), 1),\n",
       " (datetime.datetime(2021, 8, 6, 0, 0), 1),\n",
       " (datetime.datetime(2021, 8, 9, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 10, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 11, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 12, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 13, 0, 0), 1),\n",
       " (datetime.datetime(2021, 8, 16, 0, 0), 1),\n",
       " (datetime.datetime(2021, 8, 17, 0, 0), 1),\n",
       " (datetime.datetime(2021, 8, 18, 0, 0), 1),\n",
       " (datetime.datetime(2021, 8, 19, 0, 0), 1),\n",
       " (datetime.datetime(2021, 8, 20, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 23, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 24, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 25, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 26, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 27, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 30, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 31, 0, 0), 0),\n",
       " (datetime.datetime(2021, 9, 1, 0, 0), 0),\n",
       " (datetime.datetime(2021, 9, 2, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 3, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 6, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 7, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 8, 0, 0), 0),\n",
       " (datetime.datetime(2021, 9, 9, 0, 0), 0),\n",
       " (datetime.datetime(2021, 9, 10, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 13, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 14, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 15, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 16, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 17, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 20, 0, 0), 0),\n",
       " (datetime.datetime(2021, 9, 21, 0, 0), 0),\n",
       " (datetime.datetime(2021, 9, 22, 0, 0), 0),\n",
       " (datetime.datetime(2021, 9, 23, 0, 0), 0),\n",
       " (datetime.datetime(2021, 9, 24, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 27, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 28, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 29, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 30, 0, 0), 1),\n",
       " (datetime.datetime(2021, 10, 1, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 4, 0, 0), 1),\n",
       " (datetime.datetime(2021, 10, 5, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 6, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 7, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 8, 0, 0), 1),\n",
       " (datetime.datetime(2021, 10, 11, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 12, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 13, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 14, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 15, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 18, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 19, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 20, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 21, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 22, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 25, 0, 0), 1),\n",
       " (datetime.datetime(2021, 10, 26, 0, 0), 1),\n",
       " (datetime.datetime(2021, 10, 27, 0, 0), 1),\n",
       " (datetime.datetime(2021, 10, 28, 0, 0), 1),\n",
       " (datetime.datetime(2021, 10, 29, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 1, 0, 0), 0),\n",
       " (datetime.datetime(2021, 11, 2, 0, 0), 0),\n",
       " (datetime.datetime(2021, 11, 3, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 5, 0, 0), 0),\n",
       " (datetime.datetime(2021, 11, 8, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 9, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 10, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 11, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 12, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 15, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 16, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 17, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 18, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 19, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 22, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 23, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 24, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 25, 0, 0), 0),\n",
       " (datetime.datetime(2021, 11, 26, 0, 0), 0),\n",
       " (datetime.datetime(2021, 11, 29, 0, 0), 0),\n",
       " (datetime.datetime(2021, 11, 30, 0, 0), 0),\n",
       " (datetime.datetime(2021, 12, 1, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 2, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 3, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 6, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 7, 0, 0), 0),\n",
       " (datetime.datetime(2021, 12, 8, 0, 0), 0),\n",
       " (datetime.datetime(2021, 12, 9, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 10, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 13, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 14, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 15, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 16, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 17, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 20, 0, 0), 0),\n",
       " (datetime.datetime(2021, 12, 21, 0, 0), 0),\n",
       " (datetime.datetime(2021, 12, 22, 0, 0), 0),\n",
       " (datetime.datetime(2021, 12, 23, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 24, 0, 0), 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnl_sign_ts = [(pd.to_datetime(row['date_start']).to_pydatetime(), row['pnl_sign']) for  _, row in pnl.iterrows()]\n",
    "pnl_sign_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aaf278da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sr/lzvmv9j54ks_jl4x99t250r00000gn/T/ipykernel_32610/2889188127.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(source_data)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2017-09-15T23:23:53</td>\n",
       "      <td>* 15-Sep-2017 23:10:16 - S&amp;P SAYS RUSSIAN FEDE...</td>\n",
       "      <td>mmi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-09-15T23:57:58</td>\n",
       "      <td>S&amp;P\"Мы можем пересмотреть прогноз на \"стабильн...</td>\n",
       "      <td>mmi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>2017-09-16T00:01:10</td>\n",
       "      <td>Министр финансов Антон Силуанов, комментируя ж...</td>\n",
       "      <td>mmi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>2017-09-16T00:27:05</td>\n",
       "      <td>Промышленный рост – пауза продолжается\\nСтатис...</td>\n",
       "      <td>mmi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>2017-09-16T07:26:42</td>\n",
       "      <td>Оживления кредитования корпоративного сектора ...</td>\n",
       "      <td>mmi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                 date                                               text  \\\n",
       "0   8  2017-09-15T23:23:53  * 15-Sep-2017 23:10:16 - S&P SAYS RUSSIAN FEDE...   \n",
       "1  11  2017-09-15T23:57:58  S&P\"Мы можем пересмотреть прогноз на \"стабильн...   \n",
       "2  12  2017-09-16T00:01:10  Министр финансов Антон Силуанов, комментируя ж...   \n",
       "3  13  2017-09-16T00:27:05  Промышленный рост – пауза продолжается\\nСтатис...   \n",
       "4  15  2017-09-16T07:26:42  Оживления кредитования корпоративного сектора ...   \n",
       "\n",
       "  source  \n",
       "0    mmi  \n",
       "1    mmi  \n",
       "2    mmi  \n",
       "3    mmi  \n",
       "4    mmi  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate dataframes\n",
    "df = pd.DataFrame()\n",
    "\n",
    "subset = ['mmi', 'cbonds']\n",
    "\n",
    "for s in sources:\n",
    "    s = s.split('.')[0]\n",
    "    \n",
    "    if len(subset) == 0:\n",
    "        subset = sources.remove('.gitignore')\n",
    "        subset = [sub.split('.')[0] for sub in subset]\n",
    "    \n",
    "    if s in subset:\n",
    "        source_data = pd.read_csv(f'{PATH_TEXTS}/{s}')\n",
    "        source_data['source'] = s.split('.')[0]\n",
    "        df = df.append(source_data)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3d7b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_date = pnl_sign_ts[0][0]\n",
    "\n",
    "def get_pnl_sign(row):\n",
    "    date_x = pd.to_datetime(row['date']).to_pydatetime()\n",
    "    pnl_sign_key = _binary_search_by_date(pnl_sign_ts, date_x)\n",
    "    \n",
    "    if pnl_sign_key is not None and date_x >= initial_date:\n",
    "        return pnl_sign_ts[_binary_search_by_date(pnl_sign_ts, date_x)][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75961477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>pnl_sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2017-09-15T23:23:53</td>\n",
       "      <td>* 15-Sep-2017 23:10:16 - S&amp;P SAYS RUSSIAN FEDE...</td>\n",
       "      <td>mmi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-09-15T23:57:58</td>\n",
       "      <td>S&amp;P\"Мы можем пересмотреть прогноз на \"стабильн...</td>\n",
       "      <td>mmi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>2017-09-16T00:01:10</td>\n",
       "      <td>Министр финансов Антон Силуанов, комментируя ж...</td>\n",
       "      <td>mmi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>2017-09-16T00:27:05</td>\n",
       "      <td>Промышленный рост – пауза продолжается\\nСтатис...</td>\n",
       "      <td>mmi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>2017-09-16T07:26:42</td>\n",
       "      <td>Оживления кредитования корпоративного сектора ...</td>\n",
       "      <td>mmi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                 date                                               text  \\\n",
       "0   8  2017-09-15T23:23:53  * 15-Sep-2017 23:10:16 - S&P SAYS RUSSIAN FEDE...   \n",
       "1  11  2017-09-15T23:57:58  S&P\"Мы можем пересмотреть прогноз на \"стабильн...   \n",
       "2  12  2017-09-16T00:01:10  Министр финансов Антон Силуанов, комментируя ж...   \n",
       "3  13  2017-09-16T00:27:05  Промышленный рост – пауза продолжается\\nСтатис...   \n",
       "4  15  2017-09-16T07:26:42  Оживления кредитования корпоративного сектора ...   \n",
       "\n",
       "  source  pnl_sign  \n",
       "0    mmi       NaN  \n",
       "1    mmi       NaN  \n",
       "2    mmi       NaN  \n",
       "3    mmi       NaN  \n",
       "4    mmi       NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pnl_sign'] = df.apply(lambda row: get_pnl_sign(row), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a02b786d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>pnl_sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9712</td>\n",
       "      <td>2021-01-05T08:40:45</td>\n",
       "      <td>🔴 - умеренно-негативные настроения с утра: рос...</td>\n",
       "      <td>mmi</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9713</td>\n",
       "      <td>2021-01-05T08:47:00</td>\n",
       "      <td>🔴🟢 - смешанные настроения на ЕМ, небольшой рос...</td>\n",
       "      <td>mmi</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9714</td>\n",
       "      <td>2021-01-05T09:03:28</td>\n",
       "      <td>ВЕЛИКОБРИТАНИЯ ВВЕЛА ОЧЕРЕДНОЙ ЛОКДАУН За посл...</td>\n",
       "      <td>mmi</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9715</td>\n",
       "      <td>2021-01-05T09:33:54</td>\n",
       "      <td>МИРОВАЯ ПРОМЫШЛЕННОСТЬ В ДЕКАБРЕ: UNCHANGE С Н...</td>\n",
       "      <td>mmi</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9716</td>\n",
       "      <td>2021-01-05T10:12:55</td>\n",
       "      <td>ГЕРМАНИЯ: КАРАНТИН ПОКА НЕ ОКАЗАЛ ЗАМЕТНОГО ВЛ...</td>\n",
       "      <td>mmi</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                 date  \\\n",
       "0  9712  2021-01-05T08:40:45   \n",
       "1  9713  2021-01-05T08:47:00   \n",
       "2  9714  2021-01-05T09:03:28   \n",
       "3  9715  2021-01-05T09:33:54   \n",
       "4  9716  2021-01-05T10:12:55   \n",
       "\n",
       "                                                text source  pnl_sign  \n",
       "0  🔴 - умеренно-негативные настроения с утра: рос...    mmi       1.0  \n",
       "1  🔴🟢 - смешанные настроения на ЕМ, небольшой рос...    mmi       1.0  \n",
       "2  ВЕЛИКОБРИТАНИЯ ВВЕЛА ОЧЕРЕДНОЙ ЛОКДАУН За посл...    mmi       1.0  \n",
       "3  МИРОВАЯ ПРОМЫШЛЕННОСТЬ В ДЕКАБРЕ: UNCHANGE С Н...    mmi       1.0  \n",
       "4  ГЕРМАНИЯ: КАРАНТИН ПОКА НЕ ОКАЗАЛ ЗАМЕТНОГО ВЛ...    mmi       1.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=['pnl_sign'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e7f8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['id', 'date', 'pnl_sign'], axis=1)\n",
    "y = df['pnl_sign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f3545b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       🔴 - умеренно-негативные настроения с утра: рос...\n",
       "1       🔴🟢 - смешанные настроения на ЕМ, небольшой рос...\n",
       "2       ВЕЛИКОБРИТАНИЯ ВВЕЛА ОЧЕРЕДНОЙ ЛОКДАУН За посл...\n",
       "3       МИРОВАЯ ПРОМЫШЛЕННОСТЬ В ДЕКАБРЕ: UNCHANGE С Н...\n",
       "4       ГЕРМАНИЯ: КАРАНТИН ПОКА НЕ ОКАЗАЛ ЗАМЕТНОГО ВЛ...\n",
       "                              ...                        \n",
       "3312    🟢 - неплохие покупки накануне в техах (Apple, ...\n",
       "3313    🟢 - преимущественно позитивные настроения на Е...\n",
       "3314    💡Сегодня в еженедельной рубрике «Газпромбанк.М...\n",
       "3315    РОСТ ЦЕН ПРОИЗВОДИТЕЛЕЙ ПИЩЕВЫХ ПРОДУКТОВ ЗАМЕ...\n",
       "3316    ЦБ ЧЕХИИ: ПЯТОЕ ПОВЫШЕНИЕ СТАВКИ ПОДРЯД, И В М...\n",
       "Name: text, Length: 3317, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b6e3c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from functools import lru_cache\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm.gui import tqdm as tqdm_gui\n",
    "\n",
    "m = MorphAnalyzer()\n",
    "regex = re.compile(\"[а-яa-zёЁ]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return regex.findall(text.lower())\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "@lru_cache(maxsize=128)\n",
    "def lemmatize_word(token, pymorphy=m):\n",
    "    return pymorphy.parse(token)[0].normal_form\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatize_word(w) for w in text]\n",
    "\n",
    "mystopwords = stopwords.words('russian') \n",
    "def remove_stopwords(lemmas, stopwords = mystopwords):\n",
    "    return [w for w in lemmas if not w in stopwords and len(w) > 3]\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = words_only(text)\n",
    "    lemmas = lemmatize_text(tokens)\n",
    "    \n",
    "    return ' '.join(remove_stopwords(lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51c88026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09b2f9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c1abb47d984d43ad7fd356c427c022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2653 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>🔴 - преимущественно негативные настроения на Е...</td>\n",
       "      <td>mmi</td>\n",
       "      <td>преимущественно негативный настроение наиболее...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>ЭКОНОМИКА МЕКСИКИ: ПОСРЕДСТВЕННЫЕ РЕЗУЛЬТАТЫ П...</td>\n",
       "      <td>mmi</td>\n",
       "      <td>экономика мексика посредственный результат пер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>❗️ АВСТРИЯ ОБЪЯВИЛА ПОЛНЫЙ ЛОКДАУН! НА РЫНКАХ ...</td>\n",
       "      <td>mmi</td>\n",
       "      <td>австрия объявить полный локдаун рынок мощный r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>СУТОЧНАЯ ЗАБОЛЕВАЕМОСТЬ КАК В ЗАПАДНОЙ, ТАК И ...</td>\n",
       "      <td>mmi</td>\n",
       "      <td>суточный заболеваемость западный восточный евр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Группа компаний «ТФН» объявляет о размещении н...</td>\n",
       "      <td>mmi</td>\n",
       "      <td>группа компания объявлять размещение мосбиржа ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text source  \\\n",
       "2299  🔴 - преимущественно негативные настроения на Е...    mmi   \n",
       "1284  ЭКОНОМИКА МЕКСИКИ: ПОСРЕДСТВЕННЫЕ РЕЗУЛЬТАТЫ П...    mmi   \n",
       "2986  ❗️ АВСТРИЯ ОБЪЯВИЛА ПОЛНЫЙ ЛОКДАУН! НА РЫНКАХ ...    mmi   \n",
       "3013  СУТОЧНАЯ ЗАБОЛЕВАЕМОСТЬ КАК В ЗАПАДНОЙ, ТАК И ...    mmi   \n",
       "287   Группа компаний «ТФН» объявляет о размещении н...    mmi   \n",
       "\n",
       "                                                 lemmas  \n",
       "2299  преимущественно негативный настроение наиболее...  \n",
       "1284  экономика мексика посредственный результат пер...  \n",
       "2986  австрия объявить полный локдаун рынок мощный r...  \n",
       "3013  суточный заболеваемость западный восточный евр...  \n",
       "287   группа компания объявлять размещение мосбиржа ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas = list(tqdm(map(clean_text, X_train['text']), total=len(X_train)))\n",
    "\n",
    "X_train['lemmas'] = lemmas\n",
    "X_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7159b314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9545678644544df96f5c7dc16c3888a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/664 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lemmas_val = list(tqdm(map(clean_text, X_val['text']), total=len(X_val)))\n",
    "\n",
    "X_val['lemmas'] = lemmas_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84cde13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2653, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e76422a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73892cf9e68456c8d001fee1e15a0f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2653 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train done\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "X_train['embedding'] = X_train['lemmas'].progress_apply(lambda x: get_tweet_embedding(x, model=ft))\n",
    "print('train done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4b9cb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61aa5ef85c14031ba27e8236e8c38a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/664 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "X_val['embedding'] = X_val['lemmas'].progress_apply(lambda x: get_tweet_embedding(x, model=ft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c58229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedding = np.array(list(X_train['embedding'].values))\n",
    "val_embedding = np.array(list(X_val['embedding'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ca0cbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5446664153788164"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = LogisticRegression(random_state=12)\n",
    "clf.fit(train_embedding, y_train)\n",
    "clf.score(train_embedding, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfae93e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score = 0.5406626506024096\n",
      "Balance = 0.536\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(val_embedding)\n",
    "score = accuracy_score(pred, y_val)\n",
    "print(f'Score = {score}')\n",
    "print(f'Balance = {balance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1ae4906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score = 0.5240963855421686\n",
      "Balance = 0.536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_features=4, n_estimators=50)\n",
    "\n",
    "rf.fit(train_embedding, y_train)\n",
    "\n",
    "score = (y_val == rf.predict(val_embedding)).mean()\n",
    "print(f'Score = {score}')\n",
    "print(f'Balance = {balance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53f27bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be681702eac148c79255cf6893553323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x110f75de0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import catboost as cb\n",
    "\n",
    "np.random.seed(12)\n",
    "\n",
    "params = dict(\n",
    "    learning_rate=0.025,\n",
    "    iterations=10000,\n",
    "    reg_lambda=0.0005,\n",
    "    colsample_bylevel=1.,\n",
    "    max_bin=80,\n",
    "    bagging_temperature=2,\n",
    "    use_best_model=True,\n",
    "    verbose=False,\n",
    "    grow_policy='Depthwise',\n",
    "    random_seed=12\n",
    ")\n",
    "model = cb.CatBoostClassifier(\n",
    "    **params,\n",
    ")\n",
    "\n",
    "eval_set = cb.Pool(data=val_embedding, label=y_val)\n",
    "model.fit(train_embedding, y_train, eval_set=eval_set, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f69c134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score = 0.5180722891566265\n",
      "Balance = 0.536\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(val_embedding)\n",
    "score = accuracy_score(pred, y_val)\n",
    "print(f'Score = {score}')\n",
    "print(f'Balance = {balance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8de8b7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba8c145b3274f90adb1ad4aae8ca7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3317 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lemmas = list(tqdm(map(clean_text, df['text']), total=len(df)))\n",
    "\n",
    "df['lemmas'] = lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "344297db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(df, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a423224",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_ft.txt', 'w') as f:\n",
    "    for label, lemmas in list(zip(\n",
    "        y_train, X_train['lemmas']\n",
    "    )):\n",
    "        f.write(f\"__label__{int(label)} {lemmas}\\n\")\n",
    "        #print(f\"__label__{int(label)} {lemmas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25163fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__0 сдержать момент настроение большинство сегмент российский актив некоторый ухудшение геополитический повестка взаимный высылка дипломат чехия очевидный большой экономический подтекст связанный недопуск росатом тендер строительство возможный новый акция протест оппозиция наметить неделя время moody отмечать иметься буфер капитал россия небольшой потребность привлечение заёмный средство расширить политический инструментарий позволить страна справиться внезапно возникнуть негативный эффект возможный санкция market sentiment index\r\n",
      "__label__0 погрузка октябрь годовой динамика несколько ухудшиться счёт сокращение темп угол строительный груз зерно согласно оперативный данные итог октябрь объём погрузка составить тонна весь большой аналогичный показатель прошлое сентябрь август занимать первый место объём уголь итог январь октябрь показать позитивный динамика месяц ранее нефть нефтепродукт промсырьё удобрение лесной груз кокс металлолом цемент чёрный металл контейнер позиция минус строительный груз химикат сода цветной руда зерно годовой сопоставление\r\n",
      "__label__1 первый помесячный дефляция еврозона согласно финальный оценка eurostat потребительский цена страна еврозона сократиться июль июнь годовой исчисление увеличение составить июнь цифра соответствие ожидание данный момент считать текущий рост цена временной явление риторика регулятор оставаться достаточно dovish отношение основной фактор рост мнение являться основное разовый цена энергоноситель повышение налог германия статистический последствие пандемия covid динамика ведущий экономика германия показывать некоторый усиление инфляционный тренд https russianmacro\r\n",
      "__label__0 понижательный тренд смертность москва несколько приостановилсяроссия заболеть сутки предыдущий пара день умерший последний день москва вчера предыдущий двое сутки умерший последний день количество тест вчера день назад\r\n",
      "__label__1 глубоко хотеть погрузиться вопрос денежный кредитный политика очень рекомендовать обстоятельный длинный выступление зампред алексей заботкин начало минилекция алексей подробно рассказывать идеология набор профессиональный вопрос взгляд исчерпывающий охватывать самый актуальный тема макроэкономический политика сожаление алексей место говорить сложно поэтому непонятно задавать вопрос russianmacro попробовать объяснить https youtube watch okqkx\r\n",
      "__label__0 расти цена нефть накануне запас топливо версия снизиться пока способствовать покупка акция динамика основный бумага довольно разнонаправленный повторный приближение максимум индекс часть инвестор видимо предпочитать зафиксировать прибыль также возобновиться продажа сегмент локальный госдолг время рубль чувствовать довольно неплохо месячный волатильность продолжать снижаться\r\n",
      "__label__0 баланс очедедный максимум сигнал федрезерв план сворачивание указывать начало баланс федеральный резерв последний неделя увеличиться млрд снижение млрд ранее ключевой момент корректировка объём срок скупка актив федрезерв представитель который полагать начало обсуждение постепенный сворачивание стимулирование необходимо начинать время регулятор продолжать считать нынешний уровень инфляция временной явление сворачивание стимулирование начаться достигнуть цель полный занятость считать мочь восстановить полный занятость конец уместно рассмотреть сворачивание экстренный стимулирование начало\r\n",
      "__label__0 разовый компенсация пенсионер следовать сделать зависимость выборы разовый выплата пенсионер являться новация последний начало выплатить частично компенсировать случиться кризис всплеск инфляция реальный выражение пенсия выше ниже пиковый значение пенсия реальный выражение начать снижаться https russianmacro вообще главный критерий успешность пенсионный политика являться столько рост реальный пенсия сколько удержание менее стабильный соотношение зарплата пенсия мота рекомендовать соотношение уровень дотягивать правый граф показатель устойчивый падать опуститься ниже пандемия ускорить тренд разовый выплата приостановить падение соотношение вряд развернуть тренд макроэффект выплата читать канал утро\r\n",
      "__label__1 динамика ввод жильё помесячный темп понизиться отношение последний данные росстат рост темп ввод жильё квадратный метр годовой сопоставление сохраняться двузначный несколько скромный апрель сравнение рост также сократиться составить апрель сравнение показательно статистика добавить дачный домик ажиотажный спрос недвижимость подпитываться пока повсеместно действовать программа льготный ипотека который несколько скорректировать вчерашний день данный момент рынок присутствовать дисбаланс спрос предложение выливаться продолжаться рост цена\r\n",
      "__label__0 сегодня еженедельный рубрика газпромбанк мнение рассказывать насколько интересный высокодоходный еврооблигация таджикистан условие низкий ставка ведущий мировой центробанк оценивать рынок перспективный инструмент читать ссылка\r\n"
     ]
    }
   ],
   "source": [
    "!tail train_ft.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "996c9c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Read 0M words\n",
      "Number of words:  8625\n",
      "Number of labels: 2\n",
      "\r",
      "Progress: 100.1% words/sec/thread: 1128841 lr: -0.000069 avg.loss:  0.694911 ETA:   0h 0m 0s\r",
      "Progress: 100.0% words/sec/thread: 1127883 lr:  0.000000 avg.loss:  0.694911 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "classifier = fasttext.train_supervised('train_ft.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9371ecc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score = 0.5406626506024096\n",
      "Balance = 0.536\n"
     ]
    }
   ],
   "source": [
    "pred = classifier.predict(list(X_val['lemmas']))[0]\n",
    "pred = [int(label[0][-1]) for label in pred]\n",
    "\n",
    "score = accuracy_score(pred, y_val)\n",
    "print(f'Score = {score}')\n",
    "print(f'Balance = {balance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd1fef11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 797 ms, sys: 8.19 ms, total: 805 ms\n",
      "Wall time: 257 ms\n"
     ]
    }
   ],
   "source": [
    "tokenized_tweets = [tweet.split() for tweet in train['lemmas'].values]\n",
    "\n",
    "%time w2v = word2vec.Word2Vec(tokenized_tweets, workers=4, vector_size=200, min_count=10, window=3, sample=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cfed6754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('цена', 0.9429660439491272),\n",
       " ('потребительский', 0.9428662657737732),\n",
       " ('динамика', 0.9409146904945374),\n",
       " ('производитель', 0.9314670562744141),\n",
       " ('ускориться', 0.9179934859275818),\n",
       " ('замедление', 0.9148222208023071),\n",
       " ('темп', 0.9046868681907654),\n",
       " ('энергоноситель', 0.9022824764251709),\n",
       " ('расход', 0.8981800079345703),\n",
       " ('сгладить', 0.8910050392150879)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(positive=['рост'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0ee7fb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_embedding(lemmas, model=w2v.wv, embedding_size=200):\n",
    "    \n",
    "    res = np.zeros(embedding_size)\n",
    "    cnt = 0\n",
    "    for word in lemmas.split():\n",
    "        if word in model:\n",
    "            res += np.array(model[word])\n",
    "            cnt += 1\n",
    "    if cnt:\n",
    "        res = res / cnt\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a1c181c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['w2v_embedding'] = X_train['lemmas'].map(get_tweet_embedding)\n",
    "X_val['w2v_embedding'] = X_val['lemmas'].map(get_tweet_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4694775",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w2v = list(X_train['w2v_embedding'].values)\n",
    "val_w2v = list(X_val['w2v_embedding'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f10b33c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score = 0.5421686746987951\n",
      "Balance = 0.536\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=12, max_iter=500)\n",
    "clf.fit(train_w2v, y_train)\n",
    "\n",
    "pred = clf.predict(val_w2v)\n",
    "\n",
    "score = accuracy_score(pred, y_val)\n",
    "print(f'Score = {score}')\n",
    "print(f'Balance = {balance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedb13e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_features=4, n_estimators=50)\n",
    "\n",
    "rf.fit(train_w2v, y_train)\n",
    "\n",
    "score = (y_val == rf.predict(val_w2v)).mean()\n",
    "print(f'Score = {score}')\n",
    "print(f'Balance = {balance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "069e738a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260a32e24be24193b61280afa2296f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x43e3bdcc0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import catboost as cb\n",
    "\n",
    "np.random.seed(12)\n",
    "\n",
    "params = dict(\n",
    "    learning_rate=0.025,\n",
    "    iterations=10000,\n",
    "    reg_lambda=0.0005,\n",
    "    colsample_bylevel=1.,\n",
    "    max_bin=80,\n",
    "    bagging_temperature=2,\n",
    "    use_best_model=True,\n",
    "    verbose=False,\n",
    "    grow_policy='Depthwise',\n",
    "    random_seed=12\n",
    ")\n",
    "model = cb.CatBoostClassifier(\n",
    "    **params,\n",
    ")\n",
    "\n",
    "eval_set = cb.Pool(data=val_w2v, label=y_val)\n",
    "model.fit(train_w2v, y_train, eval_set=eval_set, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2145fc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score = 0.5391566265060241\n",
      "Balance = 0.536\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(val_w2v)\n",
    "\n",
    "score = accuracy_score(pred, y_val)\n",
    "print(f'Score = {score}')\n",
    "print(f'Balance = {balance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2f5e4e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm  \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim import utils\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "\n",
    "# import dlnlputils\n",
    "# from dlnlputils.data import tokenize_text_simple_regex, tokenize_corpus, build_vocabulary, \\\n",
    "#     vectorize_texts, SparseFeaturesDataset\n",
    "# from dlnlputils.pipeline import train_eval_loop, predict_with_model, init_random_seed\n",
    "\n",
    "# init_random_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "86569712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "TOKEN_RE = re.compile(r'[\\w\\d]+')\n",
    "\n",
    "\n",
    "def tokenize_text_simple_regex(txt, min_token_size=4):\n",
    "    txt = txt.lower()\n",
    "    all_tokens = TOKEN_RE.findall(txt)\n",
    "    return [token for token in all_tokens if len(token) >= min_token_size]\n",
    "\n",
    "\n",
    "def character_tokenize(txt):\n",
    "    return list(txt)\n",
    "\n",
    "\n",
    "def tokenize_corpus(texts, tokenizer=tokenize_text_simple_regex, **tokenizer_kwargs):\n",
    "    return [tokenizer(text, **tokenizer_kwargs) for text in texts]\n",
    "\n",
    "\n",
    "def add_fake_token(word2id, token=''):\n",
    "    word2id_new = {token: i + 1 for token, i in word2id.items()}\n",
    "    word2id_new[token] = 0\n",
    "    return word2id_new\n",
    "\n",
    "\n",
    "def texts_to_token_ids(tokenized_texts, word2id):\n",
    "    return [[word2id[token] for token in text if token in word2id]\n",
    "            for text in tokenized_texts]\n",
    "\n",
    "\n",
    "def build_vocabulary(tokenized_texts, max_size=1000000, max_doc_freq=0.8, min_count=5, pad_word=None):\n",
    "    word_counts = collections.defaultdict(int)\n",
    "    doc_n = 0\n",
    "\n",
    "    # посчитать количество документов, в которых употребляется каждое слово\n",
    "    # а также общее количество документов\n",
    "    for txt in tokenized_texts:\n",
    "        doc_n += 1\n",
    "        unique_text_tokens = set(txt)\n",
    "        for token in unique_text_tokens:\n",
    "            word_counts[token] += 1\n",
    "\n",
    "    # убрать слишком редкие и слишком частые слова\n",
    "    word_counts = {word: cnt for word, cnt in word_counts.items()\n",
    "                   if cnt >= min_count and cnt / doc_n <= max_doc_freq}\n",
    "\n",
    "    # отсортировать слова по убыванию частоты\n",
    "    sorted_word_counts = sorted(word_counts.items(),\n",
    "                                reverse=True,\n",
    "                                key=lambda pair: pair[1])\n",
    "\n",
    "    # добавим несуществующее слово с индексом 0 для удобства пакетной обработки\n",
    "    if pad_word is not None:\n",
    "        sorted_word_counts = [(pad_word, 0)] + sorted_word_counts\n",
    "\n",
    "    # если у нас по прежнему слишком много слов, оставить только max_size самых частотных\n",
    "    if len(word_counts) > max_size:\n",
    "        sorted_word_counts = sorted_word_counts[:max_size]\n",
    "\n",
    "    # нумеруем слова\n",
    "    word2id = {word: i for i, (word, _) in enumerate(sorted_word_counts)}\n",
    "\n",
    "    # нормируем частоты слов\n",
    "    word2freq = np.array([cnt / doc_n for _, cnt in sorted_word_counts], dtype='float32')\n",
    "\n",
    "    return word2id, word2freq\n",
    "\n",
    "\n",
    "PAD_TOKEN = '__PAD__'\n",
    "NUMERIC_TOKEN = '__NUMBER__'\n",
    "NUMERIC_RE = re.compile(r'^([0-9.,e+\\-]+|[mcxvi]+)$', re.I)\n",
    "\n",
    "\n",
    "def replace_number_nokens(tokenized_texts):\n",
    "    return [[token if not NUMERIC_RE.match(token) else NUMERIC_TOKEN for token in text]\n",
    "            for text in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d1e0c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "def vectorize_texts(tokenized_texts, word2id, word2freq, mode='tfidf', scale=True):\n",
    "    assert mode in {'tfidf', 'idf', 'tf', 'bin'}\n",
    "\n",
    "    # считаем количество употреблений каждого слова в каждом документе\n",
    "    result = scipy.sparse.dok_matrix((len(tokenized_texts), len(word2id)), dtype='float32')\n",
    "    for text_i, text in enumerate(tokenized_texts):\n",
    "        for token in text:\n",
    "            if token in word2id:\n",
    "                result[text_i, word2id[token]] += 1\n",
    "\n",
    "    # получаем бинарные вектора \"встречается или нет\"\n",
    "    if mode == 'bin':\n",
    "        result = (result > 0).astype('float32')\n",
    "\n",
    "    # получаем вектора относительных частот слова в документе\n",
    "    elif mode == 'tf':\n",
    "        result = result.tocsr()\n",
    "        result = result.multiply(1 / result.sum(1))\n",
    "\n",
    "    # полностью убираем информацию о количестве употреблений слова в данном документе,\n",
    "    # но оставляем информацию о частотности слова в корпусе в целом\n",
    "    elif mode == 'idf':\n",
    "        result = (result > 0).astype('float32').multiply(1 / word2freq)\n",
    "\n",
    "    # учитываем всю информацию, которая у нас есть:\n",
    "    # частоту слова в документе и частоту слова в корпусе\n",
    "    elif mode == 'tfidf':\n",
    "        result = result.tocsr()\n",
    "        result = result.multiply(1 / result.sum(1))  # разделить каждую строку на её длину\n",
    "        result = result.multiply(1 / word2freq)  # разделить каждый столбец на вес слова\n",
    "\n",
    "    if scale:\n",
    "        result = result.tocsc()\n",
    "        result -= result.min()\n",
    "        result /= (result.max() + 1e-6)\n",
    "\n",
    "    return result.tocsr()\n",
    "\n",
    "\n",
    "class SparseFeaturesDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cur_features = torch.from_numpy(self.features[idx].toarray()[0]).float()\n",
    "        cur_label = torch.from_numpy(np.asarray(self.targets[idx])).long()\n",
    "        return cur_features, cur_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a3793d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = tokenize_corpus(X_train['text'])\n",
    "val_tokenized = tokenize_corpus(X_val['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "395e4250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "фьючерс p500 торгуется сегодня небольшом плюсе уверенно держится нефть восстановление добычи мексиканском заливе идет гораздо более медленными ожидалось темпами нефтяных платформ остаются закрытыми азиатские площадки некоторым давлением власти китая предъявили регуляторные претензии alipay может поставить сомнение полноценную дальнейшую деятельность этого платежного сервиса market sentiment index\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(train_tokenized[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79a12687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных токенов 5135\n",
      "[('рост', 0), ('года', 1), ('ранее', 2), ('последние', 3), ('роста', 4), ('также', 5), ('более', 6), ('довольно', 7), ('https', 8), ('сутки', 9)]\n"
     ]
    }
   ],
   "source": [
    "# строим словарь - vocabulary с помощью функции build_vocabulary\n",
    "# принимает на вход список списков токенезированные\n",
    "# word_doc_freq - содержит относительные частоты всех слов в датасете, он понадобиться \n",
    "# на этапе формирования матрицы признаков\n",
    "\n",
    "MAX_DF = 0.8 #во скольких документах встречаеться слово\n",
    "MIN_COUNT = 5 # сколько раз слово встречаеться в тексте\n",
    "\n",
    "\n",
    "vocabulary, word_doc_freq = build_vocabulary(train_tokenized, max_doc_freq=MAX_DF, min_count=MIN_COUNT)\n",
    "UNIQUE_WORDS_N = len(vocabulary)\n",
    "print('Количество уникальных токенов', UNIQUE_WORDS_N)\n",
    "print(list(vocabulary.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3ebd3e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(word_doc_freq, bins=20)\n",
    "plt.title('Распределение относительных частот слов')\n",
    "plt.yscale('log');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed0faaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность матрицы признаков обучающей выборки (2653, 5135)\n",
      "\n",
      "Количество ненулевых элементов в обучающей выборке 127164\n",
      "Процент заполненности матрицы признаков 0.93%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "VECTORIZATION_MODE = 'tfidf'\n",
    "# построение матрицы признаков по методу мешка слов\n",
    "# функция vectorize_texts принимает на вход\n",
    "#1. токенизированные список списков\n",
    "#2. словарь\n",
    "#3. вектор частоты токенизированны\n",
    "#4. алгоритм взвешивания токенов по частоте mode - есть 4 алгорима - bin,tf,idf,tfidf\n",
    "#5. флаг чтобы перемаштабировать флаг после взвешивания\n",
    "\n",
    "train_vectors = vectorize_texts(train_tokenized, vocabulary, word_doc_freq, mode=VECTORIZATION_MODE)\n",
    "\n",
    "print('Размерность матрицы признаков обучающей выборки', train_vectors.shape)\n",
    "print()\n",
    "print('Количество ненулевых элементов в обучающей выборке', train_vectors.nnz)\n",
    "print('Процент заполненности матрицы признаков {:.2f}%'.format(train_vectors.nnz * 100 / (train_vectors.shape[0] * train_vectors.shape[1])))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "686d2508",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_t = api.load('glove-twitter-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7aa419ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "\n",
    "def get_vectors_gt100(row):\n",
    "    '''\n",
    "      word_doc_freq # частоты слов\n",
    "      train_tokenized #сами слова\n",
    "    '''\n",
    "    vecs = [np.zeros(100)]\n",
    "    for word in row:\n",
    "        #print(row)\n",
    "        try: \n",
    "            # если слово есть в нашем очищенном словаре\n",
    "            # умножаем вектор на вес tfidf\n",
    "            v = model_t[word] * word_doc_freq[vocabulary[word]] \n",
    "        except:\n",
    "            v = np.zeros(100)\n",
    "        vecs.append(v)\n",
    "    return np.sum(np.array(vecs),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1d2e5892",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gt100 = np.array([get_vectors_gt100(i) for i in train_tokenized])\n",
    "val_gt100 = np.array([get_vectors_gt100(i) for i in val_tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2730d1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('аналитик', 0.7176759243011475)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_t.most_similar(positive=['инвестор', 'рынок'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ddd22560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score = 0.5301204819277109\n",
      "Balance = 0.536\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=12, max_iter=500)\n",
    "clf.fit(train_gt100, y_train)\n",
    "\n",
    "pred = clf.predict(val_gt100)\n",
    "\n",
    "score = accuracy_score(pred, y_val)\n",
    "print(f'Score = {score}')\n",
    "print(f'Balance = {balance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda2eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_features=4, n_estimators=50)\n",
    "\n",
    "rf.fit(train_gt100, y_train)\n",
    "\n",
    "score = (y_val == rf.predict(val_gt100)).mean()\n",
    "print(f'Score = {score}')\n",
    "print(f'Balance = {balance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d2c095ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1ed018c21c48a899e7f65096b7c063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x4627c3b20>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import catboost as cb\n",
    "\n",
    "np.random.seed(12)\n",
    "\n",
    "params = dict(\n",
    "    learning_rate=0.025,\n",
    "    iterations=10000,\n",
    "    reg_lambda=0.0005,\n",
    "    colsample_bylevel=1.,\n",
    "    max_bin=80,\n",
    "    bagging_temperature=2,\n",
    "    use_best_model=True,\n",
    "    verbose=False,\n",
    "    grow_policy='Depthwise',\n",
    "    random_seed=12\n",
    ")\n",
    "model = cb.CatBoostClassifier(\n",
    "    **params,\n",
    ")\n",
    "\n",
    "eval_set = cb.Pool(data=val_gt100, label=y_val)\n",
    "model.fit(train_gt100, y_train, eval_set=eval_set, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "81132739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score = 0.5512048192771084\n",
      "Balance = 0.536\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(val_gt100)\n",
    "\n",
    "score = accuracy_score(pred, y_val)\n",
    "print(f'Score = {score}')\n",
    "print(f'Balance = {balance}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
