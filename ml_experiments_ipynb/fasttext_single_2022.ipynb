{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8495324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0da7883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f6ee630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm>=4.9.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.63.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install \"tqdm>=4.9.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "386b2622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fasttext==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fcbc498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/facebookresearch/fastText.git\n",
    "# !cd fastText\n",
    "# !pip install fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42d28100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ccf1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e0f7322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function download_model in module fasttext.util.util:\n",
      "\n",
      "download_model(lang_id, if_exists='strict', dimension=None)\n",
      "    Download pre-trained common-crawl vectors from fastText's website\n",
      "    https://fasttext.cc/docs/en/crawl-vectors.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(fasttext.util.download_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34cdbfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# fasttext.util.download_model('ru', if_exists='ignore')\n",
    "ft = fasttext.load_model('cc.ru.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5b2382c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06434693, -0.01527086, -0.06963537, -0.03582602,  0.01471584,\n",
       "       -0.03503159,  0.02701715,  0.04161827, -0.00033126,  0.00355259,\n",
       "        0.06979205,  0.06205348,  0.05154078,  0.03831509, -0.02394784,\n",
       "       -0.03954181, -0.00189653, -0.11174394, -0.0407712 ,  0.09289949,\n",
       "       -0.07412342, -0.05209147,  0.02017231,  0.04837443,  0.02212641,\n",
       "        0.00856511, -0.03055364,  0.04733564,  0.04380886,  0.03856769,\n",
       "        0.03442968,  0.05576854,  0.01513439,  0.14055566,  0.03365337,\n",
       "       -0.02920472, -0.10305687, -0.09332671,  0.03085899, -0.11067575,\n",
       "       -0.08992791,  0.05850704, -0.017424  ,  0.00120653, -0.07153153,\n",
       "        0.10312843, -0.08066262, -0.00642456,  0.04408539, -0.05728461,\n",
       "       -0.0179531 ,  0.03936698,  0.04778077, -0.04907751, -0.00909553,\n",
       "        0.05588715, -0.00236535,  0.04878682, -0.01769035,  0.03295048,\n",
       "        0.00906604,  0.08772802,  0.02970458, -0.04903899, -0.03025401,\n",
       "       -0.04151824,  0.04931813, -0.02804473,  0.05716789,  0.03559401,\n",
       "       -0.12191223,  0.02087349, -0.05121018, -0.0584691 , -0.04781278,\n",
       "       -0.06298476, -0.00432743, -0.03785646, -0.08833752, -0.0375172 ,\n",
       "        0.04602968,  0.02096615,  0.00321184, -0.00927999, -0.00288017,\n",
       "        0.04345381, -0.0330169 ,  0.00840916, -0.05537616, -0.02134524,\n",
       "       -0.03705332,  0.06453154, -0.01733523, -0.01977487, -0.02836509,\n",
       "        0.01901042,  0.04043126, -0.07048826, -0.09381784, -0.02532577,\n",
       "       -0.02679786,  0.01097633, -0.01681483, -0.08134623,  0.00429079,\n",
       "       -0.07213577, -0.03950587,  0.07274695, -0.00337509,  0.05469057,\n",
       "       -0.01510826, -0.05297935,  0.04232059, -0.04494021, -0.01873806,\n",
       "        0.02970697, -0.02128338, -0.07461107,  0.04457341,  0.02913763,\n",
       "       -0.05406609,  0.06825955, -0.0423348 , -0.01933457,  0.00638132,\n",
       "        0.00075826,  0.10154837, -0.06699109, -0.01374834,  0.10683898,\n",
       "        0.06719182,  0.00299954,  0.03092229, -0.01919586,  0.02315286,\n",
       "        0.02552165,  0.0297376 ,  0.0476847 , -0.06794806,  0.01934321,\n",
       "        0.07793375,  0.04631811,  0.07487484, -0.06923444, -0.09797966,\n",
       "       -0.02230856,  0.04383751,  0.05814477,  0.09182699,  0.0407513 ,\n",
       "        0.06562199,  0.06420117, -0.12618978, -0.00895569, -0.03637737,\n",
       "        0.0323772 ,  0.05442533,  0.02233687,  0.0607053 , -0.03511162,\n",
       "       -0.02011008, -0.04657565, -0.1363746 , -0.09366813, -0.01257268,\n",
       "       -0.0822741 ,  0.04026463,  0.08941573,  0.05416025, -0.00148568,\n",
       "        0.02470817, -0.01521165,  0.06688396,  0.01970377, -0.067048  ,\n",
       "        0.05173868, -0.06437217,  0.02638604,  0.02355881, -0.03286408,\n",
       "       -0.01542088,  0.0226214 ,  0.01009578, -0.06503511,  0.05164307,\n",
       "        0.08621447, -0.00291589,  0.0201317 ,  0.05789564,  0.04330945,\n",
       "       -0.01468945,  0.00915974,  0.02692279,  0.07124459, -0.05370982,\n",
       "        0.04218086,  0.00314814,  0.00356758, -0.02068229,  0.0604349 ,\n",
       "       -0.08158811,  0.04939371,  0.0430281 , -0.03372736, -0.0558867 ,\n",
       "        0.00376545, -0.037087  ,  0.05940549,  0.02495521, -0.00334628,\n",
       "        0.01005986, -0.02053031,  0.01179219,  0.07010209, -0.10397089,\n",
       "        0.07733957,  0.06056703,  0.01003617, -0.15787463, -0.01765688,\n",
       "        0.00765593, -0.01905038,  0.01327723,  0.01084452, -0.05930451,\n",
       "       -0.07062402, -0.08540855,  0.01374613, -0.03077546, -0.04025275,\n",
       "        0.00268231, -0.06844234,  0.05945092,  0.02234607,  0.14669767,\n",
       "        0.03161074, -0.03626112,  0.13065669, -0.02795461,  0.00260858,\n",
       "        0.02103085, -0.01555263,  0.02790887, -0.02395738, -0.10259839,\n",
       "       -0.01162906,  0.07939966,  0.01229805,  0.0472665 ,  0.00792722,\n",
       "        0.07495239, -0.04777352,  0.02290227, -0.02349729, -0.01035224,\n",
       "       -0.04128299, -0.05037197, -0.02936148, -0.03995599, -0.09582971,\n",
       "        0.00652219, -0.00309965,  0.09921778, -0.07993053, -0.07525942,\n",
       "       -0.03148453, -0.03216294,  0.00986726, -0.03059178, -0.01402058,\n",
       "        0.02519003, -0.04734642,  0.12286284, -0.09953459,  0.01202545,\n",
       "        0.03934894,  0.07455902,  0.02744922,  0.03999532, -0.05147249,\n",
       "       -0.0055727 ,  0.07064351,  0.07526451,  0.00223117,  0.01765039,\n",
       "       -0.02785274,  0.0251571 ,  0.05081079,  0.06183068, -0.03087618,\n",
       "       -0.00268458, -0.02822061, -0.05344585, -0.05139395,  0.00151552,\n",
       "       -0.01931686,  0.00034288, -0.01423903,  0.00377267, -0.0598783 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft['привет']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2fecc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "def get_tweet_embedding(lemmas, model, embedding_size=300):\n",
    "    \n",
    "    res = np.zeros(embedding_size)\n",
    "    cnt = 0\n",
    "    for word in lemmas.split():\n",
    "        if word in model:\n",
    "            res += np.array(model[word])\n",
    "            cnt += 1\n",
    "    if cnt:\n",
    "        res = res / cnt\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17ef304c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.84749218e-02,  1.14055865e-02, -1.54750008e-02,  6.10717852e-03,\n",
       "       -5.42343501e-03,  2.83443742e-03,  2.40256451e-03,  1.29073053e-02,\n",
       "        3.05031866e-02, -1.99234379e-02,  6.13203850e-02,  4.42768331e-02,\n",
       "        2.71531800e-02, -1.02064133e-02,  9.22483567e-04,  2.50384058e-02,\n",
       "       -1.25383004e-02, -4.89095808e-02, -3.07890818e-02,  1.01918663e-01,\n",
       "       -2.85800546e-02, -1.05811988e-01, -1.28629373e-02,  2.95597422e-02,\n",
       "        2.13206490e-03,  1.26906892e-02, -2.97227059e-02,  2.77029723e-02,\n",
       "       -1.21254625e-02, -4.76178443e-02, -6.68591424e-03,  3.05985650e-02,\n",
       "        3.59081652e-02,  1.02970391e-01,  3.62780495e-02, -5.56655712e-02,\n",
       "       -1.11200343e-01, -1.16946280e-01,  4.69890856e-02, -5.79430675e-02,\n",
       "       -4.56299540e-03, -2.32621958e-03, -2.30524363e-03,  1.96370891e-02,\n",
       "       -1.68996924e-02,  4.77626729e-02, -7.71877861e-02,  2.95996453e-02,\n",
       "        3.40769021e-02, -3.43663241e-02,  5.55797149e-02,  1.05126291e-02,\n",
       "        9.77615127e-03,  3.99762448e-02, -2.15159254e-02,  1.93620831e-02,\n",
       "       -1.34500194e-02,  2.17238814e-03,  1.39238648e-02, -1.24853794e-02,\n",
       "       -5.08000248e-02,  6.46954067e-02,  3.07824350e-02, -4.07074159e-02,\n",
       "       -1.99913508e-02,  1.96010725e-02, -1.52623175e-02, -1.58499312e-02,\n",
       "       -4.72955415e-02,  4.77682170e-03, -5.21384678e-02,  3.73177927e-02,\n",
       "       -3.41336881e-02,  5.90577209e-03,  6.41630217e-03, -2.70765051e-02,\n",
       "       -5.57585534e-02, -9.87857254e-03, -1.75393135e-02, -3.92743144e-02,\n",
       "        2.59191706e-02,  3.97690022e-02,  5.75262937e-03, -4.60929359e-02,\n",
       "        3.89499759e-03,  3.79725420e-02, -6.47511277e-02,  5.06016524e-02,\n",
       "        1.29573480e-02,  9.16208606e-04, -1.10791333e-01, -1.59734851e-02,\n",
       "        4.38956684e-03, -5.00591882e-02, -1.91273557e-02, -1.31234950e-02,\n",
       "        4.23284452e-02, -1.32317897e-02, -9.03501306e-02,  4.14077961e-02,\n",
       "       -9.01901850e-03,  7.61899361e-02, -1.04387742e-02, -1.22785277e-02,\n",
       "       -1.63511078e-02, -3.89259742e-02,  4.25888405e-02,  2.55549918e-02,\n",
       "        7.98778998e-03,  9.49782273e-03, -3.10476529e-02, -1.09063331e-02,\n",
       "        8.43151626e-02, -3.58087434e-02, -1.24211812e-02, -1.87083688e-02,\n",
       "       -5.45124998e-02, -8.86561619e-02,  3.79863534e-02, -3.31068560e-02,\n",
       "       -4.89519509e-02,  7.88756466e-02, -5.50974393e-02,  1.60968699e-02,\n",
       "        1.01266545e-03,  2.75706507e-02,  5.04551297e-02, -1.64009025e-02,\n",
       "        1.19224258e-02,  6.78465860e-02,  2.69761501e-02,  1.12457192e-02,\n",
       "        1.86175751e-02, -1.40191410e-02, -1.72757215e-02,  5.70655339e-02,\n",
       "        5.77574829e-04,  5.24380505e-02, -5.08161918e-03,  3.53807122e-02,\n",
       "       -1.40902330e-02,  2.29508245e-02,  6.68836981e-02, -2.08306434e-02,\n",
       "       -5.37150722e-02, -9.75077925e-03, -4.46044868e-02,  3.50373158e-02,\n",
       "        5.37473205e-02,  2.23793560e-02,  3.78368636e-02,  1.91988172e-02,\n",
       "       -9.24861385e-02,  1.07819675e-02, -1.21989548e-02,  3.31418150e-02,\n",
       "        2.23143799e-02,  1.49282608e-02,  1.40205264e-02, -2.72367133e-02,\n",
       "       -2.69449629e-02,  2.49509839e-03, -5.19380664e-02, -6.78124642e-02,\n",
       "       -6.38052975e-02,  1.68222875e-02, -7.74696337e-02,  8.44685482e-02,\n",
       "        4.74610087e-02, -2.62326931e-03, -9.03137206e-03, -6.54254213e-02,\n",
       "        4.35586069e-02,  3.72354283e-02, -3.41950073e-02, -1.16772181e-02,\n",
       "       -3.14856721e-02,  6.10582798e-02,  4.79020393e-02, -4.82062241e-02,\n",
       "       -1.99088580e-02,  3.10592290e-02, -4.53291640e-02, -6.53951182e-02,\n",
       "        6.01363019e-04,  3.27027021e-02,  1.47671076e-02, -3.70643544e-02,\n",
       "       -2.04997172e-02,  5.32348915e-02, -4.50411410e-02,  1.28656339e-02,\n",
       "        3.19320844e-02,  1.45057300e-02, -1.72404865e-02,  3.71150244e-02,\n",
       "       -2.15479551e-02, -1.15545052e-02, -1.25362631e-02,  2.60218652e-02,\n",
       "       -4.58280314e-02,  7.53374584e-03,  7.35389721e-03, -1.82377142e-02,\n",
       "       -9.48007656e-02, -2.56354164e-02,  5.40375593e-04,  4.41152531e-02,\n",
       "       -7.10717402e-04,  4.32135077e-03,  2.78144046e-02, -4.11721691e-03,\n",
       "       -8.98516446e-04,  5.58417288e-02, -3.63211357e-02, -6.08586776e-03,\n",
       "        3.32013650e-02,  3.86003682e-02, -4.08708490e-02,  1.05813891e-02,\n",
       "        1.79253643e-02,  3.97888436e-02,  3.22979216e-02,  1.34046650e-02,\n",
       "       -3.69763831e-02,  3.80074000e-02, -3.84184653e-02, -1.46874161e-02,\n",
       "        1.31309093e-02, -1.08475601e-02,  1.34081137e-02, -1.17426082e-02,\n",
       "        1.28444180e-01, -2.20539912e-02,  1.15903737e-01,  5.90186799e-03,\n",
       "        1.24620628e-02,  7.31505433e-02, -7.99386785e-03,  3.64330948e-02,\n",
       "        3.45786135e-02,  3.46622248e-02,  2.36364873e-03, -7.05305371e-02,\n",
       "       -5.42092409e-02, -8.53608083e-03, -5.25069842e-03, -6.02257324e-02,\n",
       "        2.03989604e-02, -1.16195149e-02,  9.21856882e-02, -6.69648121e-02,\n",
       "        7.29324436e-03,  2.93620190e-02,  6.43402617e-02,  1.59824028e-02,\n",
       "        2.18187862e-02, -1.51119323e-03, -8.90493509e-03, -1.16167957e-01,\n",
       "        3.43116624e-02, -2.22888631e-02,  6.75987527e-02,  2.60055298e-02,\n",
       "       -2.21864720e-02, -2.88950545e-02,  5.87026319e-02,  5.31624537e-05,\n",
       "        4.37127347e-02, -3.44873604e-02,  1.45444367e-02,  4.66503901e-04,\n",
       "        1.16275493e-01, -7.23772724e-02,  3.08836906e-02,  3.09007196e-03,\n",
       "        1.63774043e-02,  1.35315594e-02,  3.91931003e-02, -3.61349685e-02,\n",
       "        8.19852925e-04,  2.57454347e-04,  6.94709985e-03,  1.86907215e-02,\n",
       "       -3.81673360e-03,  1.24494154e-02, -2.23289109e-02, -3.35482652e-02,\n",
       "       -4.22900976e-02,  2.49405606e-02,  4.42143134e-03,  5.85364044e-03,\n",
       "        3.19063303e-03, -4.88638142e-02, -1.23414861e-02, -1.29953995e-02,\n",
       "        1.96110924e-02,  1.76430468e-02,  9.77955939e-03, -1.76622996e-02])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 'привет всем слушателям курса'\n",
    "get_tweet_embedding(x, model=ft, embedding_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d77a274",
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKTEST_CCY = 'USDRUB'\n",
    "BACKTEST_DAYS = 5\n",
    "YEAR = 2022\n",
    "\n",
    "PATH_TEXTS = 'data/telegram'\n",
    "PATH_OPT_PNL = 'data/pnl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9b3272b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cbonds.csv',\n",
       " 'themovchans.csv',\n",
       " 'headlines_QUANTS.csv',\n",
       " 'War_Wealth_Wisdom.csv',\n",
       " 'mmi.csv',\n",
       " 'vts.csv',\n",
       " 'signal.csv',\n",
       " '.gitignore',\n",
       " 'rshb_invest.csv',\n",
       " 'Alfa_Wealth.csv',\n",
       " 'sky_bond.csv',\n",
       " 'bitkogan.csv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all available data_sources\n",
    "sources = os.listdir(PATH_TEXTS)\n",
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c00cad9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_start</th>\n",
       "      <th>pnl</th>\n",
       "      <th>pnl_sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-02</td>\n",
       "      <td>4.562674e+06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>-4.663725e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-04</td>\n",
       "      <td>-4.845276e+05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-09</td>\n",
       "      <td>1.268498e+06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-10</td>\n",
       "      <td>-2.874466e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>-3.886725e+05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2022-09-29</td>\n",
       "      <td>8.040320e+05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>1.544311e+06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2022-10-03</td>\n",
       "      <td>1.868107e+06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2022-10-04</td>\n",
       "      <td>2.480969e+06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_start           pnl  pnl_sign\n",
       "0    2022-03-02  4.562674e+06         1\n",
       "1    2022-03-03 -4.663725e+06         0\n",
       "2    2022-03-04 -4.845276e+05         0\n",
       "3    2022-03-09  1.268498e+06         1\n",
       "4    2022-03-10 -2.874466e+06         0\n",
       "..          ...           ...       ...\n",
       "138  2022-09-28 -3.886725e+05         0\n",
       "139  2022-09-29  8.040320e+05         1\n",
       "140  2022-09-30  1.544311e+06         1\n",
       "141  2022-10-03  1.868107e+06         1\n",
       "142  2022-10-04  2.480969e+06         1\n",
       "\n",
       "[143 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create target variable dataframe\n",
    "pnl = pd.read_csv(f'{PATH_OPT_PNL}/Backtest_{BACKTEST_CCY}_{BACKTEST_DAYS}_days_{YEAR}.txt')\n",
    "pnl['date_start'] = pd.to_datetime(pnl['date_start']).dt.strftime('%Y-%m-%d')\n",
    "pnl['pnl_sign'] = pnl['pnl'].apply(lambda x: 1 if x >= 0 else 0)\n",
    "pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c052489b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32167832167832167"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get balance of the sample\n",
    "balance = pnl['pnl_sign'].sum() / pnl.shape[0]\n",
    "max([balance, 1 - balance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f953b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "\n",
    "def _binary_search_by_date(array: List[Tuple[dt.datetime, float]], date_x: dt.datetime) -> Union[int, None]:\n",
    "    \"\"\"\n",
    "    Searches for the index of date_x in the array via binary search.\n",
    "\n",
    "        Parameters:\n",
    "            array (list) : A sorted array of (date, float_value) tuples\n",
    "            date_x (datetime.datetime) : Date to search for\n",
    "\n",
    "        Returns:\n",
    "            index_x (int): Index of the searched date in the array.\n",
    "    \"\"\"\n",
    "    left = 0\n",
    "    right = len(array) - 1\n",
    "\n",
    "    while left <= right:\n",
    "        mid = left + (right - left) // 2\n",
    "\n",
    "        if array[mid - 1][0] <= date_x <= array[mid][0]:\n",
    "            return mid\n",
    "        elif date_x > array[mid - 1][0] and date_x > array[mid][0]:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def binary_search_time_series(time_series: List[Tuple[dt.datetime, float]], date_start: dt.datetime,\n",
    "                              date_end: dt.datetime) -> Union[List[Tuple[dt.datetime, float]], None]:\n",
    "    \"\"\"\n",
    "    Searches for the part of the time series that is contained inside [date_start; date_end] period via binary search.\n",
    "\n",
    "        Parameters:\n",
    "            time_series (list) : A sorted array of (date, float_value) tuples\n",
    "            date_start (datetime.datetime) : Starting date of the searched period\n",
    "            date_end (datetime.datetime) : Ending date of the searched period\n",
    "\n",
    "        Returns:\n",
    "            time_series_data (list): Part of the time series that is contained inside [date_start; date_end] period.\n",
    "    \"\"\"\n",
    "\n",
    "    if date_start <= date_end:\n",
    "        left_index = _binary_search_by_date(time_series, date_start)\n",
    "        \n",
    "        if left_index is None:\n",
    "            return None\n",
    "        \n",
    "        right_index = _binary_search_by_date(time_series[left_index:], date_end)\n",
    "        \n",
    "        if right_index is None:\n",
    "            return None\n",
    "        \n",
    "        right_index += left_index\n",
    "    else:\n",
    "        left_index = _binary_search_by_date(time_series, date_end)\n",
    "        \n",
    "        if left_index is None:\n",
    "            return None\n",
    "        \n",
    "        right_index = _binary_search_by_date(time_series[left_index:], date_start)\n",
    "        \n",
    "        if right_index is None:\n",
    "            return None\n",
    "        \n",
    "        right_index += left_index\n",
    "    \n",
    "    return time_series[left_index:right_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19fac87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.datetime(2022, 3, 2, 0, 0), 1),\n",
       " (datetime.datetime(2022, 3, 3, 0, 0), 0),\n",
       " (datetime.datetime(2022, 3, 4, 0, 0), 0),\n",
       " (datetime.datetime(2022, 3, 9, 0, 0), 1),\n",
       " (datetime.datetime(2022, 3, 10, 0, 0), 0),\n",
       " (datetime.datetime(2022, 3, 11, 0, 0), 0),\n",
       " (datetime.datetime(2022, 3, 14, 0, 0), 0),\n",
       " (datetime.datetime(2022, 3, 15, 0, 0), 0),\n",
       " (datetime.datetime(2022, 3, 16, 0, 0), 0),\n",
       " (datetime.datetime(2022, 3, 17, 0, 0), 0),\n",
       " (datetime.datetime(2022, 3, 18, 0, 0), 1),\n",
       " (datetime.datetime(2022, 3, 21, 0, 0), 0),\n",
       " (datetime.datetime(2022, 3, 22, 0, 0), 0),\n",
       " (datetime.datetime(2022, 3, 23, 0, 0), 0),\n",
       " (datetime.datetime(2022, 3, 24, 0, 0), 0),\n",
       " (datetime.datetime(2022, 3, 25, 0, 0), 0),\n",
       " (datetime.datetime(2022, 3, 28, 0, 0), 0),\n",
       " (datetime.datetime(2022, 3, 29, 0, 0), 0),\n",
       " (datetime.datetime(2022, 3, 30, 0, 0), 0),\n",
       " (datetime.datetime(2022, 3, 31, 0, 0), 0),\n",
       " (datetime.datetime(2022, 4, 1, 0, 0), 1),\n",
       " (datetime.datetime(2022, 4, 4, 0, 0), 0),\n",
       " (datetime.datetime(2022, 4, 5, 0, 0), 0),\n",
       " (datetime.datetime(2022, 4, 6, 0, 0), 0),\n",
       " (datetime.datetime(2022, 4, 7, 0, 0), 1),\n",
       " (datetime.datetime(2022, 4, 8, 0, 0), 1),\n",
       " (datetime.datetime(2022, 4, 11, 0, 0), 1),\n",
       " (datetime.datetime(2022, 4, 12, 0, 0), 0),\n",
       " (datetime.datetime(2022, 4, 13, 0, 0), 0),\n",
       " (datetime.datetime(2022, 4, 14, 0, 0), 0),\n",
       " (datetime.datetime(2022, 4, 15, 0, 0), 0),\n",
       " (datetime.datetime(2022, 4, 18, 0, 0), 0),\n",
       " (datetime.datetime(2022, 4, 19, 0, 0), 0),\n",
       " (datetime.datetime(2022, 4, 20, 0, 0), 0),\n",
       " (datetime.datetime(2022, 4, 21, 0, 0), 0),\n",
       " (datetime.datetime(2022, 4, 22, 0, 0), 0),\n",
       " (datetime.datetime(2022, 4, 25, 0, 0), 0),\n",
       " (datetime.datetime(2022, 4, 26, 0, 0), 0),\n",
       " (datetime.datetime(2022, 4, 27, 0, 0), 0),\n",
       " (datetime.datetime(2022, 4, 28, 0, 0), 0),\n",
       " (datetime.datetime(2022, 4, 29, 0, 0), 0),\n",
       " (datetime.datetime(2022, 5, 4, 0, 0), 0),\n",
       " (datetime.datetime(2022, 5, 5, 0, 0), 1),\n",
       " (datetime.datetime(2022, 5, 6, 0, 0), 1),\n",
       " (datetime.datetime(2022, 5, 11, 0, 0), 0),\n",
       " (datetime.datetime(2022, 5, 12, 0, 0), 0),\n",
       " (datetime.datetime(2022, 5, 13, 0, 0), 1),\n",
       " (datetime.datetime(2022, 5, 16, 0, 0), 0),\n",
       " (datetime.datetime(2022, 5, 17, 0, 0), 0),\n",
       " (datetime.datetime(2022, 5, 18, 0, 0), 0),\n",
       " (datetime.datetime(2022, 5, 19, 0, 0), 0),\n",
       " (datetime.datetime(2022, 5, 20, 0, 0), 0),\n",
       " (datetime.datetime(2022, 5, 23, 0, 0), 1),\n",
       " (datetime.datetime(2022, 5, 24, 0, 0), 1),\n",
       " (datetime.datetime(2022, 5, 25, 0, 0), 1),\n",
       " (datetime.datetime(2022, 5, 26, 0, 0), 1),\n",
       " (datetime.datetime(2022, 5, 27, 0, 0), 0),\n",
       " (datetime.datetime(2022, 6, 6, 0, 0), 0),\n",
       " (datetime.datetime(2022, 6, 7, 0, 0), 0),\n",
       " (datetime.datetime(2022, 6, 8, 0, 0), 0),\n",
       " (datetime.datetime(2022, 6, 9, 0, 0), 0),\n",
       " (datetime.datetime(2022, 6, 10, 0, 0), 0),\n",
       " (datetime.datetime(2022, 6, 14, 0, 0), 0),\n",
       " (datetime.datetime(2022, 6, 15, 0, 0), 0),\n",
       " (datetime.datetime(2022, 6, 16, 0, 0), 0),\n",
       " (datetime.datetime(2022, 6, 17, 0, 0), 0),\n",
       " (datetime.datetime(2022, 6, 20, 0, 0), 0),\n",
       " (datetime.datetime(2022, 6, 21, 0, 0), 0),\n",
       " (datetime.datetime(2022, 6, 22, 0, 0), 0),\n",
       " (datetime.datetime(2022, 6, 23, 0, 0), 0),\n",
       " (datetime.datetime(2022, 6, 24, 0, 0), 0),\n",
       " (datetime.datetime(2022, 6, 27, 0, 0), 0),\n",
       " (datetime.datetime(2022, 6, 28, 0, 0), 1),\n",
       " (datetime.datetime(2022, 6, 29, 0, 0), 1),\n",
       " (datetime.datetime(2022, 6, 30, 0, 0), 1),\n",
       " (datetime.datetime(2022, 7, 1, 0, 0), 1),\n",
       " (datetime.datetime(2022, 7, 4, 0, 0), 1),\n",
       " (datetime.datetime(2022, 7, 5, 0, 0), 1),\n",
       " (datetime.datetime(2022, 7, 6, 0, 0), 0),\n",
       " (datetime.datetime(2022, 7, 7, 0, 0), 0),\n",
       " (datetime.datetime(2022, 7, 8, 0, 0), 0),\n",
       " (datetime.datetime(2022, 7, 11, 0, 0), 0),\n",
       " (datetime.datetime(2022, 7, 12, 0, 0), 0),\n",
       " (datetime.datetime(2022, 7, 13, 0, 0), 0),\n",
       " (datetime.datetime(2022, 7, 14, 0, 0), 0),\n",
       " (datetime.datetime(2022, 7, 15, 0, 0), 0),\n",
       " (datetime.datetime(2022, 7, 18, 0, 0), 0),\n",
       " (datetime.datetime(2022, 7, 19, 0, 0), 0),\n",
       " (datetime.datetime(2022, 7, 20, 0, 0), 1),\n",
       " (datetime.datetime(2022, 7, 21, 0, 0), 1),\n",
       " (datetime.datetime(2022, 7, 22, 0, 0), 1),\n",
       " (datetime.datetime(2022, 7, 25, 0, 0), 1),\n",
       " (datetime.datetime(2022, 7, 26, 0, 0), 1),\n",
       " (datetime.datetime(2022, 7, 27, 0, 0), 1),\n",
       " (datetime.datetime(2022, 7, 28, 0, 0), 0),\n",
       " (datetime.datetime(2022, 7, 29, 0, 0), 0),\n",
       " (datetime.datetime(2022, 8, 1, 0, 0), 0),\n",
       " (datetime.datetime(2022, 8, 2, 0, 0), 1),\n",
       " (datetime.datetime(2022, 8, 3, 0, 0), 0),\n",
       " (datetime.datetime(2022, 8, 4, 0, 0), 0),\n",
       " (datetime.datetime(2022, 8, 5, 0, 0), 0),\n",
       " (datetime.datetime(2022, 8, 8, 0, 0), 0),\n",
       " (datetime.datetime(2022, 8, 9, 0, 0), 0),\n",
       " (datetime.datetime(2022, 8, 10, 0, 0), 1),\n",
       " (datetime.datetime(2022, 8, 11, 0, 0), 1),\n",
       " (datetime.datetime(2022, 8, 12, 0, 0), 1),\n",
       " (datetime.datetime(2022, 8, 15, 0, 0), 0),\n",
       " (datetime.datetime(2022, 8, 16, 0, 0), 0),\n",
       " (datetime.datetime(2022, 8, 17, 0, 0), 0),\n",
       " (datetime.datetime(2022, 8, 18, 0, 0), 0),\n",
       " (datetime.datetime(2022, 8, 19, 0, 0), 1),\n",
       " (datetime.datetime(2022, 8, 22, 0, 0), 1),\n",
       " (datetime.datetime(2022, 8, 23, 0, 0), 1),\n",
       " (datetime.datetime(2022, 8, 24, 0, 0), 1),\n",
       " (datetime.datetime(2022, 8, 25, 0, 0), 1),\n",
       " (datetime.datetime(2022, 8, 26, 0, 0), 0),\n",
       " (datetime.datetime(2022, 8, 29, 0, 0), 0),\n",
       " (datetime.datetime(2022, 8, 30, 0, 0), 1),\n",
       " (datetime.datetime(2022, 8, 31, 0, 0), 1),\n",
       " (datetime.datetime(2022, 9, 1, 0, 0), 1),\n",
       " (datetime.datetime(2022, 9, 2, 0, 0), 1),\n",
       " (datetime.datetime(2022, 9, 5, 0, 0), 0),\n",
       " (datetime.datetime(2022, 9, 6, 0, 0), 0),\n",
       " (datetime.datetime(2022, 9, 7, 0, 0), 0),\n",
       " (datetime.datetime(2022, 9, 8, 0, 0), 0),\n",
       " (datetime.datetime(2022, 9, 9, 0, 0), 0),\n",
       " (datetime.datetime(2022, 9, 12, 0, 0), 0),\n",
       " (datetime.datetime(2022, 9, 13, 0, 0), 0),\n",
       " (datetime.datetime(2022, 9, 14, 0, 0), 1),\n",
       " (datetime.datetime(2022, 9, 15, 0, 0), 1),\n",
       " (datetime.datetime(2022, 9, 16, 0, 0), 1),\n",
       " (datetime.datetime(2022, 9, 19, 0, 0), 0),\n",
       " (datetime.datetime(2022, 9, 20, 0, 0), 0),\n",
       " (datetime.datetime(2022, 9, 21, 0, 0), 0),\n",
       " (datetime.datetime(2022, 9, 22, 0, 0), 0),\n",
       " (datetime.datetime(2022, 9, 23, 0, 0), 0),\n",
       " (datetime.datetime(2022, 9, 26, 0, 0), 0),\n",
       " (datetime.datetime(2022, 9, 27, 0, 0), 0),\n",
       " (datetime.datetime(2022, 9, 28, 0, 0), 0),\n",
       " (datetime.datetime(2022, 9, 29, 0, 0), 1),\n",
       " (datetime.datetime(2022, 9, 30, 0, 0), 1),\n",
       " (datetime.datetime(2022, 10, 3, 0, 0), 1),\n",
       " (datetime.datetime(2022, 10, 4, 0, 0), 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnl_sign_ts = [(pd.to_datetime(row['date_start']).to_pydatetime(), row['pnl_sign']) for  _, row in pnl.iterrows()]\n",
    "pnl_sign_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aaf278da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sr/lzvmv9j54ks_jl4x99t250r00000gn/T/ipykernel_26199/371081446.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(source_data)\n",
      "/var/folders/sr/lzvmv9j54ks_jl4x99t250r00000gn/T/ipykernel_26199/371081446.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(source_data)\n",
      "/var/folders/sr/lzvmv9j54ks_jl4x99t250r00000gn/T/ipykernel_26199/371081446.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(source_data)\n",
      "/var/folders/sr/lzvmv9j54ks_jl4x99t250r00000gn/T/ipykernel_26199/371081446.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(source_data)\n",
      "/var/folders/sr/lzvmv9j54ks_jl4x99t250r00000gn/T/ipykernel_26199/371081446.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(source_data)\n",
      "/var/folders/sr/lzvmv9j54ks_jl4x99t250r00000gn/T/ipykernel_26199/371081446.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(source_data)\n",
      "/var/folders/sr/lzvmv9j54ks_jl4x99t250r00000gn/T/ipykernel_26199/371081446.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(source_data)\n",
      "/var/folders/sr/lzvmv9j54ks_jl4x99t250r00000gn/T/ipykernel_26199/371081446.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(source_data)\n",
      "/var/folders/sr/lzvmv9j54ks_jl4x99t250r00000gn/T/ipykernel_26199/371081446.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(source_data)\n",
      "/var/folders/sr/lzvmv9j54ks_jl4x99t250r00000gn/T/ipykernel_26199/371081446.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(source_data)\n",
      "/var/folders/sr/lzvmv9j54ks_jl4x99t250r00000gn/T/ipykernel_26199/371081446.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(source_data)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>2017-07-28T10:56:14</td>\n",
       "      <td>Cbonds.ru  запустило канал в Telegram. Планиру...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>2017-08-03T15:28:17</td>\n",
       "      <td>Облигационный бюллетень Cbonds – все данные о ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-08-03T15:41:02</td>\n",
       "      <td>Cbonds prepared monthly report: CBONDS GLOBAL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>2017-08-03T18:11:32</td>\n",
       "      <td>Дайджест Cbonds от  3 августа:«Группа Компаний...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>2017-08-04T12:42:41</td>\n",
       "      <td>Совкомбанк открыл книгу заявок на вторичное ра...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                 date                                               text\n",
       "0   9  2017-07-28T10:56:14  Cbonds.ru  запустило канал в Telegram. Планиру...\n",
       "1  10  2017-08-03T15:28:17  Облигационный бюллетень Cbonds – все данные о ...\n",
       "2  11  2017-08-03T15:41:02  Cbonds prepared monthly report: CBONDS GLOBAL ...\n",
       "3  12  2017-08-03T18:11:32  Дайджест Cbonds от  3 августа:«Группа Компаний...\n",
       "4  13  2017-08-04T12:42:41  Совкомбанк открыл книгу заявок на вторичное ра..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate dataframes\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for s in sources:\n",
    "    if s != '.gitignore':\n",
    "        source_data = pd.read_csv(f'{PATH_TEXTS}/{s}')\n",
    "        df = df.append(source_data)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53d077c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_date = pnl_sign_ts[0][0]\n",
    "\n",
    "# for i, row in df.iterrows():\n",
    "#     date_x = pd.to_datetime(row['date']).to_pydatetime()\n",
    "#     pnl_sign_key = _binary_search_by_date(pnl_sign_ts, date_x)\n",
    "    \n",
    "#     if pnl_sign_key is not None and date_x >= initial_date:\n",
    "#         df.loc[df.index[i], 'pnl_sign'] = pnl_sign_ts[_binary_search_by_date(pnl_sign_ts, date_x)][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3d7b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_date = pnl_sign_ts[0][0]\n",
    "\n",
    "def get_pnl_sign(row):\n",
    "    date_x = pd.to_datetime(row['date']).to_pydatetime()\n",
    "    pnl_sign_key = _binary_search_by_date(pnl_sign_ts, date_x)\n",
    "    \n",
    "    if pnl_sign_key is not None and date_x >= initial_date:\n",
    "        return pnl_sign_ts[_binary_search_by_date(pnl_sign_ts, date_x)][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75961477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>pnl_sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>2017-07-28T10:56:14</td>\n",
       "      <td>Cbonds.ru  запустило канал в Telegram. Планиру...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>2017-08-03T15:28:17</td>\n",
       "      <td>Облигационный бюллетень Cbonds – все данные о ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-08-03T15:41:02</td>\n",
       "      <td>Cbonds prepared monthly report: CBONDS GLOBAL ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>2017-08-03T18:11:32</td>\n",
       "      <td>Дайджест Cbonds от  3 августа:«Группа Компаний...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>2017-08-04T12:42:41</td>\n",
       "      <td>Совкомбанк открыл книгу заявок на вторичное ра...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                 date                                               text  \\\n",
       "0   9  2017-07-28T10:56:14  Cbonds.ru  запустило канал в Telegram. Планиру...   \n",
       "1  10  2017-08-03T15:28:17  Облигационный бюллетень Cbonds – все данные о ...   \n",
       "2  11  2017-08-03T15:41:02  Cbonds prepared monthly report: CBONDS GLOBAL ...   \n",
       "3  12  2017-08-03T18:11:32  Дайджест Cbonds от  3 августа:«Группа Компаний...   \n",
       "4  13  2017-08-04T12:42:41  Совкомбанк открыл книгу заявок на вторичное ра...   \n",
       "\n",
       "   pnl_sign  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pnl_sign'] = df.apply(lambda row: get_pnl_sign(row), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a02b786d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>pnl_sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10813</td>\n",
       "      <td>2022-03-02T09:38:25</td>\n",
       "      <td>УТРЕННИЙ ДАЙДЖЕСТ  🏛❗️Банк России принял решен...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10814</td>\n",
       "      <td>2022-03-02T10:49:57</td>\n",
       "      <td>#НовостиКомпаний  ⚡️ Российские компании: осно...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10815</td>\n",
       "      <td>2022-03-02T11:06:47</td>\n",
       "      <td>⚡️ Важное на рынках: ⛔️Международная ассоциаци...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10816</td>\n",
       "      <td>2022-03-02T11:23:57</td>\n",
       "      <td>📝 НАУФОР просит рассмотреть вопрос дополнитель...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10817</td>\n",
       "      <td>2022-03-02T12:23:55</td>\n",
       "      <td>#ДенежныйРынок 📆 💰События денежного рынка сего...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                 date  \\\n",
       "0  10813  2022-03-02T09:38:25   \n",
       "1  10814  2022-03-02T10:49:57   \n",
       "2  10815  2022-03-02T11:06:47   \n",
       "3  10816  2022-03-02T11:23:57   \n",
       "4  10817  2022-03-02T12:23:55   \n",
       "\n",
       "                                                text  pnl_sign  \n",
       "0  УТРЕННИЙ ДАЙДЖЕСТ  🏛❗️Банк России принял решен...       0.0  \n",
       "1  #НовостиКомпаний  ⚡️ Российские компании: осно...       0.0  \n",
       "2  ⚡️ Важное на рынках: ⛔️Международная ассоциаци...       0.0  \n",
       "3  📝 НАУФОР просит рассмотреть вопрос дополнитель...       0.0  \n",
       "4  #ДенежныйРынок 📆 💰События денежного рынка сего...       0.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=['pnl_sign'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e7f8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['id', 'date', 'pnl_sign'], axis=1)\n",
    "y = df['pnl_sign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f3545b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        УТРЕННИЙ ДАЙДЖЕСТ  🏛❗️Банк России принял решен...\n",
       "1        #НовостиКомпаний  ⚡️ Российские компании: осно...\n",
       "2        ⚡️ Важное на рынках: ⛔️Международная ассоциаци...\n",
       "3        📝 НАУФОР просит рассмотреть вопрос дополнитель...\n",
       "4        #ДенежныйРынок 📆 💰События денежного рынка сего...\n",
       "                               ...                        \n",
       "14922    Завершаем начатую в субботу серию  заметок  о ...\n",
       "14923    Санкции на НКЦ = санкции на американские акции...\n",
       "14924    В среду в Вене группа ОПЕК+ встретится, чтобы ...\n",
       "14925    На прошлой неделе в  сервисе по подписке  мы з...\n",
       "14926    Торги на валютном рынке сегодня проходят нетип...\n",
       "Name: text, Length: 14927, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b6e3c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from functools import lru_cache\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm.gui import tqdm as tqdm_gui\n",
    "\n",
    "m = MorphAnalyzer()\n",
    "regex = re.compile(\"[а-яa-zёЁ]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return regex.findall(text.lower())\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "@lru_cache(maxsize=128)\n",
    "def lemmatize_word(token, pymorphy=m):\n",
    "    return pymorphy.parse(token)[0].normal_form\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatize_word(w) for w in text]\n",
    "\n",
    "mystopwords = stopwords.words('russian') \n",
    "def remove_stopwords(lemmas, stopwords = mystopwords):\n",
    "    return [w for w in lemmas if not w in stopwords and len(w) > 3]\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = words_only(text)\n",
    "    lemmas = lemmatize_text(tokens)\n",
    "    \n",
    "    return ' '.join(remove_stopwords(lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51c88026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09b2f9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd482ae030cb46819b6f3991395a1c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11941 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9288</th>\n",
       "      <td>#Макро \\n 📊 Опрос: Маск — красавчик? В апреле ...</td>\n",
       "      <td>макро опрос маск красавчик апрель опросить отз...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10636</th>\n",
       "      <td>#Макро \\n🇷🇺 Санкции против России не смогли по...</td>\n",
       "      <td>макро санкция против россия смочь подорвать фи...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785</th>\n",
       "      <td>#Commodities \\n📊  Товарные   биржи Цены фьючер...</td>\n",
       "      <td>commodities товарный биржа цена фьючерс основн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8707</th>\n",
       "      <td>#Commodities \\n📊  Товарные   биржи Цены фьючер...</td>\n",
       "      <td>commodities товарный биржа цена фьючерс основн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>‼️ Все карты международных платежных систем Vi...</td>\n",
       "      <td>карта международный платёжный система visa mas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "9288   #Макро \\n 📊 Опрос: Маск — красавчик? В апреле ...   \n",
       "10636  #Макро \\n🇷🇺 Санкции против России не смогли по...   \n",
       "4785   #Commodities \\n📊  Товарные   биржи Цены фьючер...   \n",
       "8707   #Commodities \\n📊  Товарные   биржи Цены фьючер...   \n",
       "2392   ‼️ Все карты международных платежных систем Vi...   \n",
       "\n",
       "                                                  lemmas  \n",
       "9288   макро опрос маск красавчик апрель опросить отз...  \n",
       "10636  макро санкция против россия смочь подорвать фи...  \n",
       "4785   commodities товарный биржа цена фьючерс основн...  \n",
       "8707   commodities товарный биржа цена фьючерс основн...  \n",
       "2392   карта международный платёжный система visa mas...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas = list(tqdm(map(clean_text, X_train['text']), total=len(X_train)))\n",
    "\n",
    "X_train['lemmas'] = lemmas\n",
    "X_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7159b314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15375699ad784bee92dda85176e31cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2986 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lemmas_val = list(tqdm(map(clean_text, X_val['text']), total=len(X_val)))\n",
    "\n",
    "X_val['lemmas'] = lemmas_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84cde13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11941, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e76422a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6cc1815d7a84f959367fe1fc3242f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11941 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train done\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "X_train['embedding'] = X_train['lemmas'].progress_apply(lambda x: get_tweet_embedding(x, model=ft))\n",
    "print('train done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4b9cb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c82e46dff9b45fb89bc64c9dc4acfe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2986 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "X_val['embedding'] = X_val['lemmas'].progress_apply(lambda x: get_tweet_embedding(x, model=ft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c58229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedding = np.array(list(X_train['embedding'].values))\n",
    "val_embedding = np.array(list(X_val['embedding'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ca0cbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6993551628841805"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = LogisticRegression(random_state=12)\n",
    "clf.fit(train_embedding, y_train)\n",
    "clf.score(train_embedding, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfae93e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6999330207635633"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf.predict(val_embedding)\n",
    "accuracy_score(pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1ae4906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.695244474212994"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_features=4, n_estimators=50)\n",
    "\n",
    "rf.fit(train_embedding, y_train)\n",
    "(y_val == rf.predict(val_embedding)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53f27bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f32cdbf9fca41cb959bb02b9b0dc41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1037d9db0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import catboost as cb\n",
    "\n",
    "np.random.seed(12)\n",
    "\n",
    "params = dict(\n",
    "    learning_rate=0.025,\n",
    "    iterations=10000,\n",
    "    reg_lambda=0.0005,\n",
    "    colsample_bylevel=1.,\n",
    "    max_bin=80,\n",
    "    bagging_temperature=2,\n",
    "    use_best_model=True,\n",
    "    verbose=False,\n",
    "    grow_policy='Depthwise',\n",
    "    random_seed=12\n",
    ")\n",
    "model = cb.CatBoostClassifier(\n",
    "    **params,\n",
    ")\n",
    "\n",
    "eval_set = cb.Pool(data=val_embedding, label=y_val)\n",
    "model.fit(train_embedding, y_train, eval_set=eval_set, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f69c134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6999330207635633"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(val_embedding)\n",
    "accuracy_score(pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8de8b7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ed07cdb80b4f04bb2611ee5990237f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14927 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lemmas = list(tqdm(map(clean_text, df['text']), total=len(df)))\n",
    "\n",
    "df['lemmas'] = lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "344297db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(df, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a423224",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_ft.txt', 'w') as f:\n",
    "    for label, lemmas in list(zip(\n",
    "        y_train, X_train['lemmas']\n",
    "    )):\n",
    "        f.write(f\"__label__{int(label)} {lemmas}\\n\")\n",
    "        #print(f\"__label__{int(label)} {lemmas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25163fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__0 покупать коррекция эпизод энергетика энергетика традиционно считаться защитный актив поэтому сектор также обратить внимание многие энергетический компания продолжать платить дивиденд интер русгидро иметь достаточно стабильный бизнес негатив сектор сталкиваться санкционный проблема часть запрет поставка западный оборудование затруднять технический модернизация сказываться перспектива рост бизнес сектор отдельный история который обратить внимание частность интер почему самый ликвидный компания сектор интер напоминать сургутнефтегаз достаточно большой запас ожидание дать средство использовать покупка актив компания заявить уход россия enel forum uniper занизить цена крупный buyback иметься риск средство мочь потребоваться выкуп акция делистинг компания решить уйти биржа интер наиболее дешёвый мультипликатор компания российский рынок компания продолжать платить дивиденд последний выплата выплатить июнь размер акция итог соответствовать доходность минус отметить интер свести минимум контакт внешний компания решить воспользоваться разрешение раскрывать информация перестать публиковать отчётность хотя означать дело бизнес интер идти плохо аэрофлот положение отечественный авиаперевозчик выглядеть крайне проблематичный конец понятно обслуживание самолёт дальнейший отношение лизингодатель компания недавно провести допэмиссия который доля госучастие вырасти компания продолжать остро нуждаться деньга сокращение международный внутрироссийский рейс среди инвестор немало желать половить рыба мутный вода ставка аэрофлот выглядеть рисковой яндекс история неопределённый перспектива сторона компания хороший финансовый показатель итог квартал выручка вырасти ebitda увеличиться чистый прибыль чистый денежный поток впервые квартал оказаться положительный темп рост прибыль объясняться эффект низкий база предыдущий уход крупный конкурент недружественный юрисдикция российский рынок главный риск инвестор возможный раздел актив иностранный российский понимать российский периметр находиться значительно маленький расти актив иначе говорить сценарий реализовать российский компания факт мочь оставить поиск такси яндекс маркет связанный бизнес доставка уйти мочь беспилотник облако яндекс практикум также карта навигатор достаточно сильный удар экосистема компания алрос интересный история отметить следующий ранее наблюдательный совет компания рекомендовать выплачивать финальный дивиденд итог деятельность компания надежда компания мочь пересмотреть решение второй полугодие низкий риск рост ндпить пример металлургический компания алрос принадлежать государство эксперт ожидать высокий цена алмаз рекордно низкий запас огранщик истощение существующий месторождение прогнозироваться добыча пять выйти допандемийный уровень негатив алрос попасть list закрыть возможность расчёт доллар создать проблема реализация продукция поэтому перспектива слишком прозрачный\r\n",
      "__label__0 вставать пауза помимо снижение ставка пересмотреть сегодня прогноз инфляция конец снизить ожидать аномально низкий цифра последний месяц также указать динамика складываться близкий верхний граница прогноз который составлять скорее весь октябрь повысить понизить давно очевидный кризис сместиться вправо длительный глубина примерно оцениваться ранее самый интересный сигнал точнее отсутствие напомнить стандартный формулировка сигнал допускать возможность снижение повышение сильный оценивать целесообразность снижение повышение сегодняшний пресс релиз направить сигнал однозначный указание цикл снижение ставка возможно завершить повод сокращение длинный позиция исключать первый половина следующий начать повышать ставка особенно пакет санкция оказаться эффективный торговый профицит схлопнуться рубль упасть\r\n",
      "__label__0 политика стартовать процесс ратификация вступление швеция финляндия нато генсек нато столтенберг\r\n",
      "__label__0 цбрф международный резерв апрель составить млрд апрель млрд\r\n",
      "__label__0 вчерашний выступление глава вызвать рекордный распродажа облигация глобальный рынок настоящий обеспокоить высокий инфляция перегрев рынок труд готовый рассматривать повышение ставка интересно реальный ставка срок доходность соответствующий tips начало снизиться долгосрочный ставка несмотря рост начало оставаться отрицательный интервал нулевой иронически написать крупный инвестбанк отрицательный реальный ставка инфляция снизить вероятно инвестор стоить ожидать продолжение период повышенный инфляция ужесточение монетарный политика\r\n",
      "__label__0 новость день германия вдвое сократить импорт российский уголь время польша вообще запретить поставка российский уголь страна польша приходиться около российский экспорт уголь который россия планировать перенаправить азия индекс доверие потребитель март вырасти пункт ожидание аналитик уровень февраль индекс доверие потребитель составить пункт индекс потребительский уверенность начало снижаться усиление инфляционный давление китай продолжать увеличивать ликвидность банковский система операция дневный reverse repo сегодня объём интервенция составить млрд юань мера направить поддержание стабильный ликвидность конец квартал также связь введение локдаун город китай daily\r\n",
      "__label__0 rual отчётность русало мсфо выручка млрд ebitda млрд скорра чистый прибыль млрд цена алюминий себестоимость подробный результат\r\n",
      "__label__0 лидер рост падение подробный карта российский рынок\r\n",
      "__label__0 политика пока преждевременно раскрывать либо набор договорённость песок новость сообщение подготовка россия украина план урегулирование\r\n",
      "__label__0 главное россия возобновлять торг мосбиржа март kommersant минфин направить трлн приобретение акция российский компания kommersant индекс обрабатывать отрасль россия снизиться пункт kommersant циан зафиксировать ажиотажный спрос жильё повышение ставка interfax daily\r\n"
     ]
    }
   ],
   "source": [
    "!tail train_ft.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "996c9c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  26644\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 2629014 lr:  0.000000 avg.loss:  0.585039 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "classifier = fasttext.train_supervised('train_ft.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9371ecc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6892163429336906"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = classifier.predict(list(X_val['lemmas']))[0]\n",
    "pred = [int(label[0][-1]) for label in pred]\n",
    "\n",
    "accuracy_score(list(y_val), pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cd1fef11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.41 s, sys: 108 ms, total: 5.51 s\n",
      "Wall time: 1.65 s\n"
     ]
    }
   ],
   "source": [
    "tokenized_tweets = [tweet.split() for tweet in train['lemmas'].values]\n",
    "\n",
    "%time w2v = word2vec.Word2Vec(tokenized_tweets, workers=4, vector_size=200, min_count=10, window=3, sample=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cfed6754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('снижение', 0.8544461727142334),\n",
       " ('падение', 0.825333297252655),\n",
       " ('замедление', 0.7423386573791504),\n",
       " ('скачок', 0.7407942414283752),\n",
       " ('динамика', 0.7228158116340637),\n",
       " ('восстановление', 0.7145742774009705),\n",
       " ('прирост', 0.7144163250923157),\n",
       " ('ускорение', 0.6959972977638245),\n",
       " ('сокращение', 0.6948442459106445),\n",
       " ('спад', 0.6923654675483704)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(positive=['рост'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ee7fb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_embedding(lemmas, model=w2v.wv, embedding_size=200):\n",
    "    \n",
    "    res = np.zeros(embedding_size)\n",
    "    cnt = 0\n",
    "    for word in lemmas.split():\n",
    "        if word in model:\n",
    "            res += np.array(model[word])\n",
    "            cnt += 1\n",
    "    if cnt:\n",
    "        res = res / cnt\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a1c181c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['w2v_embedding'] = X_train['lemmas'].map(get_tweet_embedding)\n",
    "X_val['w2v_embedding'] = X_val['lemmas'].map(get_tweet_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f4694775",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w2v = list(X_train['w2v_embedding'].values)\n",
    "val_w2v = list(X_val['w2v_embedding'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f10b33c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7016075016744809"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=12, max_iter=500)\n",
    "clf.fit(train_w2v, y_train)\n",
    "\n",
    "pred = clf.predict(val_w2v)\n",
    "accuracy_score(pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "069e738a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172a0907ab354d818497e4da3553eaf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x475b526e0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import catboost as cb\n",
    "\n",
    "np.random.seed(12)\n",
    "\n",
    "params = dict(\n",
    "    learning_rate=0.025,\n",
    "    iterations=10000,\n",
    "    reg_lambda=0.0005,\n",
    "    colsample_bylevel=1.,\n",
    "    max_bin=80,\n",
    "    bagging_temperature=2,\n",
    "    use_best_model=True,\n",
    "    verbose=False,\n",
    "    grow_policy='Depthwise',\n",
    "    random_seed=12\n",
    ")\n",
    "model = cb.CatBoostClassifier(\n",
    "    **params,\n",
    ")\n",
    "\n",
    "eval_set = cb.Pool(data=val_w2v, label=y_val)\n",
    "model.fit(train_w2v, y_train, eval_set=eval_set, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2145fc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.702277294038848"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(val_w2v)\n",
    "accuracy_score(pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2f5e4e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm  \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim import utils\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "\n",
    "# import dlnlputils\n",
    "# from dlnlputils.data import tokenize_text_simple_regex, tokenize_corpus, build_vocabulary, \\\n",
    "#     vectorize_texts, SparseFeaturesDataset\n",
    "# from dlnlputils.pipeline import train_eval_loop, predict_with_model, init_random_seed\n",
    "\n",
    "# init_random_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "86569712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "TOKEN_RE = re.compile(r'[\\w\\d]+')\n",
    "\n",
    "\n",
    "def tokenize_text_simple_regex(txt, min_token_size=4):\n",
    "    txt = txt.lower()\n",
    "    all_tokens = TOKEN_RE.findall(txt)\n",
    "    return [token for token in all_tokens if len(token) >= min_token_size]\n",
    "\n",
    "\n",
    "def character_tokenize(txt):\n",
    "    return list(txt)\n",
    "\n",
    "\n",
    "def tokenize_corpus(texts, tokenizer=tokenize_text_simple_regex, **tokenizer_kwargs):\n",
    "    return [tokenizer(text, **tokenizer_kwargs) for text in texts]\n",
    "\n",
    "\n",
    "def add_fake_token(word2id, token=''):\n",
    "    word2id_new = {token: i + 1 for token, i in word2id.items()}\n",
    "    word2id_new[token] = 0\n",
    "    return word2id_new\n",
    "\n",
    "\n",
    "def texts_to_token_ids(tokenized_texts, word2id):\n",
    "    return [[word2id[token] for token in text if token in word2id]\n",
    "            for text in tokenized_texts]\n",
    "\n",
    "\n",
    "def build_vocabulary(tokenized_texts, max_size=1000000, max_doc_freq=0.8, min_count=5, pad_word=None):\n",
    "    word_counts = collections.defaultdict(int)\n",
    "    doc_n = 0\n",
    "\n",
    "    # посчитать количество документов, в которых употребляется каждое слово\n",
    "    # а также общее количество документов\n",
    "    for txt in tokenized_texts:\n",
    "        doc_n += 1\n",
    "        unique_text_tokens = set(txt)\n",
    "        for token in unique_text_tokens:\n",
    "            word_counts[token] += 1\n",
    "\n",
    "    # убрать слишком редкие и слишком частые слова\n",
    "    word_counts = {word: cnt for word, cnt in word_counts.items()\n",
    "                   if cnt >= min_count and cnt / doc_n <= max_doc_freq}\n",
    "\n",
    "    # отсортировать слова по убыванию частоты\n",
    "    sorted_word_counts = sorted(word_counts.items(),\n",
    "                                reverse=True,\n",
    "                                key=lambda pair: pair[1])\n",
    "\n",
    "    # добавим несуществующее слово с индексом 0 для удобства пакетной обработки\n",
    "    if pad_word is not None:\n",
    "        sorted_word_counts = [(pad_word, 0)] + sorted_word_counts\n",
    "\n",
    "    # если у нас по прежнему слишком много слов, оставить только max_size самых частотных\n",
    "    if len(word_counts) > max_size:\n",
    "        sorted_word_counts = sorted_word_counts[:max_size]\n",
    "\n",
    "    # нумеруем слова\n",
    "    word2id = {word: i for i, (word, _) in enumerate(sorted_word_counts)}\n",
    "\n",
    "    # нормируем частоты слов\n",
    "    word2freq = np.array([cnt / doc_n for _, cnt in sorted_word_counts], dtype='float32')\n",
    "\n",
    "    return word2id, word2freq\n",
    "\n",
    "\n",
    "PAD_TOKEN = '__PAD__'\n",
    "NUMERIC_TOKEN = '__NUMBER__'\n",
    "NUMERIC_RE = re.compile(r'^([0-9.,e+\\-]+|[mcxvi]+)$', re.I)\n",
    "\n",
    "\n",
    "def replace_number_nokens(tokenized_texts):\n",
    "    return [[token if not NUMERIC_RE.match(token) else NUMERIC_TOKEN for token in text]\n",
    "            for text in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d1e0c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "def vectorize_texts(tokenized_texts, word2id, word2freq, mode='tfidf', scale=True):\n",
    "    assert mode in {'tfidf', 'idf', 'tf', 'bin'}\n",
    "\n",
    "    # считаем количество употреблений каждого слова в каждом документе\n",
    "    result = scipy.sparse.dok_matrix((len(tokenized_texts), len(word2id)), dtype='float32')\n",
    "    for text_i, text in enumerate(tokenized_texts):\n",
    "        for token in text:\n",
    "            if token in word2id:\n",
    "                result[text_i, word2id[token]] += 1\n",
    "\n",
    "    # получаем бинарные вектора \"встречается или нет\"\n",
    "    if mode == 'bin':\n",
    "        result = (result > 0).astype('float32')\n",
    "\n",
    "    # получаем вектора относительных частот слова в документе\n",
    "    elif mode == 'tf':\n",
    "        result = result.tocsr()\n",
    "        result = result.multiply(1 / result.sum(1))\n",
    "\n",
    "    # полностью убираем информацию о количестве употреблений слова в данном документе,\n",
    "    # но оставляем информацию о частотности слова в корпусе в целом\n",
    "    elif mode == 'idf':\n",
    "        result = (result > 0).astype('float32').multiply(1 / word2freq)\n",
    "\n",
    "    # учитываем всю информацию, которая у нас есть:\n",
    "    # частоту слова в документе и частоту слова в корпусе\n",
    "    elif mode == 'tfidf':\n",
    "        result = result.tocsr()\n",
    "        result = result.multiply(1 / result.sum(1))  # разделить каждую строку на её длину\n",
    "        result = result.multiply(1 / word2freq)  # разделить каждый столбец на вес слова\n",
    "\n",
    "    if scale:\n",
    "        result = result.tocsc()\n",
    "        result -= result.min()\n",
    "        result /= (result.max() + 1e-6)\n",
    "\n",
    "    return result.tocsr()\n",
    "\n",
    "\n",
    "class SparseFeaturesDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cur_features = torch.from_numpy(self.features[idx].toarray()[0]).float()\n",
    "        cur_label = torch.from_numpy(np.asarray(self.targets[idx])).long()\n",
    "        return cur_features, cur_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a3793d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = tokenize_corpus(X_train['text'])\n",
    "val_tokenized = tokenize_corpus(X_val['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "395e4250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "макро карта американского рынка ярче праздничного салюта\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(train_tokenized[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "79a12687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных токенов 17342\n",
      "[('россии', 0), ('года', 1), ('2022', 2), ('будет', 3), ('может', 4), ('млрд', 5), ('также', 6), ('более', 7), ('сегодня', 8), ('рынка', 9)]\n"
     ]
    }
   ],
   "source": [
    "# строим словарь - vocabulary с помощью функции build_vocabulary\n",
    "# принимает на вход список списков токенезированные\n",
    "# word_doc_freq - содержит относительные частоты всех слов в датасете, он понадобиться \n",
    "# на этапе формирования матрицы признаков\n",
    "\n",
    "MAX_DF = 0.8 #во скольких документах встречаеться слово\n",
    "MIN_COUNT = 5 # сколько раз слово встречаеться в тексте\n",
    "\n",
    "\n",
    "vocabulary, word_doc_freq = build_vocabulary(train_tokenized, max_doc_freq=MAX_DF, min_count=MIN_COUNT)\n",
    "UNIQUE_WORDS_N = len(vocabulary)\n",
    "print('Количество уникальных токенов', UNIQUE_WORDS_N)\n",
    "print(list(vocabulary.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3ebd3e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZvElEQVR4nO3df7QcZX3H8feHQAKCJGBCK/nBDQ1Qg7ZgbwP9gcVWSyJewlEqifgDjISoaK3WGoptPS1YONWqFCzEY4yKElOtnERC8VcjWgkSEDSRRi8xmAQqCSER+Q359o95Fieb3ZvdO7v3Xp58Xufcc3efmXnmu8/MfveZZ2ZnFRGYmVle9hvuAMzMrPOc3M3MMuTkbmaWISd3M7MMObmbmWXIyd3MLENO7mZmGdpnk7ukjZIek/QrSb+QtETSIcMdl5lZJ+yzyT3pi4hDgJcCvcAHhjkeM7OO2NeTOwARsQW4EXgxgKTzJN0t6WFJGyRdUJ5f0mxJd0r6paR7JM1M5askPZ6OBn6Vjgw2lpbbKOkiST+W9JCkT0s6sDT91aneHZK+J+l36tZ7raQnS3VvLk0bI+nDkn6ejkSulnRQaXqPpCjF9oykt6Zp+0lamF7Lg5KWSTq8brn96+L4YHp8al0cr0vzv7VU9pbUng9JuknSUc22haQzJK1LbbBK0otS+ZWl2EPSI+nxjaW2L6/zFXVt/6I0z45U/xmlaQdJ+oikeyXtlPTdVLbba5c0Iz2/JD3fkWJ4PLVnLb5z0vST03bcIekuSafWvdYlA2zPkDStSRttlPSK0vO3Slq1t2XT6zo3Pf53SV8uTbtc0jclqcFyS2qvuf65pMMkfVXS1rR9vyppUmnew9N+fl+afn2LbTeo/aBB7JMl/WeK70FJV5amnSppV6m+XbV2lTRW0mfTcvdK+oCk/dK0c0sx/1LStyRNbLT+4eTkTrEDAK8CfpCKHgBeDRwKnAd8VNJL07wzgM8C7wPGAS8DNpaquzAiDklHBH0NVncOcBrwW8CxpKMFSScCi4ELgBcA1wDLJY0phwpcmuqeVVfvZam+E4BpwETg70vTa9t6bFr+O6Vp7wTOBP4EOBJ4CLiqQewDknQA8E/A/aWy2cDfAq8BJqT1Xtdk+WPTtHeneVcCKySNjohyuwL8bnpe3w7N4loBfA04Ir3ez0s6Ls3yYeD3gD8EDgf+BtjVoKp/AbbUnkTEuBTPAuCWWnwR8fn0Zr8BuCTV+dfAlyVNKNW3H3B5k+3Zbe8FXpIS1SnAPODN0fh+JLtoniv2Az4NHAVMAR4DrixN/xzwPOB4irb/KOy17TqyH0gaBXwVuBfooXhPLK2LfUupvp+Xpv0bMBY4muJ98SaKXFBzS1rmCOAJ4K+atM+w2deT+/WSdgDfBb4NfAggIm6IiHui8G2KpHBKWmYesDgivh4RuyJiS0T8bxvrvDIiNkXEduBSYG4qnw9cExG3RsQzEfEZip3m5NKyBwFP1leYelvzgb+KiO0R8XB6LXNKs40GdkXEMw1iWgBcHBGbI+IJ4IPAWSr11lt0AXAr8JO6uv85Iu6OiKdTXCeoce/9bOCG1LZPUSTdgyiSbhUnA4cAl0XEkxHxLYo3/dzUG3sL8JdpWz4TEd9L7fAsSa+m+HD9RovrfAOwMiJWpv3k68Aaik5EzWgabM+hEBGPAm8E/hW4FnhnRGxuMvvPgVNUOsos1fNgRHw5Ih5N+92lFMkQSS+k+NBaEBEPRcRT6f20N53aD2ZQdFbeFxGPRMTjEfHd0vSG7Z8+FOYAF0XEwxGxEfgIRXvV2y/9PdhmbF23ryf3M1MP4qiIeHtEPAYgaZak1ZK2p+T/KmB8WmYycE+FdW4qPb6XYueDoufz3nQYuiOtd3JpOsBvAlsb1DmBond0e2nZ/0rlNYdT9MgbOQr4SmnZu4FngN8ozbOtNP119RVIej5Fj/fvGtT98dKy2ymSZKPD2CMp2gSAiNhF0V6tHvJeUVrP9XX1bkr11dyb6h0PHMjA23QU8M8Ur69VRwF/Ubc9/xh4YWmegbYJwB1p2Q2S3ls37fpSvVe0uSwAEXErsIFieywbII6rgMeBX6T1vb42QdLzJF2Thi5+CdwMjEsJcjKwPSIGeo2NVN0PaiYD96ZORSPN2n88cEA5Bn69v9ScnNpiBzAVWNJmbF23ryf3PaRhkC9T9BZ+IyLGURwW1sYiN1EMqQzW5NLjKcB9pXovTR82tb/nRcR1Ka4DKM4J3NWgzm0Uh8PHl5atDb/UHMvuPeqyTcCsunUfmM5F1IyvTaNxIngfsCwi7q0r3wRcUFf3QRHxvQZ13EeRFEmvWRTttaXBvI28qxTjmXX1Tq6NmSZTUr3bKBLXQNv0zcD6iFjdYhxQvO7P1b3ugyPistI8A20TgJem13IGcImk3y5NO7P0Wt/V5rIASHoHMIaifZp+cEXE1oh4ZdqnxgFfKE1+L3AccFJEHEoxTAnF+2UTcLikcQO8xkaq7gc1m4ApAxyBNmv/bcBT5Rj49f5Sszq1xYEURz5L2oyt65zc9zSaYoffCjwtaRbw56XpnwLOk/RnKk5ETmz0xhnAOyRNUnHC8mLgi6n8k8ACSSepcLCk01OPGIrxvv+jOLTfTerZfJLi3MARACmu09LjycBfsntvtuxq4NLaUImkCWmsvFXPT/Fd2qTuiyQdn+oeK+kvmtSzDDg9te0BFInjCaDRB0E7bgUeBf5G0gEqTmz2AUtT2y0G/lXSkZJGSfqDunMdFwMXtbnOa4E+SaelOg9UcQJvkqT9JS2gGCr6zl7qgaJ3ONC4d9vLpnHtSyiGj95I0TYnDKL+51N0LHakffofahMi4n6KCxU+oeLE6wGSXtaknrJO7Qffpzj/c1l6Px0o6Y8AJE2nGI67vn6hNHS5jOI98fz0vngPxTbdY3aKo9wJDaYNKyf3Omnc8F0UG/chikPQ5aXp3yedZAV2UozVN736o4EvUIzhb6AYCrgk1bsGOJ/iZNRDQD9wLoCKKwiuoTj8e1jSryjeNEdKujrV+/60zOp0ePwNih4VwE3AqhRzIx9Pr/Frkh4GVgMntfGaDgWuaHT4HRFfAS4Hlqa41tLk5GFErKdINv9G0Xvqo7hctdK4dFq+L613G/AJ4E2lcyV/DfwIuI1i2Ohydn9vfDUiftrmOjcBtZPJWyl6ke9L9c6j2Idm14YCm/iOiito/gf4UET8uI0Qmi6berLXUpzMvSu9tr8FPlf3odaKj1GMh2+j2G/+q276Gyl6wf9LcaHCu/dWYaf2g5Sk+yguMPg5sBk4W9LBFO/BayKi2XDUO4FHKN6n36V43y4uTf+D9D7cSXGxwIXtxDYUFP6xjiGj4tK8t0ZEqyflasudC/RExAfryicBl0TEuR0K0cwy4Z77c8MjwC8blD9N0dM0M9uNe+5DaLA9dzOzdjm5m5llyMMyZmYZavcbiF0xfvz46OnpGe4wzMyeU26//fZtEdHwMswRkdx7enpYs2aPy7fNzGwAkuq/NPgsD8uYmWXIyd3MLENO7mZmGXJyNzPL0LAmd0l9khbt3LlzOMMwM8vOsCb3iFgREfPHjh07nGGYmWXHwzJmZhlycjczy9CI+BJTFT0Lbxj0shsvO72DkZiZjRzuuZuZZcjJ3cwsQ07uZmYZcnI3M8uQk7uZWYac3M3MMtSV5C7pYElrJL26G/WbmdnAWkrukhZLekDS2rrymZLWS+qXtLA06f3Ask4GamZmrWu1574EmFkukDQKuAqYBUwH5kqaLumVwI+BBzoYp5mZtaGlb6hGxM2SeuqKZwD9EbEBQNJSYDZwCHAwRcJ/TNLKiNhVX6ek+cB8gClTpgz6BZiZ2Z6q3H5gIrCp9HwzcFJEXAgg6VxgW6PEDhARi4BFAL29vVEhDjMzq9O1e8tExJK9zSOpD+ibNm1at8IwM9snVblaZgswufR8Uiprme/nbmbWHVWS+23AMZKmShoNzAGWdyYsMzOrotVLIa8DbgGOk7RZ0ryIeBq4ELgJuBtYFhHr2lm5f2bPzKw7Wr1aZm6T8pXAysGuPCJWACt6e3vPH2wdZma2J99+wMwsQ8Oa3D0sY2bWHcOa3H21jJlZd3hYxswsQx6WMTPLkIdlzMwy5GEZM7MMeVjGzCxDHpYxM8uQh2XMzDLk5G5mliEndzOzDPmEqplZhnxC1cwsQx6WMTPLkJO7mVmGnNzNzDLk5G5mliFfLWNmliFfLWNmliEPy5iZZcjJ3cwsQ07uZmYZcnI3M8uQk7uZWYac3M3MMuTr3M3MMuTr3M3MMuRhGTOzDDm5m5llyMndzCxDTu5mZhlycjczy5CTu5lZhpzczcwy5ORuZpYhJ3czswx1PLlLepGkqyV9SdLbOl2/mZntXUvJXdJiSQ9IWltXPlPSekn9khYCRMTdEbEAeB3wR50P2czM9qbVnvsSYGa5QNIo4CpgFjAdmCtpepp2BnADsLJjkZqZWctaSu4RcTOwva54BtAfERsi4klgKTA7zb88ImYB5zSrU9J8SWskrdm6devgojczs4b2r7DsRGBT6flm4CRJpwKvAcYwQM89IhYBiwB6e3ujQhxmZlanSnJvKCJWAatamVdSH9A3bdq0TodhZrZPq3K1zBZgcun5pFTWMt/P3cysO6ok99uAYyRNlTQamAMs70xYZmZWRauXQl4H3AIcJ2mzpHkR8TRwIXATcDewLCLWtbNy/8yemVl3tDTmHhFzm5SvpMLljhGxAljR29t7/mDrMDOzPfkHss3MMuQfyDYzy5BvHGZmliEndzOzDHnM3cwsQx3/hmo7hvtqmZ6FN1RafuNlp3coEjOzzvKwjJlZhjwsY2aWIV8KaWaWIQ/LmJllyMndzCxDTu5mZhnyCVUzswz5hKqZWYY8LGNmliEndzOzDDm5m5llyMndzCxDvlrGzCxDvlrGzCxDHpYxM8uQk7uZWYac3M3MMuTkbmaWISd3M7MMObmbmWXI17mbmWVo/+FceUSsAFb09vaeP5xxDFbPwhsGvezGy07vYCRmZrvzsIyZWYac3M3MMuTkbmaWISd3M7MMObmbmWXIyd3MLENO7mZmGXJyNzPLkJO7mVmGuvINVUlnAqcDhwKfioivdWM9ZmbWWMs9d0mLJT0gaW1d+UxJ6yX1S1oIEBHXR8T5wALg7M6GbGZme9POsMwSYGa5QNIo4CpgFjAdmCtpemmWD6TpZmY2hFpO7hFxM7C9rngG0B8RGyLiSWApMFuFy4EbI+KORvVJmi9pjaQ1W7duHWz8ZmbWQNUTqhOBTaXnm1PZO4FXAGdJWtBowYhYFBG9EdE7YcKEimGYmVlZV06oRsQVwBV7m09SH9A3bdq0boRhZrbPqtpz3wJMLj2flMpaEhErImL+2LFjK4ZhZmZlVZP7bcAxkqZKGg3MAZZXD8vMzKpo51LI64BbgOMkbZY0LyKeBi4EbgLuBpZFxLo26vTP7JmZdYEiYrhjoLe3N9asWTOoZav81N1zlX+iz8wAJN0eEb2NpvkHss3MMjSsyd0nVM3MusM3DjMzy5CTu5lZhjzmbmaWIY+5m5llyMMyZmYZ8rCMmVmGPCxjZpYhD8uYmWXIyd3MLENduZ+7dVeV++n4vjRm+wafUDUzy5BPqJqZZchj7mZmGXJyNzPLkJO7mVmGnNzNzDLkq2XMzDLkq2XMzDLkYRkzsww5uZuZZcjJ3cwsQ07uZmYZ8o3D9jFVbjoGvvGY2XOFe+5mZhnyde5mZhnyde5mZhnysIyZWYac3M3MMuTkbmaWISd3M7MMObmbmWXIX2KytlT5EpS/AGU2dNxzNzPLkJO7mVmGnNzNzDLU8eQu6WhJn5L0pU7XbWZmrWkpuUtaLOkBSWvrymdKWi+pX9JCgIjYEBHzuhGsmZm1ptWe+xJgZrlA0ijgKmAWMB2YK2l6R6MzM7NBaSm5R8TNwPa64hlAf+qpPwksBWa3umJJ8yWtkbRm69atLQdsZmZ7V2XMfSKwqfR8MzBR0gskXQ2cKOmiZgtHxKKI6I2I3gkTJlQIw8zM6nX8S0wR8SCwoJV5JfUBfdOmTet0GGZm+7QqPfctwOTS80mprGW+n7uZWXdUSe63AcdImippNDAHWN6ZsMzMrIqWhmUkXQecCoyXtBn4h4j4lKQLgZuAUcDiiFjXzso9LGOt8j1tzNrTUnKPiLlNylcCKwe78ohYAazo7e09f7B1mJnZnob1rpDuue9bqvS+h2u97vXbc5V/INvMLEO+cZiZWYaGNblL6pO0aOfOncMZhplZdjwsY2aWIQ/LmJllyMndzCxDHnM3M8uQx9zNzDLkYRkzsww5uZuZZcjJ3cwsQ763jNkAqt4Px/emseHiE6pmZhnysIyZWYac3M3MMuTkbmaWISd3M7MM+WoZswzti78+tS++5oH4ahkzswx5WMbMLENO7mZmGXJyNzPLkJO7mVmGnNzNzDLk5G5mliFf527WRVXvKjkcfCfMPPg6dzOzDHlYxswsQ07uZmYZcnI3M8uQk7uZWYac3M3MMuTkbmaWISd3M7MMObmbmWXIyd3MLEMdv/2ApIOBTwBPAqsi4vOdXoeZmQ2spZ67pMWSHpC0tq58pqT1kvolLUzFrwG+FBHnA2d0OF4zM2tBq8MyS4CZ5QJJo4CrgFnAdGCupOnAJGBTmu2ZzoRpZmbtaGlYJiJultRTVzwD6I+IDQCSlgKzgc0UCf5OBvjwkDQfmA8wZcqUduM2MxsRRupdNKucUJ3Ir3voUCT1icB/Aq+V9O/AimYLR8SiiOiNiN4JEyZUCMPMzOp1/IRqRDwCnNfKvL6fu5lZd1TpuW8BJpeeT0plLfP93M3MuqNKcr8NOEbSVEmjgTnA8nYqkNQnadHOnTsrhGFmZvVavRTyOuAW4DhJmyXNi4ingQuBm4C7gWURsa6dlbvnbmbWHa1eLTO3SflKYGVHIzIzs8qG9fYDHpYxM+sO/0C2mVmGfOMwM7MMKSKGOwYkbQXuHeTi44FtHQynExxT60ZiXI6pdSMxrn0ppqMiouG3QEdEcq9C0pqI6B3uOMocU+tGYlyOqXUjMS7HVPCwjJlZhpzczcwylENyXzTcATTgmFo3EuNyTK0biXE5JjIYczczsz3l0HM3M7M6Tu5mZhkaUcm9yW+ylqePkfTFNP3W8q9DSboola+XdFqrdXYrJkmvlHS7pB+l/39aWmZVqvPO9HfEEMbVI+mx0rqvLi3zeynefklXSNIQxXROKZ47Je2SdEKaVqmtWojpZZLukPS0pLPqpr1Z0k/T35tL5ZXaqUpckk6QdIukdZJ+KOns0rQlkn5WaqsThiKmNO2Z0nqXl8qnpm3dn7b96KGISdLL6/apxyWdmaZVaqcW43qPpB+nbfRNSUeVpnVtv9pNRIyIP2AUcA9wNDAauAuYXjfP24Gr0+M5wBfT4+lp/jHA1FTPqFbq7GJMJwJHpscvBraUllkF9A5TW/UAa5vU+33gZEDAjcCsoYipbp6XAPd0oq1ajKkH+B3gs8BZpfLDgQ3p/2Hp8WFV26kDcR0LHJMeHwncD4xLz5eU5x2qmNK0XzWpdxkwJz2+GnjbUMVUty23A8+r2k5txPXy0vrexq/ff13br+r/RlLP/dnfZI2IJ4Hab7KWzQY+kx5/Cfiz9Ok2G1gaEU9ExM+A/lRfK3V2JaaI+EFE3JfK1wEHSRrTxrq7ElezCiW9EDg0IlZHsad9FjhzGGKam5bthL3GFBEbI+KHwK66ZU8Dvh4R2yPiIeDrwMwOtFOluCLiJxHx0/T4PuABoBO/U1mlrRpK2/ZPKbY1FNv+zGGI6Szgxoh4tI11V43rv0vrW03xY0bQ3f1qNyMpuTf7TdaG80RxP/mdwAsGWLaVOrsVU9lrgTsi4olS2afTIeHfDeLwq2pcUyX9QNK3JZ1Smn/zXursZkw1ZwPX1ZUNtq2qbP+B9qkq7VQ1rmdJmkHRc7ynVHxpGgr4aJudiaoxHShpjaTVteEPim27I23rwdTZkXaiOEqs36cG206DiWseRU98oGU7sV/tZiQl9yxJOh64HLigVHxORLwEOCX9vXEIQ7ofmBIRJwLvAb4g6dAhXH9Tkk4CHo2ItaXi4WyrESv19D4HnBcRtV7rRcBvA79Pcdj//iEM6agovl7/euBjkn5rCNfdVGqnl1D8qFDNkLWTpDcAvcC/dGsdzYyk5N7Kb7I+O4+k/YGxwIMDLFv1d16rxISkScBXgDdFxLO9q4jYkv4/DHyB4jCvHYOOKw1dPZjWfztFr+/YNP+k0vJD2lbJHj2sim1VZfsPtE9VaaeqcZE+jG8ALo6I1bXyiLg/Ck8An2bo2qq8nTZQnCc5kWLbjkvbuu06q8aUvA74SkQ8VYq1Sju1HJekVwAXA2eUjtq7uV/trsqAfSf/KH4VagPFCdHaSYrj6+Z5B7ufkFuWHh/P7idUN1Cc9NhrnV2MaVya/zUN6hyfHh9AMR65YAjbagIwKj0+mmIHOjwan9B51VDElJ7vl2I5ulNt1c72p+4kG0WP7mcUJ70OS48rt1MH4hoNfBN4d4N5X5j+C/gYcNkQxXQYMCY9Hg/8lHSCEfgPdj+h+vahiKlUvhp4eafaqY19/USKjtMxdeVd26/2iLPKwp3+A14F/CQ1ysWp7B8pPvkADkw7S39qiHIiuDgtt57SWeZGdQ5FTMAHgEeAO0t/RwAHA7cDP6Q40fpxUrIdorhem9Z7J3AH0FeqsxdYm+q8kvQN5iHafqcCq+vqq9xWLcT0+xTjm49Q9DTXlZZ9S4q1n2L4oyPtVCUu4A3AU3X71Qlp2reAH6XYrgUOGaKY/jCt9670f16pzqPTtu5P237MEG6/HooOw351dVZqpxbj+gbwi9I2Wj4U+1X5z7cfMDPL0Egaczczsw5xcjczy5CTu5lZhpzczcwy5ORuZpYhJ3czsww5uZuZZej/AXJr3Uh4jUmCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(word_doc_freq, bins=20)\n",
    "plt.title('Распределение относительных частот слов')\n",
    "plt.yscale('log');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ed0faaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность матрицы признаков обучающей выборки (11941, 17342)\n",
      "\n",
      "Количество ненулевых элементов в обучающей выборке 619898\n",
      "Процент заполненности матрицы признаков 0.30%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "VECTORIZATION_MODE = 'tfidf'\n",
    "# построение матрицы признаков по методу мешка слов\n",
    "# функция vectorize_texts принимает на вход\n",
    "#1. токенизированные список списков\n",
    "#2. словарь\n",
    "#3. вектор частоты токенизированны\n",
    "#4. алгоритм взвешивания токенов по частоте mode - есть 4 алгорима - bin,tf,idf,tfidf\n",
    "#5. флаг чтобы перемаштабировать флаг после взвешивания\n",
    "\n",
    "train_vectors = vectorize_texts(train_tokenized, vocabulary, word_doc_freq, mode=VECTORIZATION_MODE)\n",
    "\n",
    "print('Размерность матрицы признаков обучающей выборки', train_vectors.shape)\n",
    "print()\n",
    "print('Количество ненулевых элементов в обучающей выборке', train_vectors.nnz)\n",
    "print('Процент заполненности матрицы признаков {:.2f}%'.format(train_vectors.nnz * 100 / (train_vectors.shape[0] * train_vectors.shape[1])))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "686d2508",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_t = api.load('glove-twitter-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7aa419ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "\n",
    "def get_vectors_gt100(row):\n",
    "    '''\n",
    "      word_doc_freq # частоты слов\n",
    "      train_tokenized #сами слова\n",
    "    '''\n",
    "    vecs = [np.zeros(100)]\n",
    "    for word in row:\n",
    "        #print(row)\n",
    "        try: \n",
    "            # если слово есть в нашем очищенном словаре\n",
    "            # умножаем вектор на вес tfidf\n",
    "            v = model_t[word] * word_doc_freq[vocabulary[word]] \n",
    "        except:\n",
    "            v = np.zeros(100)\n",
    "        vecs.append(v)\n",
    "    return np.sum(np.array(vecs),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1d2e5892",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gt100 = np.array([get_vectors_gt100(i) for i in train_tokenized])\n",
    "val_gt100 = np.array([get_vectors_gt100(i) for i in val_tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2730d1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('аналитик', 0.7176759243011475)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_t.most_similar(positive=['инвестор', 'рынок'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ddd22560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6989283322170127"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=12, max_iter=500)\n",
    "clf.fit(train_gt100, y_train)\n",
    "\n",
    "pred = clf.predict(val_gt100)\n",
    "accuracy_score(pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d2c095ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab1d92ddd3a245ec9bd195ace34b806a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x480676e00>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import catboost as cb\n",
    "\n",
    "np.random.seed(12)\n",
    "\n",
    "params = dict(\n",
    "    learning_rate=0.025,\n",
    "    iterations=10000,\n",
    "    reg_lambda=0.0005,\n",
    "    colsample_bylevel=1.,\n",
    "    max_bin=80,\n",
    "    bagging_temperature=2,\n",
    "    use_best_model=True,\n",
    "    verbose=False,\n",
    "    grow_policy='Depthwise',\n",
    "    random_seed=12\n",
    ")\n",
    "model = cb.CatBoostClassifier(\n",
    "    **params,\n",
    ")\n",
    "\n",
    "eval_set = cb.Pool(data=val_gt100, label=y_val)\n",
    "model.fit(train_gt100, y_train, eval_set=eval_set, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "81132739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6697923643670463"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(val_w2v)\n",
    "accuracy_score(pred, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
