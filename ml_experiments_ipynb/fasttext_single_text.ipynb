{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8495324f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Cython\n",
      "  Downloading Cython-0.29.33-py2.py3-none-any.whl (987 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m987.3/987.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Cython\n",
      "Successfully installed Cython-0.29.33\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# !pip install Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e0da7883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy2\n",
      "  Using cached pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "Collecting dawg-python>=0.7.1\n",
      "  Using cached DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Collecting docopt>=0.6\n",
      "  Using cached docopt-0.6.2-py2.py3-none-any.whl\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
      "  Using cached pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
     ]
    }
   ],
   "source": [
    "# !pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2f6ee630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm>=4.9.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.63.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install \"tqdm>=4.9.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "386b2622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fasttext==0.6.0\n",
      "  Using cached fasttext-0.6.0.tar.gz (57 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from fasttext==0.6.0) (1.23.4)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fasttext: filename=fasttext-0.6.0-cp310-cp310-macosx_10_9_universal2.whl size=205718 sha256=e418d441df760d7961cee6c7b4a5d30d02e68f73be2d7a9a66feb02cf566e96c\n",
      "  Stored in directory: /Users/buchkovv/Library/Caches/pip/wheels/d1/27/e9/355ddd858916c673b2bb4863938bb8ced0a30da2bf59eef646\n",
      "Successfully built fasttext\n",
      "Installing collected packages: fasttext\n",
      "Successfully installed fasttext-0.6.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install fasttext==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fcbc498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'fastText' already exists and is not an empty directory.\n",
      "Collecting fastText\n",
      "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m695.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pybind11>=2.2\n",
      "  Using cached pybind11-2.10.3-py3-none-any.whl (222 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from fastText) (58.1.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from fastText) (1.23.4)\n",
      "Building wheels for collected packages: fastText\n",
      "  Building wheel for fastText (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fastText: filename=fasttext-0.9.2-cp310-cp310-macosx_13_0_universal2.whl size=652139 sha256=0abf5605bfb2c8c2324e633910b7669b00697c99aabfad3c393e4ae96fe02d04\n",
      "  Stored in directory: /Users/buchkovv/Library/Caches/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
      "Successfully built fastText\n",
      "Installing collected packages: pybind11, fastText\n",
      "Successfully installed fastText-0.9.2 pybind11-2.10.3\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/facebookresearch/fastText.git\n",
    "# !cd fastText\n",
    "# !pip install fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42d28100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ccf1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e0f7322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function download_model in module fasttext.util.util:\n",
      "\n",
      "download_model(lang_id, if_exists='strict', dimension=None)\n",
      "    Download pre-trained common-crawl vectors from fastText's website\n",
      "    https://fasttext.cc/docs/en/crawl-vectors.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(fasttext.util.download_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34cdbfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# fasttext.util.download_model('ru', if_exists='ignore')\n",
    "ft = fasttext.load_model('cc.ru.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5b2382c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06434693, -0.01527086, -0.06963537, -0.03582602,  0.01471584,\n",
       "       -0.03503159,  0.02701715,  0.04161827, -0.00033126,  0.00355259,\n",
       "        0.06979205,  0.06205348,  0.05154078,  0.03831509, -0.02394784,\n",
       "       -0.03954181, -0.00189653, -0.11174394, -0.0407712 ,  0.09289949,\n",
       "       -0.07412342, -0.05209147,  0.02017231,  0.04837443,  0.02212641,\n",
       "        0.00856511, -0.03055364,  0.04733564,  0.04380886,  0.03856769,\n",
       "        0.03442968,  0.05576854,  0.01513439,  0.14055566,  0.03365337,\n",
       "       -0.02920472, -0.10305687, -0.09332671,  0.03085899, -0.11067575,\n",
       "       -0.08992791,  0.05850704, -0.017424  ,  0.00120653, -0.07153153,\n",
       "        0.10312843, -0.08066262, -0.00642456,  0.04408539, -0.05728461,\n",
       "       -0.0179531 ,  0.03936698,  0.04778077, -0.04907751, -0.00909553,\n",
       "        0.05588715, -0.00236535,  0.04878682, -0.01769035,  0.03295048,\n",
       "        0.00906604,  0.08772802,  0.02970458, -0.04903899, -0.03025401,\n",
       "       -0.04151824,  0.04931813, -0.02804473,  0.05716789,  0.03559401,\n",
       "       -0.12191223,  0.02087349, -0.05121018, -0.0584691 , -0.04781278,\n",
       "       -0.06298476, -0.00432743, -0.03785646, -0.08833752, -0.0375172 ,\n",
       "        0.04602968,  0.02096615,  0.00321184, -0.00927999, -0.00288017,\n",
       "        0.04345381, -0.0330169 ,  0.00840916, -0.05537616, -0.02134524,\n",
       "       -0.03705332,  0.06453154, -0.01733523, -0.01977487, -0.02836509,\n",
       "        0.01901042,  0.04043126, -0.07048826, -0.09381784, -0.02532577,\n",
       "       -0.02679786,  0.01097633, -0.01681483, -0.08134623,  0.00429079,\n",
       "       -0.07213577, -0.03950587,  0.07274695, -0.00337509,  0.05469057,\n",
       "       -0.01510826, -0.05297935,  0.04232059, -0.04494021, -0.01873806,\n",
       "        0.02970697, -0.02128338, -0.07461107,  0.04457341,  0.02913763,\n",
       "       -0.05406609,  0.06825955, -0.0423348 , -0.01933457,  0.00638132,\n",
       "        0.00075826,  0.10154837, -0.06699109, -0.01374834,  0.10683898,\n",
       "        0.06719182,  0.00299954,  0.03092229, -0.01919586,  0.02315286,\n",
       "        0.02552165,  0.0297376 ,  0.0476847 , -0.06794806,  0.01934321,\n",
       "        0.07793375,  0.04631811,  0.07487484, -0.06923444, -0.09797966,\n",
       "       -0.02230856,  0.04383751,  0.05814477,  0.09182699,  0.0407513 ,\n",
       "        0.06562199,  0.06420117, -0.12618978, -0.00895569, -0.03637737,\n",
       "        0.0323772 ,  0.05442533,  0.02233687,  0.0607053 , -0.03511162,\n",
       "       -0.02011008, -0.04657565, -0.1363746 , -0.09366813, -0.01257268,\n",
       "       -0.0822741 ,  0.04026463,  0.08941573,  0.05416025, -0.00148568,\n",
       "        0.02470817, -0.01521165,  0.06688396,  0.01970377, -0.067048  ,\n",
       "        0.05173868, -0.06437217,  0.02638604,  0.02355881, -0.03286408,\n",
       "       -0.01542088,  0.0226214 ,  0.01009578, -0.06503511,  0.05164307,\n",
       "        0.08621447, -0.00291589,  0.0201317 ,  0.05789564,  0.04330945,\n",
       "       -0.01468945,  0.00915974,  0.02692279,  0.07124459, -0.05370982,\n",
       "        0.04218086,  0.00314814,  0.00356758, -0.02068229,  0.0604349 ,\n",
       "       -0.08158811,  0.04939371,  0.0430281 , -0.03372736, -0.0558867 ,\n",
       "        0.00376545, -0.037087  ,  0.05940549,  0.02495521, -0.00334628,\n",
       "        0.01005986, -0.02053031,  0.01179219,  0.07010209, -0.10397089,\n",
       "        0.07733957,  0.06056703,  0.01003617, -0.15787463, -0.01765688,\n",
       "        0.00765593, -0.01905038,  0.01327723,  0.01084452, -0.05930451,\n",
       "       -0.07062402, -0.08540855,  0.01374613, -0.03077546, -0.04025275,\n",
       "        0.00268231, -0.06844234,  0.05945092,  0.02234607,  0.14669767,\n",
       "        0.03161074, -0.03626112,  0.13065669, -0.02795461,  0.00260858,\n",
       "        0.02103085, -0.01555263,  0.02790887, -0.02395738, -0.10259839,\n",
       "       -0.01162906,  0.07939966,  0.01229805,  0.0472665 ,  0.00792722,\n",
       "        0.07495239, -0.04777352,  0.02290227, -0.02349729, -0.01035224,\n",
       "       -0.04128299, -0.05037197, -0.02936148, -0.03995599, -0.09582971,\n",
       "        0.00652219, -0.00309965,  0.09921778, -0.07993053, -0.07525942,\n",
       "       -0.03148453, -0.03216294,  0.00986726, -0.03059178, -0.01402058,\n",
       "        0.02519003, -0.04734642,  0.12286284, -0.09953459,  0.01202545,\n",
       "        0.03934894,  0.07455902,  0.02744922,  0.03999532, -0.05147249,\n",
       "       -0.0055727 ,  0.07064351,  0.07526451,  0.00223117,  0.01765039,\n",
       "       -0.02785274,  0.0251571 ,  0.05081079,  0.06183068, -0.03087618,\n",
       "       -0.00268458, -0.02822061, -0.05344585, -0.05139395,  0.00151552,\n",
       "       -0.01931686,  0.00034288, -0.01423903,  0.00377267, -0.0598783 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft['привет']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f2fecc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "def get_tweet_embedding(lemmas, model, embedding_size=300):\n",
    "    \n",
    "    res = np.zeros(embedding_size)\n",
    "    cnt = 0\n",
    "    for word in lemmas.split():\n",
    "        if word in model:\n",
    "            res += np.array(model[word])\n",
    "            cnt += 1\n",
    "    if cnt:\n",
    "        res = res / cnt\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17ef304c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.84749218e-02,  1.14055865e-02, -1.54750008e-02,  6.10717852e-03,\n",
       "       -5.42343501e-03,  2.83443742e-03,  2.40256451e-03,  1.29073053e-02,\n",
       "        3.05031866e-02, -1.99234379e-02,  6.13203850e-02,  4.42768331e-02,\n",
       "        2.71531800e-02, -1.02064133e-02,  9.22483567e-04,  2.50384058e-02,\n",
       "       -1.25383004e-02, -4.89095808e-02, -3.07890818e-02,  1.01918663e-01,\n",
       "       -2.85800546e-02, -1.05811988e-01, -1.28629373e-02,  2.95597422e-02,\n",
       "        2.13206490e-03,  1.26906892e-02, -2.97227059e-02,  2.77029723e-02,\n",
       "       -1.21254625e-02, -4.76178443e-02, -6.68591424e-03,  3.05985650e-02,\n",
       "        3.59081652e-02,  1.02970391e-01,  3.62780495e-02, -5.56655712e-02,\n",
       "       -1.11200343e-01, -1.16946280e-01,  4.69890856e-02, -5.79430675e-02,\n",
       "       -4.56299540e-03, -2.32621958e-03, -2.30524363e-03,  1.96370891e-02,\n",
       "       -1.68996924e-02,  4.77626729e-02, -7.71877861e-02,  2.95996453e-02,\n",
       "        3.40769021e-02, -3.43663241e-02,  5.55797149e-02,  1.05126291e-02,\n",
       "        9.77615127e-03,  3.99762448e-02, -2.15159254e-02,  1.93620831e-02,\n",
       "       -1.34500194e-02,  2.17238814e-03,  1.39238648e-02, -1.24853794e-02,\n",
       "       -5.08000248e-02,  6.46954067e-02,  3.07824350e-02, -4.07074159e-02,\n",
       "       -1.99913508e-02,  1.96010725e-02, -1.52623175e-02, -1.58499312e-02,\n",
       "       -4.72955415e-02,  4.77682170e-03, -5.21384678e-02,  3.73177927e-02,\n",
       "       -3.41336881e-02,  5.90577209e-03,  6.41630217e-03, -2.70765051e-02,\n",
       "       -5.57585534e-02, -9.87857254e-03, -1.75393135e-02, -3.92743144e-02,\n",
       "        2.59191706e-02,  3.97690022e-02,  5.75262937e-03, -4.60929359e-02,\n",
       "        3.89499759e-03,  3.79725420e-02, -6.47511277e-02,  5.06016524e-02,\n",
       "        1.29573480e-02,  9.16208606e-04, -1.10791333e-01, -1.59734851e-02,\n",
       "        4.38956684e-03, -5.00591882e-02, -1.91273557e-02, -1.31234950e-02,\n",
       "        4.23284452e-02, -1.32317897e-02, -9.03501306e-02,  4.14077961e-02,\n",
       "       -9.01901850e-03,  7.61899361e-02, -1.04387742e-02, -1.22785277e-02,\n",
       "       -1.63511078e-02, -3.89259742e-02,  4.25888405e-02,  2.55549918e-02,\n",
       "        7.98778998e-03,  9.49782273e-03, -3.10476529e-02, -1.09063331e-02,\n",
       "        8.43151626e-02, -3.58087434e-02, -1.24211812e-02, -1.87083688e-02,\n",
       "       -5.45124998e-02, -8.86561619e-02,  3.79863534e-02, -3.31068560e-02,\n",
       "       -4.89519509e-02,  7.88756466e-02, -5.50974393e-02,  1.60968699e-02,\n",
       "        1.01266545e-03,  2.75706507e-02,  5.04551297e-02, -1.64009025e-02,\n",
       "        1.19224258e-02,  6.78465860e-02,  2.69761501e-02,  1.12457192e-02,\n",
       "        1.86175751e-02, -1.40191410e-02, -1.72757215e-02,  5.70655339e-02,\n",
       "        5.77574829e-04,  5.24380505e-02, -5.08161918e-03,  3.53807122e-02,\n",
       "       -1.40902330e-02,  2.29508245e-02,  6.68836981e-02, -2.08306434e-02,\n",
       "       -5.37150722e-02, -9.75077925e-03, -4.46044868e-02,  3.50373158e-02,\n",
       "        5.37473205e-02,  2.23793560e-02,  3.78368636e-02,  1.91988172e-02,\n",
       "       -9.24861385e-02,  1.07819675e-02, -1.21989548e-02,  3.31418150e-02,\n",
       "        2.23143799e-02,  1.49282608e-02,  1.40205264e-02, -2.72367133e-02,\n",
       "       -2.69449629e-02,  2.49509839e-03, -5.19380664e-02, -6.78124642e-02,\n",
       "       -6.38052975e-02,  1.68222875e-02, -7.74696337e-02,  8.44685482e-02,\n",
       "        4.74610087e-02, -2.62326931e-03, -9.03137206e-03, -6.54254213e-02,\n",
       "        4.35586069e-02,  3.72354283e-02, -3.41950073e-02, -1.16772181e-02,\n",
       "       -3.14856721e-02,  6.10582798e-02,  4.79020393e-02, -4.82062241e-02,\n",
       "       -1.99088580e-02,  3.10592290e-02, -4.53291640e-02, -6.53951182e-02,\n",
       "        6.01363019e-04,  3.27027021e-02,  1.47671076e-02, -3.70643544e-02,\n",
       "       -2.04997172e-02,  5.32348915e-02, -4.50411410e-02,  1.28656339e-02,\n",
       "        3.19320844e-02,  1.45057300e-02, -1.72404865e-02,  3.71150244e-02,\n",
       "       -2.15479551e-02, -1.15545052e-02, -1.25362631e-02,  2.60218652e-02,\n",
       "       -4.58280314e-02,  7.53374584e-03,  7.35389721e-03, -1.82377142e-02,\n",
       "       -9.48007656e-02, -2.56354164e-02,  5.40375593e-04,  4.41152531e-02,\n",
       "       -7.10717402e-04,  4.32135077e-03,  2.78144046e-02, -4.11721691e-03,\n",
       "       -8.98516446e-04,  5.58417288e-02, -3.63211357e-02, -6.08586776e-03,\n",
       "        3.32013650e-02,  3.86003682e-02, -4.08708490e-02,  1.05813891e-02,\n",
       "        1.79253643e-02,  3.97888436e-02,  3.22979216e-02,  1.34046650e-02,\n",
       "       -3.69763831e-02,  3.80074000e-02, -3.84184653e-02, -1.46874161e-02,\n",
       "        1.31309093e-02, -1.08475601e-02,  1.34081137e-02, -1.17426082e-02,\n",
       "        1.28444180e-01, -2.20539912e-02,  1.15903737e-01,  5.90186799e-03,\n",
       "        1.24620628e-02,  7.31505433e-02, -7.99386785e-03,  3.64330948e-02,\n",
       "        3.45786135e-02,  3.46622248e-02,  2.36364873e-03, -7.05305371e-02,\n",
       "       -5.42092409e-02, -8.53608083e-03, -5.25069842e-03, -6.02257324e-02,\n",
       "        2.03989604e-02, -1.16195149e-02,  9.21856882e-02, -6.69648121e-02,\n",
       "        7.29324436e-03,  2.93620190e-02,  6.43402617e-02,  1.59824028e-02,\n",
       "        2.18187862e-02, -1.51119323e-03, -8.90493509e-03, -1.16167957e-01,\n",
       "        3.43116624e-02, -2.22888631e-02,  6.75987527e-02,  2.60055298e-02,\n",
       "       -2.21864720e-02, -2.88950545e-02,  5.87026319e-02,  5.31624537e-05,\n",
       "        4.37127347e-02, -3.44873604e-02,  1.45444367e-02,  4.66503901e-04,\n",
       "        1.16275493e-01, -7.23772724e-02,  3.08836906e-02,  3.09007196e-03,\n",
       "        1.63774043e-02,  1.35315594e-02,  3.91931003e-02, -3.61349685e-02,\n",
       "        8.19852925e-04,  2.57454347e-04,  6.94709985e-03,  1.86907215e-02,\n",
       "       -3.81673360e-03,  1.24494154e-02, -2.23289109e-02, -3.35482652e-02,\n",
       "       -4.22900976e-02,  2.49405606e-02,  4.42143134e-03,  5.85364044e-03,\n",
       "        3.19063303e-03, -4.88638142e-02, -1.23414861e-02, -1.29953995e-02,\n",
       "        1.96110924e-02,  1.76430468e-02,  9.77955939e-03, -1.76622996e-02])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 'привет всем слушателям курса'\n",
    "get_tweet_embedding(x, model=ft, embedding_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d77a274",
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKTEST_CCY = 'USDRUB'\n",
    "BACKTEST_DAYS = 5\n",
    "\n",
    "PATH_TEXTS = 'data/telegram'\n",
    "PATH_OPT_PNL = 'data/pnl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9b3272b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cbonds.csv',\n",
       " 'themovchans.csv',\n",
       " 'headlines_QUANTS.csv',\n",
       " 'War_Wealth_Wisdom.csv',\n",
       " 'mmi.csv',\n",
       " 'vts.csv',\n",
       " 'signal.csv',\n",
       " '.gitignore',\n",
       " 'rshb_invest.csv',\n",
       " 'Alfa_Wealth.csv',\n",
       " 'sky_bond.csv',\n",
       " 'bitkogan.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all available data_sources\n",
    "sources = os.listdir(PATH_TEXTS)\n",
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c00cad9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_start</th>\n",
       "      <th>pnl</th>\n",
       "      <th>pnl_sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>291264.097914</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>-411993.830320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>521491.686795</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>62842.634116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-11</td>\n",
       "      <td>-537598.706217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2021-12-20</td>\n",
       "      <td>-407527.554561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2021-12-21</td>\n",
       "      <td>-176881.417077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>-206943.414418</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>23073.596468</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>283960.438531</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_start            pnl  pnl_sign\n",
       "0    2021-01-04  291264.097914         1\n",
       "1    2021-01-05 -411993.830320         0\n",
       "2    2021-01-06  521491.686795         1\n",
       "3    2021-01-08   62842.634116         1\n",
       "4    2021-01-11 -537598.706217         0\n",
       "..          ...            ...       ...\n",
       "245  2021-12-20 -407527.554561         0\n",
       "246  2021-12-21 -176881.417077         0\n",
       "247  2021-12-22 -206943.414418         0\n",
       "248  2021-12-23   23073.596468         1\n",
       "249  2021-12-24  283960.438531         1\n",
       "\n",
       "[250 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create target variable dataframe\n",
    "pnl = pd.read_csv(f'{PATH_OPT_PNL}/Backtest_{BACKTEST_CCY}_{BACKTEST_DAYS}_days.txt')\n",
    "pnl['date_start'] = pd.to_datetime(pnl['date_start']).dt.strftime('%Y-%m-%d')\n",
    "pnl['pnl_sign'] = pnl['pnl'].apply(lambda x: 1 if x >= 0 else 0)\n",
    "pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c052489b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.536"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get balance of the sample\n",
    "pnl['pnl_sign'].sum() / pnl.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f953b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "\n",
    "def _binary_search_by_date(array: List[Tuple[dt.datetime, float]], date_x: dt.datetime) -> Union[int, None]:\n",
    "    \"\"\"\n",
    "    Searches for the index of date_x in the array via binary search.\n",
    "\n",
    "        Parameters:\n",
    "            array (list) : A sorted array of (date, float_value) tuples\n",
    "            date_x (datetime.datetime) : Date to search for\n",
    "\n",
    "        Returns:\n",
    "            index_x (int): Index of the searched date in the array.\n",
    "    \"\"\"\n",
    "    left = 0\n",
    "    right = len(array) - 1\n",
    "\n",
    "    while left <= right:\n",
    "        mid = left + (right - left) // 2\n",
    "\n",
    "        if array[mid - 1][0] <= date_x <= array[mid][0]:\n",
    "            return mid\n",
    "        elif date_x > array[mid - 1][0] and date_x > array[mid][0]:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def binary_search_time_series(time_series: List[Tuple[dt.datetime, float]], date_start: dt.datetime,\n",
    "                              date_end: dt.datetime) -> Union[List[Tuple[dt.datetime, float]], None]:\n",
    "    \"\"\"\n",
    "    Searches for the part of the time series that is contained inside [date_start; date_end] period via binary search.\n",
    "\n",
    "        Parameters:\n",
    "            time_series (list) : A sorted array of (date, float_value) tuples\n",
    "            date_start (datetime.datetime) : Starting date of the searched period\n",
    "            date_end (datetime.datetime) : Ending date of the searched period\n",
    "\n",
    "        Returns:\n",
    "            time_series_data (list): Part of the time series that is contained inside [date_start; date_end] period.\n",
    "    \"\"\"\n",
    "\n",
    "    if date_start <= date_end:\n",
    "        left_index = _binary_search_by_date(time_series, date_start)\n",
    "        \n",
    "        if left_index is None:\n",
    "            return None\n",
    "        \n",
    "        right_index = _binary_search_by_date(time_series[left_index:], date_end)\n",
    "        \n",
    "        if right_index is None:\n",
    "            return None\n",
    "        \n",
    "        right_index += left_index\n",
    "    else:\n",
    "        left_index = _binary_search_by_date(time_series, date_end)\n",
    "        \n",
    "        if left_index is None:\n",
    "            return None\n",
    "        \n",
    "        right_index = _binary_search_by_date(time_series[left_index:], date_start)\n",
    "        \n",
    "        if right_index is None:\n",
    "            return None\n",
    "        \n",
    "        right_index += left_index\n",
    "    \n",
    "    return time_series[left_index:right_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19fac87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.datetime(2021, 1, 4, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 5, 0, 0), 0),\n",
       " (datetime.datetime(2021, 1, 6, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 8, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 11, 0, 0), 0),\n",
       " (datetime.datetime(2021, 1, 12, 0, 0), 0),\n",
       " (datetime.datetime(2021, 1, 13, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 14, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 15, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 18, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 19, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 20, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 21, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 22, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 25, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 26, 0, 0), 0),\n",
       " (datetime.datetime(2021, 1, 27, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 28, 0, 0), 1),\n",
       " (datetime.datetime(2021, 1, 29, 0, 0), 1),\n",
       " (datetime.datetime(2021, 2, 1, 0, 0), 0),\n",
       " (datetime.datetime(2021, 2, 2, 0, 0), 0),\n",
       " (datetime.datetime(2021, 2, 3, 0, 0), 0),\n",
       " (datetime.datetime(2021, 2, 4, 0, 0), 0),\n",
       " (datetime.datetime(2021, 2, 5, 0, 0), 0),\n",
       " (datetime.datetime(2021, 2, 8, 0, 0), 0),\n",
       " (datetime.datetime(2021, 2, 9, 0, 0), 0),\n",
       " (datetime.datetime(2021, 2, 10, 0, 0), 1),\n",
       " (datetime.datetime(2021, 2, 11, 0, 0), 0),\n",
       " (datetime.datetime(2021, 2, 12, 0, 0), 0),\n",
       " (datetime.datetime(2021, 2, 15, 0, 0), 1),\n",
       " (datetime.datetime(2021, 2, 16, 0, 0), 1),\n",
       " (datetime.datetime(2021, 2, 17, 0, 0), 1),\n",
       " (datetime.datetime(2021, 2, 18, 0, 0), 1),\n",
       " (datetime.datetime(2021, 2, 19, 0, 0), 1),\n",
       " (datetime.datetime(2021, 2, 22, 0, 0), 1),\n",
       " (datetime.datetime(2021, 2, 24, 0, 0), 1),\n",
       " (datetime.datetime(2021, 2, 25, 0, 0), 1),\n",
       " (datetime.datetime(2021, 2, 26, 0, 0), 0),\n",
       " (datetime.datetime(2021, 3, 1, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 2, 0, 0), 0),\n",
       " (datetime.datetime(2021, 3, 3, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 4, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 5, 0, 0), 0),\n",
       " (datetime.datetime(2021, 3, 9, 0, 0), 0),\n",
       " (datetime.datetime(2021, 3, 10, 0, 0), 0),\n",
       " (datetime.datetime(2021, 3, 11, 0, 0), 0),\n",
       " (datetime.datetime(2021, 3, 12, 0, 0), 0),\n",
       " (datetime.datetime(2021, 3, 15, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 16, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 17, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 18, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 19, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 22, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 23, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 24, 0, 0), 0),\n",
       " (datetime.datetime(2021, 3, 25, 0, 0), 0),\n",
       " (datetime.datetime(2021, 3, 26, 0, 0), 0),\n",
       " (datetime.datetime(2021, 3, 29, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 30, 0, 0), 1),\n",
       " (datetime.datetime(2021, 3, 31, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 1, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 2, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 5, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 6, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 7, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 8, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 9, 0, 0), 0),\n",
       " (datetime.datetime(2021, 4, 12, 0, 0), 0),\n",
       " (datetime.datetime(2021, 4, 13, 0, 0), 0),\n",
       " (datetime.datetime(2021, 4, 14, 0, 0), 0),\n",
       " (datetime.datetime(2021, 4, 15, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 16, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 19, 0, 0), 0),\n",
       " (datetime.datetime(2021, 4, 20, 0, 0), 0),\n",
       " (datetime.datetime(2021, 4, 21, 0, 0), 0),\n",
       " (datetime.datetime(2021, 4, 22, 0, 0), 0),\n",
       " (datetime.datetime(2021, 4, 23, 0, 0), 0),\n",
       " (datetime.datetime(2021, 4, 26, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 27, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 28, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 29, 0, 0), 1),\n",
       " (datetime.datetime(2021, 4, 30, 0, 0), 1),\n",
       " (datetime.datetime(2021, 5, 4, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 5, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 6, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 7, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 10, 0, 0), 1),\n",
       " (datetime.datetime(2021, 5, 11, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 12, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 13, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 14, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 17, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 18, 0, 0), 1),\n",
       " (datetime.datetime(2021, 5, 19, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 20, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 21, 0, 0), 1),\n",
       " (datetime.datetime(2021, 5, 24, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 25, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 26, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 27, 0, 0), 0),\n",
       " (datetime.datetime(2021, 5, 28, 0, 0), 1),\n",
       " (datetime.datetime(2021, 5, 31, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 1, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 2, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 3, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 4, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 7, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 8, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 9, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 10, 0, 0), 1),\n",
       " (datetime.datetime(2021, 6, 11, 0, 0), 1),\n",
       " (datetime.datetime(2021, 6, 14, 0, 0), 1),\n",
       " (datetime.datetime(2021, 6, 15, 0, 0), 1),\n",
       " (datetime.datetime(2021, 6, 16, 0, 0), 1),\n",
       " (datetime.datetime(2021, 6, 17, 0, 0), 1),\n",
       " (datetime.datetime(2021, 6, 18, 0, 0), 1),\n",
       " (datetime.datetime(2021, 6, 21, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 22, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 23, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 24, 0, 0), 0),\n",
       " (datetime.datetime(2021, 6, 25, 0, 0), 1),\n",
       " (datetime.datetime(2021, 6, 28, 0, 0), 1),\n",
       " (datetime.datetime(2021, 6, 29, 0, 0), 1),\n",
       " (datetime.datetime(2021, 6, 30, 0, 0), 1),\n",
       " (datetime.datetime(2021, 7, 1, 0, 0), 1),\n",
       " (datetime.datetime(2021, 7, 2, 0, 0), 1),\n",
       " (datetime.datetime(2021, 7, 5, 0, 0), 1),\n",
       " (datetime.datetime(2021, 7, 6, 0, 0), 1),\n",
       " (datetime.datetime(2021, 7, 7, 0, 0), 0),\n",
       " (datetime.datetime(2021, 7, 8, 0, 0), 0),\n",
       " (datetime.datetime(2021, 7, 9, 0, 0), 1),\n",
       " (datetime.datetime(2021, 7, 12, 0, 0), 0),\n",
       " (datetime.datetime(2021, 7, 13, 0, 0), 1),\n",
       " (datetime.datetime(2021, 7, 14, 0, 0), 1),\n",
       " (datetime.datetime(2021, 7, 15, 0, 0), 1),\n",
       " (datetime.datetime(2021, 7, 16, 0, 0), 0),\n",
       " (datetime.datetime(2021, 7, 19, 0, 0), 0),\n",
       " (datetime.datetime(2021, 7, 20, 0, 0), 0),\n",
       " (datetime.datetime(2021, 7, 21, 0, 0), 0),\n",
       " (datetime.datetime(2021, 7, 22, 0, 0), 1),\n",
       " (datetime.datetime(2021, 7, 23, 0, 0), 1),\n",
       " (datetime.datetime(2021, 7, 26, 0, 0), 0),\n",
       " (datetime.datetime(2021, 7, 27, 0, 0), 0),\n",
       " (datetime.datetime(2021, 7, 28, 0, 0), 0),\n",
       " (datetime.datetime(2021, 7, 29, 0, 0), 0),\n",
       " (datetime.datetime(2021, 7, 30, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 2, 0, 0), 1),\n",
       " (datetime.datetime(2021, 8, 3, 0, 0), 1),\n",
       " (datetime.datetime(2021, 8, 4, 0, 0), 1),\n",
       " (datetime.datetime(2021, 8, 5, 0, 0), 1),\n",
       " (datetime.datetime(2021, 8, 6, 0, 0), 1),\n",
       " (datetime.datetime(2021, 8, 9, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 10, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 11, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 12, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 13, 0, 0), 1),\n",
       " (datetime.datetime(2021, 8, 16, 0, 0), 1),\n",
       " (datetime.datetime(2021, 8, 17, 0, 0), 1),\n",
       " (datetime.datetime(2021, 8, 18, 0, 0), 1),\n",
       " (datetime.datetime(2021, 8, 19, 0, 0), 1),\n",
       " (datetime.datetime(2021, 8, 20, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 23, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 24, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 25, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 26, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 27, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 30, 0, 0), 0),\n",
       " (datetime.datetime(2021, 8, 31, 0, 0), 0),\n",
       " (datetime.datetime(2021, 9, 1, 0, 0), 0),\n",
       " (datetime.datetime(2021, 9, 2, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 3, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 6, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 7, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 8, 0, 0), 0),\n",
       " (datetime.datetime(2021, 9, 9, 0, 0), 0),\n",
       " (datetime.datetime(2021, 9, 10, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 13, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 14, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 15, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 16, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 17, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 20, 0, 0), 0),\n",
       " (datetime.datetime(2021, 9, 21, 0, 0), 0),\n",
       " (datetime.datetime(2021, 9, 22, 0, 0), 0),\n",
       " (datetime.datetime(2021, 9, 23, 0, 0), 0),\n",
       " (datetime.datetime(2021, 9, 24, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 27, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 28, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 29, 0, 0), 1),\n",
       " (datetime.datetime(2021, 9, 30, 0, 0), 1),\n",
       " (datetime.datetime(2021, 10, 1, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 4, 0, 0), 1),\n",
       " (datetime.datetime(2021, 10, 5, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 6, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 7, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 8, 0, 0), 1),\n",
       " (datetime.datetime(2021, 10, 11, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 12, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 13, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 14, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 15, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 18, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 19, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 20, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 21, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 22, 0, 0), 0),\n",
       " (datetime.datetime(2021, 10, 25, 0, 0), 1),\n",
       " (datetime.datetime(2021, 10, 26, 0, 0), 1),\n",
       " (datetime.datetime(2021, 10, 27, 0, 0), 1),\n",
       " (datetime.datetime(2021, 10, 28, 0, 0), 1),\n",
       " (datetime.datetime(2021, 10, 29, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 1, 0, 0), 0),\n",
       " (datetime.datetime(2021, 11, 2, 0, 0), 0),\n",
       " (datetime.datetime(2021, 11, 3, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 5, 0, 0), 0),\n",
       " (datetime.datetime(2021, 11, 8, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 9, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 10, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 11, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 12, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 15, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 16, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 17, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 18, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 19, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 22, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 23, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 24, 0, 0), 1),\n",
       " (datetime.datetime(2021, 11, 25, 0, 0), 0),\n",
       " (datetime.datetime(2021, 11, 26, 0, 0), 0),\n",
       " (datetime.datetime(2021, 11, 29, 0, 0), 0),\n",
       " (datetime.datetime(2021, 11, 30, 0, 0), 0),\n",
       " (datetime.datetime(2021, 12, 1, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 2, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 3, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 6, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 7, 0, 0), 0),\n",
       " (datetime.datetime(2021, 12, 8, 0, 0), 0),\n",
       " (datetime.datetime(2021, 12, 9, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 10, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 13, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 14, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 15, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 16, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 17, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 20, 0, 0), 0),\n",
       " (datetime.datetime(2021, 12, 21, 0, 0), 0),\n",
       " (datetime.datetime(2021, 12, 22, 0, 0), 0),\n",
       " (datetime.datetime(2021, 12, 23, 0, 0), 1),\n",
       " (datetime.datetime(2021, 12, 24, 0, 0), 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnl_sign_ts = [(pd.to_datetime(row['date_start']).to_pydatetime(), row['pnl_sign']) for  _, row in pnl.iterrows()]\n",
    "pnl_sign_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "aaf278da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sr/lzvmv9j54ks_jl4x99t250r00000gn/T/ipykernel_81743/371081446.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(source_data)\n",
      "/var/folders/sr/lzvmv9j54ks_jl4x99t250r00000gn/T/ipykernel_81743/371081446.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(source_data)\n",
      "/var/folders/sr/lzvmv9j54ks_jl4x99t250r00000gn/T/ipykernel_81743/371081446.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(source_data)\n",
      "/var/folders/sr/lzvmv9j54ks_jl4x99t250r00000gn/T/ipykernel_81743/371081446.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(source_data)\n",
      "/var/folders/sr/lzvmv9j54ks_jl4x99t250r00000gn/T/ipykernel_81743/371081446.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(source_data)\n",
      "/var/folders/sr/lzvmv9j54ks_jl4x99t250r00000gn/T/ipykernel_81743/371081446.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(source_data)\n",
      "/var/folders/sr/lzvmv9j54ks_jl4x99t250r00000gn/T/ipykernel_81743/371081446.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(source_data)\n",
      "/var/folders/sr/lzvmv9j54ks_jl4x99t250r00000gn/T/ipykernel_81743/371081446.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(source_data)\n",
      "/var/folders/sr/lzvmv9j54ks_jl4x99t250r00000gn/T/ipykernel_81743/371081446.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(source_data)\n",
      "/var/folders/sr/lzvmv9j54ks_jl4x99t250r00000gn/T/ipykernel_81743/371081446.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(source_data)\n",
      "/var/folders/sr/lzvmv9j54ks_jl4x99t250r00000gn/T/ipykernel_81743/371081446.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(source_data)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>2017-07-28T10:56:14</td>\n",
       "      <td>Cbonds.ru  запустило канал в Telegram. Планиру...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>2017-08-03T15:28:17</td>\n",
       "      <td>Облигационный бюллетень Cbonds – все данные о ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-08-03T15:41:02</td>\n",
       "      <td>Cbonds prepared monthly report: CBONDS GLOBAL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>2017-08-03T18:11:32</td>\n",
       "      <td>Дайджест Cbonds от  3 августа:«Группа Компаний...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>2017-08-04T12:42:41</td>\n",
       "      <td>Совкомбанк открыл книгу заявок на вторичное ра...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                 date                                               text\n",
       "0   9  2017-07-28T10:56:14  Cbonds.ru  запустило канал в Telegram. Планиру...\n",
       "1  10  2017-08-03T15:28:17  Облигационный бюллетень Cbonds – все данные о ...\n",
       "2  11  2017-08-03T15:41:02  Cbonds prepared monthly report: CBONDS GLOBAL ...\n",
       "3  12  2017-08-03T18:11:32  Дайджест Cbonds от  3 августа:«Группа Компаний...\n",
       "4  13  2017-08-04T12:42:41  Совкомбанк открыл книгу заявок на вторичное ра..."
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate dataframes\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for s in sources:\n",
    "    if s != '.gitignore':\n",
    "        source_data = pd.read_csv(f'{PATH_TEXTS}/{s}')\n",
    "        df = df.append(source_data)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "53d077c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_date = pnl_sign_ts[0][0]\n",
    "\n",
    "# for i, row in df.iterrows():\n",
    "#     date_x = pd.to_datetime(row['date']).to_pydatetime()\n",
    "#     pnl_sign_key = _binary_search_by_date(pnl_sign_ts, date_x)\n",
    "    \n",
    "#     if pnl_sign_key is not None and date_x >= initial_date:\n",
    "#         df.loc[df.index[i], 'pnl_sign'] = pnl_sign_ts[_binary_search_by_date(pnl_sign_ts, date_x)][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a3d7b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_date = pnl_sign_ts[0][0]\n",
    "\n",
    "def get_pnl_sign(row):\n",
    "    date_x = pd.to_datetime(row['date']).to_pydatetime()\n",
    "    pnl_sign_key = _binary_search_by_date(pnl_sign_ts, date_x)\n",
    "    \n",
    "    if pnl_sign_key is not None and date_x >= initial_date:\n",
    "        return pnl_sign_ts[_binary_search_by_date(pnl_sign_ts, date_x)][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "75961477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>pnl_sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>2017-07-28T10:56:14</td>\n",
       "      <td>Cbonds.ru  запустило канал в Telegram. Планиру...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>2017-08-03T15:28:17</td>\n",
       "      <td>Облигационный бюллетень Cbonds – все данные о ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-08-03T15:41:02</td>\n",
       "      <td>Cbonds prepared monthly report: CBONDS GLOBAL ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>2017-08-03T18:11:32</td>\n",
       "      <td>Дайджест Cbonds от  3 августа:«Группа Компаний...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>2017-08-04T12:42:41</td>\n",
       "      <td>Совкомбанк открыл книгу заявок на вторичное ра...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                 date                                               text  \\\n",
       "0   9  2017-07-28T10:56:14  Cbonds.ru  запустило канал в Telegram. Планиру...   \n",
       "1  10  2017-08-03T15:28:17  Облигационный бюллетень Cbonds – все данные о ...   \n",
       "2  11  2017-08-03T15:41:02  Cbonds prepared monthly report: CBONDS GLOBAL ...   \n",
       "3  12  2017-08-03T18:11:32  Дайджест Cbonds от  3 августа:«Группа Компаний...   \n",
       "4  13  2017-08-04T12:42:41  Совкомбанк открыл книгу заявок на вторичное ра...   \n",
       "\n",
       "   pnl_sign  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pnl_sign'] = df.apply(lambda row: get_pnl_sign(row), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a02b786d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>pnl_sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6400</td>\n",
       "      <td>2021-01-05T09:39:18</td>\n",
       "      <td>УТРЕННИЙ ДАЙДЖЕСТ📈ИндексыCbonds-GBI RU YTM eff...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6401</td>\n",
       "      <td>2021-01-05T10:59:32</td>\n",
       "      <td>⚡️Российские компании: основные события, 5 янв...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6402</td>\n",
       "      <td>2021-01-05T11:33:17</td>\n",
       "      <td>📉 Рубль после попыток роста перешел к снижению...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6405</td>\n",
       "      <td>2021-01-05T14:30:00</td>\n",
       "      <td>🎄🎧  Новогодний интерактив – Часть 2. Cbonds: П...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6406</td>\n",
       "      <td>2021-01-06T09:22:19</td>\n",
       "      <td>УТРЕННИЙ ДАЙДЖЕСТ📈ИндексыCbonds-GBI RU YTM eff...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                 date  \\\n",
       "0  6400  2021-01-05T09:39:18   \n",
       "1  6401  2021-01-05T10:59:32   \n",
       "2  6402  2021-01-05T11:33:17   \n",
       "3  6405  2021-01-05T14:30:00   \n",
       "4  6406  2021-01-06T09:22:19   \n",
       "\n",
       "                                                text  pnl_sign  \n",
       "0  УТРЕННИЙ ДАЙДЖЕСТ📈ИндексыCbonds-GBI RU YTM eff...       1.0  \n",
       "1  ⚡️Российские компании: основные события, 5 янв...       1.0  \n",
       "2  📉 Рубль после попыток роста перешел к снижению...       1.0  \n",
       "3  🎄🎧  Новогодний интерактив – Часть 2. Cbonds: П...       1.0  \n",
       "4  УТРЕННИЙ ДАЙДЖЕСТ📈ИндексыCbonds-GBI RU YTM eff...       1.0  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=['pnl_sign'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4e7f8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['id', 'date', 'pnl_sign'], axis=1)\n",
    "y = df['pnl_sign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3f3545b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        УТРЕННИЙ ДАЙДЖЕСТ📈ИндексыCbonds-GBI RU YTM eff...\n",
       "1        ⚡️Российские компании: основные события, 5 янв...\n",
       "2        📉 Рубль после попыток роста перешел к снижению...\n",
       "3        🎄🎧  Новогодний интерактив – Часть 2. Cbonds: П...\n",
       "4        УТРЕННИЙ ДАЙДЖЕСТ📈ИндексыCbonds-GBI RU YTM eff...\n",
       "                               ...                        \n",
       "12368    Путин анонсировал встречу между Россией и США ...\n",
       "12369    В США ожидаемо одобрили пилюли от Pfizer  Добр...\n",
       "12370    Если очень постараться, то в сочетании букв СП...\n",
       "12371    По данным Росстата, промышленное производство ...\n",
       "12372    Президент РФ Владимир Путин сегодня провел тра...\n",
       "Name: text, Length: 12373, dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7b6e3c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from functools import lru_cache\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm.gui import tqdm as tqdm_gui\n",
    "\n",
    "m = MorphAnalyzer()\n",
    "regex = re.compile(\"[а-яa-zёЁ]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return regex.findall(text.lower())\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "@lru_cache(maxsize=128)\n",
    "def lemmatize_word(token, pymorphy=m):\n",
    "    return pymorphy.parse(token)[0].normal_form\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatize_word(w) for w in text]\n",
    "\n",
    "mystopwords = stopwords.words('russian') \n",
    "def remove_stopwords(lemmas, stopwords = mystopwords):\n",
    "    return [w for w in lemmas if not w in stopwords and len(w) > 3]\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = words_only(text)\n",
    "    lemmas = lemmatize_text(tokens)\n",
    "    \n",
    "    return ' '.join(remove_stopwords(lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "51c88026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "09b2f9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf7309cc7d8e43e3b4d16ac196d1f9cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4774</th>\n",
       "      <td>ОБРАЩЕНИЯ ЗА ПОСОБИЯМИ ПО БЕЗРАБОТИЦЕ В США – ...</td>\n",
       "      <td>обращение пособие безработица менее полмиллион...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8322</th>\n",
       "      <td>Завтрак с РСХБ Инвестиции 27.10.2021 читайте н...</td>\n",
       "      <td>завтрак рсхб инвестиция читать ниже ссылка</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>#Cbonds_Review 📈🧑🏻‍💻 Как инвестору в облигации...</td>\n",
       "      <td>cbonds review инвестор облигация защититься ин...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12303</th>\n",
       "      <td>Несколько слов о рынках .Вчера получил множест...</td>\n",
       "      <td>несколько слово рынок вчера получить множество...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>🏦 Книга заявок по облигациям Сбербанка серии 0...</td>\n",
       "      <td>книга заявка облигация сбербанк серия sber объ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "4774   ОБРАЩЕНИЯ ЗА ПОСОБИЯМИ ПО БЕЗРАБОТИЦЕ В США – ...   \n",
       "8322   Завтрак с РСХБ Инвестиции 27.10.2021 читайте н...   \n",
       "2409   #Cbonds_Review 📈🧑🏻‍💻 Как инвестору в облигации...   \n",
       "12303  Несколько слов о рынках .Вчера получил множест...   \n",
       "2072   🏦 Книга заявок по облигациям Сбербанка серии 0...   \n",
       "\n",
       "                                                  lemmas  \n",
       "4774   обращение пособие безработица менее полмиллион...  \n",
       "8322          завтрак рсхб инвестиция читать ниже ссылка  \n",
       "2409   cbonds review инвестор облигация защититься ин...  \n",
       "12303  несколько слово рынок вчера получить множество...  \n",
       "2072   книга заявка облигация сбербанк серия sber объ...  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas = list(tqdm(map(clean_text, X_train['text']), total=len(X_train)))\n",
    "\n",
    "X_train['lemmas'] = lemmas\n",
    "X_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7159b314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c4046892d94e0cbf9c5cfef761d5dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2475 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lemmas_val = list(tqdm(map(clean_text, X_val['text']), total=len(X_val)))\n",
    "\n",
    "X_val['lemmas'] = lemmas_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "84cde13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9898, 2)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9e76422a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b066ff354f43a3a374ae6fbc875446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                    | 0/9898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0a291fd14e4376834bd77cd78fb1ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                    | 0/2475 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "X_train['embedding'] = X_train['lemmas'].progress_apply(lambda x: get_tweet_embedding(x, model=ft))\n",
    "print('train done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d4b9cb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "591e249537614abc952502ac5773b6d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                    | 0/2475 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tqdm.pandas()\n",
    "# X_val['embedding'] = X_val['lemmas'].progress_apply(lambda x: get_tweet_embedding(x, model=ft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7c58229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedding = np.array(list(X_train['embedding'].values))\n",
    "val_embedding = np.array(list(X_val['embedding'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3ca0cbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5435441503334006"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = LogisticRegression(random_state=12)\n",
    "clf.fit(train_embedding, y_train)\n",
    "clf.score(train_embedding, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "dfae93e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5301010101010101"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf.predict(val_embedding)\n",
    "accuracy_score(pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f1ae4906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5103030303030303"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_features=4, n_estimators=50)\n",
    "\n",
    "rf.fit(train_embedding, y_train)\n",
    "(y_val == rf.predict(val_embedding)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "53f27bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877fcdde2238424ebfffa08a0376362d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x105ffcb80>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import catboost as cb\n",
    "\n",
    "np.random.seed(12)\n",
    "\n",
    "params = dict(\n",
    "    learning_rate=0.025,\n",
    "    iterations=10000,\n",
    "    reg_lambda=0.0005,\n",
    "    colsample_bylevel=1.,\n",
    "    max_bin=80,\n",
    "    bagging_temperature=2,\n",
    "    use_best_model=True,\n",
    "    verbose=False,\n",
    "    grow_policy='Depthwise',\n",
    "    random_seed=12\n",
    ")\n",
    "model = cb.CatBoostClassifier(\n",
    "    **params,\n",
    ")\n",
    "\n",
    "eval_set = cb.Pool(data=val_embedding, label=y_val)\n",
    "model.fit(train_embedding, y_train, eval_set=eval_set, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9f69c134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5438383838383838"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(val_embedding)\n",
    "accuracy_score(pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8de8b7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29864c1cdf344c9d999c06bb11aace17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12373 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lemmas = list(tqdm(map(clean_text, df['text']), total=len(df)))\n",
    "\n",
    "df['lemmas'] = lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "344297db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(df, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0a423224",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_ft.txt', 'w') as f:\n",
    "    for label, lemmas in list(zip(\n",
    "        y_train, X_train['lemmas']\n",
    "    )):\n",
    "        f.write(f\"__label__{int(label)} {lemmas}\\n\")\n",
    "        #print(f\"__label__{int(label)} {lemmas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "25163fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__0 продолжать следить реакция мировой сообщество экстренный посадка рейс ryanair минск собранный комментарий запад лишь незначительный часть буря медиа пространство который подняться повод выразиться умник элегантный действие минск нива поимка враг режим лукашенко похоже дать элегантный история мочь душевно ударить экономика беларусь секрет многие лететь транзит минск хотеть попасть москва киев обратно данный транзит вообще транзитный поневоле тематика стать очень неплохой источник доход авиаотрасль беларусь соответственно экономика вероятность дать история белавиа мочь наступить непростой время судить последний заявление политик рада целое государство евросоюз мочь закрыться весь евросоюз лишь предположение сделать основа высказывание политический деятель горячий след произойти воскресение вечером интересно связь реакция киев вряд сильно отличаться реакция европа накрываться транзит говориться медный вообще экономика беларусь элегантный элегантный звездец bitkogan\r\n",
      "__label__1 устроенный венчурный бизнес особенность инвестирование tech стартап опыт investments герой новый серия интервью профессиональный участник инвестиционный рынок герман каплун сооснователь директор стратегия британский публичный инвестиционный компания investments рыночный капитализация который достигать миллион доллар доходность инвестиция впечатляющий годовой компания investments запустить новый фонд прямой инвестиция наиболее активно развивающийся сфера новый технология saas data marketplace healthtech ecommerce fintech герман каплун заниматься венчурный инвестирование участвовать запуск покупка стартап число сервис знакомство loveplanet крупный российский хостинг хостинг центр оператор iglobe канал интервью андрей мовчан поделиться опыт удачный неудачный венчурный инвестиция рассказать бизнес investments работа новый фонд кроме опытный медиа менеджер сооснователь росбизнесконсалтинг развиваться крупный российский медиахолдинг продажа михаил прохоров https youtube watch lkepjhgq\r\n",
      "__label__0 наблюдение облигация пара слово коллега вячеслав денисов сидеть деске fixed income покупать продавать бонд разный валюта фонд стратегия внебиржа over counter внебиржевой рынок буквально выгрызать хороший цена контрагент институционал бороться каждый пипс цена доля процент управлять отправлять исполнение бида офер заявка покупка продажа слава финалить рынок объём цена ошибка ответственность огромный слава каждый вечер делать срез увидеть день рынок облигация достоверный цена реальный сделка свежий подсвечивать положение дело бумага который постоянно торговать который следить писать душа вкладываться творчески очевидный любовь дело нейронке сбер сила слава читать каждый день коротко понятно видеть общий движение бонд особенно полезно весь день заглянуть блумберг публиковать сюда оценить первый дейли коммент слава ниже alfawealth\r\n",
      "__label__0 сбериндекс влияние школьный выплата угасать впереди новый ассигнование военный пенсионер сбер делать вывод оценка потребительский активность относительно низкий база целое нормализоваться динамика вновь отслеживаться годовой сопоставление отношение фиксировать период февраль март полагать данный момент сравнение именно отрезок время репрезентативно недельный сравнение приводиться дать период итог неделя август допандемийный период товар услуга указанный выше период неделя ранее товар услуга сбер полагать влияние президентский выплата школьник постепенно сходить сохраняться спрос непродовольственный розница\r\n",
      "__label__0 утренний дайджест индекс cbonds cbonds euro cbonds sovereign index cbonds high yield календарь событийсбор заявка группа млрд аукцион минфин россия млрд млрд размещение финанс млрд деметр холдинг оферта сегодня запланировать cbonds\r\n",
      "__label__0 petropavlovsk бодрый весь живой petropavlovsk pogr последний время показать неплохой performance локальный минимум октябрь бумага газануть наверх pogr значительно опередить динамика полюс plzl полиметалл poly прибавить аналогичный период соответственно рост котировка способствовать золото цена который вырасти небольшой локальный ослабление доллар образ реализоваться сценарий который говорить неоднократно возвращение золото рост petropavlovsk отстреливать гораздо бодрый остальной российский ликвидный золотодобытчик видимо играть фактор постепенно угасать корпоративный конфликт прекрасно риска забывать конъюнктура цена золото сегодня довольно неопределённый позитивный тренд очень слабый мнение оставаться неизменный полагать результат происходить событие золото мочь появиться достаточно сильный аптренд существовать весьма серьёзный предпосылка скоро написать подробно любой интеллигентный человек отличаться вполне допускать мнение мнение жизнь гораздо сложный многогранный оставлять пространство сомнение определённый обстоятельство акция petropavlovsk бодро мочь проследовать обратный направление выбирать момент фиксация прибыль хотя частичный необходимо особый тщательность акция золото bitkogan\r\n",
      "__label__0 добрый утро вчера ленивый написать личка эколог бобик сдохнуть пропасть достаточно серьёзный падение бумага сектор привести народ занервничать случиться aphria опубликовать очень хороший отчёт продажа ниже ожидание убыток размер цент акция вместо ожидать продажа вместо ожидать итог падение бумага компания вчерашний торговый сессия менее душевно вчера валиться бумага компания катастрофа думать плохой отчёт результат жёсткий локдаун последовать результат закрытие магазин подробно написать сегодня день дать прогноз делать помнить февраль достаточно сильно продаться хороший рост бумага отрасль https bitkogan https bitkogan бумага душевно разгоняться энтузиаст робин неплохо отрасти дальнейший акция значительно просесть вновь начать покупать спешить аккуратно вчерашний просадка обязательно увеличивать доля бумага сертификат полагать никто умереть рынок править сантимент сегодня сторона экология завтра пожить увидеть фортуна девушка капризный сегодня ночевать сосед завтра мочь забежать рюмочка cегодень выходить отчёт компания сектор думать новый скорее весь отчёт сильно обрадовать инвестор bitkogan\r\n",
      "__label__0 финасовый рынок неделя акция купить дивиденд великобритания готовить новый санкция против олигарх российский госдолг price сделать основатель миллиардер сбербанк повышать максимальный ставка розничный вклад рубль годовой почему важно также рыночный ожидание графика неделя\r\n",
      "__label__1 аукцион минфин риск маленький спрос большой риск санкционный повестка отношение определённо снизиться обеспечить минфин самый удачный аукцион последний полгода сегодня предложить классический выпуск летний летний спрос составить млрд рубль соответственно рынок уйти бумага млрд рубль максимальный объём начинать начало ноябрь разместить млрд рубль оценка участник торг рыночный спрос помимо госбанк составить около млрд рубль заметный заявка нерезидент наблюдаться удачный аукцион определённый степень мочь дополнительно улучшить сентимент обусловить дальнейший сокращение санкционный премия\r\n",
      "__label__0 евро продолжать планировать мочь испортиться сегодня настроение инвестор валюта евро bitkogan\r\n"
     ]
    }
   ],
   "source": [
    "!tail train_ft.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "996c9c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  27960\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 2798046 lr:  0.000000 avg.loss:  0.689908 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "classifier = fasttext.train_supervised('train_ft.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9371ecc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5385858585858586"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = classifier.predict(list(X_val['lemmas']))[0]\n",
    "pred = [int(label[0][-1]) for label in pred]\n",
    "\n",
    "accuracy_score(list(y_val), pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "cd1fef11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.68 s, sys: 26.9 ms, total: 4.7 s\n",
      "Wall time: 1.32 s\n"
     ]
    }
   ],
   "source": [
    "tokenized_tweets = [tweet.split() for tweet in train['lemmas'].values]\n",
    "\n",
    "%time w2v = word2vec.Word2Vec(tokenized_tweets, workers=4, vector_size=200, min_count=10, window=3, sample=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "cfed6754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('снижение', 0.8320657014846802),\n",
       " ('падение', 0.7674662470817566),\n",
       " ('возрасти', 0.7310284972190857),\n",
       " ('скачок', 0.7289108037948608),\n",
       " ('замедление', 0.724600076675415),\n",
       " ('восстановление', 0.7084911465644836),\n",
       " ('энергоноситель', 0.6922722458839417),\n",
       " ('увеличение', 0.6910353899002075),\n",
       " ('опережать', 0.6852946877479553),\n",
       " ('прирост', 0.6814692616462708)]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(positive=['рост'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0ee7fb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_embedding(lemmas, model=w2v.wv, embedding_size=200):\n",
    "    \n",
    "    res = np.zeros(embedding_size)\n",
    "    cnt = 0\n",
    "    for word in lemmas.split():\n",
    "        if word in model:\n",
    "            res += np.array(model[word])\n",
    "            cnt += 1\n",
    "    if cnt:\n",
    "        res = res / cnt\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a1c181c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['w2v_embedding'] = X_train['lemmas'].map(get_tweet_embedding)\n",
    "X_val['w2v_embedding'] = X_val['lemmas'].map(get_tweet_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f4694775",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w2v = list(X_train['w2v_embedding'].values)\n",
    "val_w2v = list(X_val['w2v_embedding'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f10b33c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5317171717171717"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=12, max_iter=500)\n",
    "clf.fit(train_w2v, y_train)\n",
    "\n",
    "pred = clf.predict(val_w2v)\n",
    "accuracy_score(pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "069e738a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "461dc13e67884b099cc3415d3b51b26a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x4dcf93580>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import catboost as cb\n",
    "\n",
    "np.random.seed(12)\n",
    "\n",
    "params = dict(\n",
    "    learning_rate=0.025,\n",
    "    iterations=10000,\n",
    "    reg_lambda=0.0005,\n",
    "    colsample_bylevel=1.,\n",
    "    max_bin=80,\n",
    "    bagging_temperature=2,\n",
    "    use_best_model=True,\n",
    "    verbose=False,\n",
    "    grow_policy='Depthwise',\n",
    "    random_seed=12\n",
    ")\n",
    "model = cb.CatBoostClassifier(\n",
    "    **params,\n",
    ")\n",
    "\n",
    "eval_set = cb.Pool(data=val_w2v, label=y_val)\n",
    "model.fit(train_w2v, y_train, eval_set=eval_set, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2145fc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5422222222222223"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(val_w2v)\n",
    "accuracy_score(pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2f5e4e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm  \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim import utils\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "\n",
    "# import dlnlputils\n",
    "# from dlnlputils.data import tokenize_text_simple_regex, tokenize_corpus, build_vocabulary, \\\n",
    "#     vectorize_texts, SparseFeaturesDataset\n",
    "# from dlnlputils.pipeline import train_eval_loop, predict_with_model, init_random_seed\n",
    "\n",
    "# init_random_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "86569712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "TOKEN_RE = re.compile(r'[\\w\\d]+')\n",
    "\n",
    "\n",
    "def tokenize_text_simple_regex(txt, min_token_size=4):\n",
    "    txt = txt.lower()\n",
    "    all_tokens = TOKEN_RE.findall(txt)\n",
    "    return [token for token in all_tokens if len(token) >= min_token_size]\n",
    "\n",
    "\n",
    "def character_tokenize(txt):\n",
    "    return list(txt)\n",
    "\n",
    "\n",
    "def tokenize_corpus(texts, tokenizer=tokenize_text_simple_regex, **tokenizer_kwargs):\n",
    "    return [tokenizer(text, **tokenizer_kwargs) for text in texts]\n",
    "\n",
    "\n",
    "def add_fake_token(word2id, token=''):\n",
    "    word2id_new = {token: i + 1 for token, i in word2id.items()}\n",
    "    word2id_new[token] = 0\n",
    "    return word2id_new\n",
    "\n",
    "\n",
    "def texts_to_token_ids(tokenized_texts, word2id):\n",
    "    return [[word2id[token] for token in text if token in word2id]\n",
    "            for text in tokenized_texts]\n",
    "\n",
    "\n",
    "def build_vocabulary(tokenized_texts, max_size=1000000, max_doc_freq=0.8, min_count=5, pad_word=None):\n",
    "    word_counts = collections.defaultdict(int)\n",
    "    doc_n = 0\n",
    "\n",
    "    # посчитать количество документов, в которых употребляется каждое слово\n",
    "    # а также общее количество документов\n",
    "    for txt in tokenized_texts:\n",
    "        doc_n += 1\n",
    "        unique_text_tokens = set(txt)\n",
    "        for token in unique_text_tokens:\n",
    "            word_counts[token] += 1\n",
    "\n",
    "    # убрать слишком редкие и слишком частые слова\n",
    "    word_counts = {word: cnt for word, cnt in word_counts.items()\n",
    "                   if cnt >= min_count and cnt / doc_n <= max_doc_freq}\n",
    "\n",
    "    # отсортировать слова по убыванию частоты\n",
    "    sorted_word_counts = sorted(word_counts.items(),\n",
    "                                reverse=True,\n",
    "                                key=lambda pair: pair[1])\n",
    "\n",
    "    # добавим несуществующее слово с индексом 0 для удобства пакетной обработки\n",
    "    if pad_word is not None:\n",
    "        sorted_word_counts = [(pad_word, 0)] + sorted_word_counts\n",
    "\n",
    "    # если у нас по прежнему слишком много слов, оставить только max_size самых частотных\n",
    "    if len(word_counts) > max_size:\n",
    "        sorted_word_counts = sorted_word_counts[:max_size]\n",
    "\n",
    "    # нумеруем слова\n",
    "    word2id = {word: i for i, (word, _) in enumerate(sorted_word_counts)}\n",
    "\n",
    "    # нормируем частоты слов\n",
    "    word2freq = np.array([cnt / doc_n for _, cnt in sorted_word_counts], dtype='float32')\n",
    "\n",
    "    return word2id, word2freq\n",
    "\n",
    "\n",
    "PAD_TOKEN = '__PAD__'\n",
    "NUMERIC_TOKEN = '__NUMBER__'\n",
    "NUMERIC_RE = re.compile(r'^([0-9.,e+\\-]+|[mcxvi]+)$', re.I)\n",
    "\n",
    "\n",
    "def replace_number_nokens(tokenized_texts):\n",
    "    return [[token if not NUMERIC_RE.match(token) else NUMERIC_TOKEN for token in text]\n",
    "            for text in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d1e0c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "def vectorize_texts(tokenized_texts, word2id, word2freq, mode='tfidf', scale=True):\n",
    "    assert mode in {'tfidf', 'idf', 'tf', 'bin'}\n",
    "\n",
    "    # считаем количество употреблений каждого слова в каждом документе\n",
    "    result = scipy.sparse.dok_matrix((len(tokenized_texts), len(word2id)), dtype='float32')\n",
    "    for text_i, text in enumerate(tokenized_texts):\n",
    "        for token in text:\n",
    "            if token in word2id:\n",
    "                result[text_i, word2id[token]] += 1\n",
    "\n",
    "    # получаем бинарные вектора \"встречается или нет\"\n",
    "    if mode == 'bin':\n",
    "        result = (result > 0).astype('float32')\n",
    "\n",
    "    # получаем вектора относительных частот слова в документе\n",
    "    elif mode == 'tf':\n",
    "        result = result.tocsr()\n",
    "        result = result.multiply(1 / result.sum(1))\n",
    "\n",
    "    # полностью убираем информацию о количестве употреблений слова в данном документе,\n",
    "    # но оставляем информацию о частотности слова в корпусе в целом\n",
    "    elif mode == 'idf':\n",
    "        result = (result > 0).astype('float32').multiply(1 / word2freq)\n",
    "\n",
    "    # учитываем всю информацию, которая у нас есть:\n",
    "    # частоту слова в документе и частоту слова в корпусе\n",
    "    elif mode == 'tfidf':\n",
    "        result = result.tocsr()\n",
    "        result = result.multiply(1 / result.sum(1))  # разделить каждую строку на её длину\n",
    "        result = result.multiply(1 / word2freq)  # разделить каждый столбец на вес слова\n",
    "\n",
    "    if scale:\n",
    "        result = result.tocsc()\n",
    "        result -= result.min()\n",
    "        result /= (result.max() + 1e-6)\n",
    "\n",
    "    return result.tocsr()\n",
    "\n",
    "\n",
    "class SparseFeaturesDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cur_features = torch.from_numpy(self.features[idx].toarray()[0]).float()\n",
    "        cur_label = torch.from_numpy(np.asarray(self.targets[idx])).long()\n",
    "        return cur_features, cur_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8a3793d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = tokenize_corpus(X_train['text'])\n",
    "val_tokenized = tokenize_corpus(X_val['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "395e4250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fresnillo конкретно интересно если резвящиеся толпы робингудов догонят серебро хотя тогда бумажка будет хорошо если имеется загашниках bitkogan\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(train_tokenized[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "79a12687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных токенов 17625\n",
      "[('года', 0), ('bitkogan', 1), ('млрд', 2), ('более', 3), ('может', 4), ('будет', 5), ('рост', 6), ('также', 7), ('сегодня', 8), ('компании', 9)]\n"
     ]
    }
   ],
   "source": [
    "# строим словарь - vocabulary с помощью функции build_vocabulary\n",
    "# принимает на вход список списков токенезированные\n",
    "# word_doc_freq - содержит относительные частоты всех слов в датасете, он понадобиться \n",
    "# на этапе формирования матрицы признаков\n",
    "\n",
    "MAX_DF = 0.8 #во скольких документах встречаеться слово\n",
    "MIN_COUNT = 5 # сколько раз слово встречаеться в тексте\n",
    "\n",
    "\n",
    "vocabulary, word_doc_freq = build_vocabulary(train_tokenized, max_doc_freq=MAX_DF, min_count=MIN_COUNT)\n",
    "UNIQUE_WORDS_N = len(vocabulary)\n",
    "print('Количество уникальных токенов', UNIQUE_WORDS_N)\n",
    "print(list(vocabulary.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "3ebd3e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(word_doc_freq, bins=20)\n",
    "plt.title('Распределение относительных частот слов')\n",
    "plt.yscale('log');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ed0faaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность матрицы признаков обучающей выборки (9898, 17625)\n",
      "\n",
      "Количество ненулевых элементов в обучающей выборке 672202\n",
      "Процент заполненности матрицы признаков 0.39%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "VECTORIZATION_MODE = 'tfidf'\n",
    "# построение матрицы признаков по методу мешка слов\n",
    "# функция vectorize_texts принимает на вход\n",
    "#1. токенизированные список списков\n",
    "#2. словарь\n",
    "#3. вектор частоты токенизированны\n",
    "#4. алгоритм взвешивания токенов по частоте mode - есть 4 алгорима - bin,tf,idf,tfidf\n",
    "#5. флаг чтобы перемаштабировать флаг после взвешивания\n",
    "\n",
    "train_vectors = vectorize_texts(train_tokenized, vocabulary, word_doc_freq, mode=VECTORIZATION_MODE)\n",
    "\n",
    "print('Размерность матрицы признаков обучающей выборки', train_vectors.shape)\n",
    "print()\n",
    "print('Количество ненулевых элементов в обучающей выборке', train_vectors.nnz)\n",
    "print('Процент заполненности матрицы признаков {:.2f}%'.format(train_vectors.nnz * 100 / (train_vectors.shape[0] * train_vectors.shape[1])))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "686d2508",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_t = api.load('glove-twitter-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "7aa419ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "\n",
    "def get_vectors_gt100(row):\n",
    "    '''\n",
    "      word_doc_freq # частоты слов\n",
    "      train_tokenized #сами слова\n",
    "    '''\n",
    "    vecs = [np.zeros(100)]\n",
    "    for word in row:\n",
    "        #print(row)\n",
    "        try: \n",
    "            # если слово есть в нашем очищенном словаре\n",
    "            # умножаем вектор на вес tfidf\n",
    "            v = model_t[word] * word_doc_freq[vocabulary[word]] \n",
    "        except:\n",
    "            v = np.zeros(100)\n",
    "        vecs.append(v)\n",
    "    return np.sum(np.array(vecs),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1d2e5892",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gt100 = np.array([get_vectors_gt100(i) for i in train_tokenized])\n",
    "val_gt100 = np.array([get_vectors_gt100(i) for i in val_tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "2730d1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('аналитик', 0.7176759243011475)]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_t.most_similar(positive=['инвестор', 'рынок'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ddd22560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5414141414141415"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=12, max_iter=500)\n",
    "clf.fit(train_gt100, y_train)\n",
    "\n",
    "pred = clf.predict(val_gt100)\n",
    "accuracy_score(pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d2c095ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e57ec166f2844bbaaf258f643ecfd96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x503428d90>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import catboost as cb\n",
    "\n",
    "np.random.seed(12)\n",
    "\n",
    "params = dict(\n",
    "    learning_rate=0.025,\n",
    "    iterations=10000,\n",
    "    reg_lambda=0.0005,\n",
    "    colsample_bylevel=1.,\n",
    "    max_bin=80,\n",
    "    bagging_temperature=2,\n",
    "    use_best_model=True,\n",
    "    verbose=False,\n",
    "    grow_policy='Depthwise',\n",
    "    random_seed=12\n",
    ")\n",
    "model = cb.CatBoostClassifier(\n",
    "    **params,\n",
    ")\n",
    "\n",
    "eval_set = cb.Pool(data=val_gt100, label=y_val)\n",
    "model.fit(train_gt100, y_train, eval_set=eval_set, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "81132739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5361616161616162"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(val_w2v)\n",
    "accuracy_score(pred, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
